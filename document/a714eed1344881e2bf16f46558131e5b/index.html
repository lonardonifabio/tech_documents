<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="This document outlines the development of a neural machine translation (NMT) system specifically for translating from English to Portuguese. The core of the project utilizes Long Short-Term Memory (LSTM) networks, a popular architecture for sequence-to-sequence tasks, combined with an attention m..."><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/tech_documents/favicon.svg"><link rel="manifest" href="/tech_documents/manifest.json"><title>Neural Machine Translation (English - Portuguese) with LSTM and Attention</title><!-- Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-G7VY771Q53"></script><!-- PWA Meta Tags --><!-- <meta name="theme-color" content="#667eea"> --><!-- <meta name="apple-mobile-web-app-capable" content="yes"> --><!-- <meta name="apple-mobile-web-app-status-bar-style" content="default"> --><!-- <meta name="apple-mobile-web-app-title" content="AI Doc Library"> --><!-- Enhanced Open Graph for LinkedIn sharing --><meta property="og:title" content="Neural Machine Translation (English - Portuguese) with LSTM and Attention"><meta property="og:description" content="This document outlines the development of a neural machine translation (NMT) system specifically for translating from English to Portuguese. The core of the project utilizes Long Short-Term Memory (LSTM) networks, a popular architecture for sequence-to-sequence tasks, combined with an attention m..."><meta property="og:type" content="article"><meta property="og:url" content="https://lonardonifabio.github.io/tech_documents/document/a714eed1344881e2bf16f46558131e5b"><meta property="og:image" content="https://lonardonifabio.github.io/tech_documents/preview/a714eed1344881e2bf16f46558131e5b.jpg"><meta property="og:image:secure_url" content="https://lonardonifabio.github.io/tech_documents/preview/a714eed1344881e2bf16f46558131e5b.jpg"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="Neural Machine Translation (English - Portuguese) with LSTM and Attention - AI &#38; Data Science Document Library"><meta property="og:site_name" content="AI & Data Science Document Library"><meta property="og:locale" content="en_US"><meta property="article:author" content="Fabio Lonardoni"><meta property="article:section" content="Technology"><meta property="article:tag" content="Neural Machine Translation, LSTM, Attention Mechanism, Encoder-Decoder, Tensorflow, MBR (Minimum Bayes Risk), neural network, Encoder, Embedding, Bidirectional LSTM"><meta property="article:published_time" content="2025-06-30T13:00:26.318639"><!-- LinkedIn specific meta tags --><meta property="linkedin:owner" content="Fabio Lonardoni"><!-- Additional meta for mobile sharing --><meta name="author" content="Houssem Zelmat"><meta name="keywords" content="Neural Machine Translation, LSTM, Attention Mechanism, Encoder-Decoder, Tensorflow, MBR (Minimum Bayes Risk), neural network, Encoder, Embedding, Bidirectional LSTM"><meta name="robots" content="index, follow"><link rel="canonical" href="https://lonardonifabio.github.io/tech_documents/document/a714eed1344881e2bf16f46558131e5b"><!-- Additional LinkedIn optimization --><meta property="og:rich_attachment" content="true"><!-- Structured Data for better SEO --><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Neural Machine Translation (English - Portuguese) with LSTM and Attention","description":"This document outlines the development of a neural machine translation (NMT) system specifically for translating from English to Portuguese. The core of the project utilizes Long Short-Term Memory (LSTM) networks, a popular architecture for sequence-to-sequence tasks, combined with an attention m...","author":{"@type":"Person","name":"Houssem Zelmat"},"publisher":{"@type":"Organization","name":"AI & Data Science Document Library","logo":{"@type":"ImageObject","url":"https://lonardonifabio.github.io/tech_documents/preview/a714eed1344881e2bf16f46558131e5b.jpg"}},"url":"https://lonardonifabio.github.io/tech_documents/document/a714eed1344881e2bf16f46558131e5b","datePublished":"2025-06-30T13:00:26.318639","image":"https://lonardonifabio.github.io/tech_documents/preview/a714eed1344881e2bf16f46558131e5b.jpg","keywords":"Neural Machine Translation, LSTM, Attention Mechanism, Encoder-Decoder, Tensorflow, MBR (Minimum Bayes Risk), neural network, Encoder, Embedding, Bidirectional LSTM"}</script><!-- Simple redirect script --><script>(function(){const mainAppUrl = "https://lonardonifabio.github.io/tech_documents/?doc=a714eed1344881e2bf16f46558131e5b";

      // Manual redirect only - no automatic redirects that interfere with crawlers
      if (typeof window !== 'undefined') {
        // Add click handler for manual redirect button
        document.addEventListener('DOMContentLoaded', () => {
          const redirectButton = document.getElementById('manual-redirect');
          if (redirectButton) {
            redirectButton.addEventListener('click', () => {
              window.location.href = mainAppUrl;
            });
          }
        });
      }
    })();</script><link rel="stylesheet" href="/tech_documents/assets/_id_.B2K7fHu1.css">
<style>html{font-family:system-ui,sans-serif}::-webkit-scrollbar{width:8px}::-webkit-scrollbar-track{background:#f1f1f1}::-webkit-scrollbar-thumb{background:#c1c1c1;border-radius:4px}::-webkit-scrollbar-thumb:hover{background:#a8a8a8}
</style><script type="module">"serviceWorker"in navigator&&window.addEventListener("load",()=>{navigator.serviceWorker.register("/tech_documents/sw.js").then(e=>{console.log("SW registered: ",e)}).catch(e=>{console.log("SW registration failed: ",e)})});window.dataLayer=window.dataLayer||[];function a(){dataLayer.push(arguments)}a("js",new Date);a("config","G-G7VY771Q53");
</script></head> <body class="bg-gray-50 min-h-screen"> <!-- Fallback content for crawlers and users with JS disabled --> <div class="max-w-4xl mx-auto p-8"> <div class="bg-white rounded-lg shadow-lg p-6"> <h1 class="text-3xl font-bold text-gray-900 mb-4">Neural Machine Translation (English - Portuguese) with LSTM and Attention</h1> <div class="mb-4"> <p class="text-gray-600"> <strong>Authors:</strong> Houssem Zelmat </p> </div> <div class="mb-6"> <p class="text-gray-700 leading-relaxed">This document outlines the development of a neural machine translation (NMT) system specifically for translating from English to Portuguese. The core of the project utilizes Long Short-Term Memory (LSTM) networks, a popular architecture for sequence-to-sequence tasks, combined with an attention mechanism. The motivation behind this approach stems from the limitations of traditional Recurrent Neural Networks (RNNs) with LSTMs when dealing with longer sentences, particularly the issue of vanishing gradients. The attention mechanism addresses this by allowing the decoder to focus on all relevant parts of the input sentence, regardless of its length, significantly improving translation accuracy for extended sequences. The project involves building the NMT model from scratch using TensorFlow, incorporating both greedy and Minimum Bayes Risk (MBR) decoding strategies for generating translations. A crucial initial step is thorough data preparation, which includes reading raw data from text files, cleaning the data through operations like lowercasing, punctuation handling, whitespace trimming, and splitting the data into training and validation sets. Furthermore, the document details the addition of start-of-sentence and end-of-sentence tokens to each sentence and the creation of a TensorFlow dataset from the tokenized sentences. This structured approach ensures the model is trained effectively and accurately. The overall goal is to create a robust and accurate NMT system capable of handling the complexities of language translation.</p> </div> <div class="flex flex-wrap gap-2 mb-6"> <span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Neural Machine Translation </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> LSTM </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Attention Mechanism </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Encoder-Decoder </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Tensorflow </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> MBR (Minimum Bayes Risk) </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> neural network </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Encoder </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Embedding </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Bidirectional LSTM </span> </div> <div class="flex items-center justify-between text-sm text-gray-500 mb-6"> <span class="bg-green-100 text-green-800 px-3 py-1 rounded-full"> Technology </span> <span class="bg-orange-100 text-orange-800 px-3 py-1 rounded-full"> Intermediate </span> </div> <div class="flex gap-4"> <a href="https://lonardonifabio.github.io/tech_documents/?doc=a714eed1344881e2bf16f46558131e5b" class="bg-green-600 text-white px-6 py-2 rounded-lg hover:bg-green-700 transition-colors">
üîç View in the library powered by AI
</a> </div> <div class="mt-6 p-4 bg-blue-50 rounded-lg"> <p class="text-blue-800 text-sm"> <strong>Note:</strong> This is a static page optimized for social media sharing.
<a href="https://lonardonifabio.github.io/tech_documents/?doc=a714eed1344881e2bf16f46558131e5b" class="underline font-semibold">Click here to view this document in the interactive library</a>.
</p> </div> </div> </div> <!-- Service Worker Registration -->  </body> </html> 