<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="This document, titled &#34;Disrupting malicious uses of AI: June 2025&#34;, outlines efforts to mitigate the harmful applications of artificial general intelligence (AI). The core mission is to ensure AI benefits all of humanity, focusing on deploying AI tools to address complex problems while simultaneo..."><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/tech_documents/favicon.svg"><link rel="manifest" href="/tech_documents/manifest.json"><title>Disrupting malicious uses of AI: June 2025</title><!-- Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-G7VY771Q53"></script><!-- PWA Meta Tags --><!-- <meta name="theme-color" content="#667eea"> --><!-- <meta name="apple-mobile-web-app-capable" content="yes"> --><!-- <meta name="apple-mobile-web-app-status-bar-style" content="default"> --><!-- <meta name="apple-mobile-web-app-title" content="AI Doc Library"> --><!-- Enhanced Open Graph for LinkedIn sharing --><meta property="og:title" content="Disrupting malicious uses of AI: June 2025"><meta property="og:description" content="This document, titled &#34;Disrupting malicious uses of AI: June 2025&#34;, outlines efforts to mitigate the harmful applications of artificial general intelligence (AI). The core mission is to ensure AI benefits all of humanity, focusing on deploying AI tools to address complex problems while simultaneo..."><meta property="og:type" content="article"><meta property="og:url" content="https://lonardonifabio.github.io/tech_documents/document/41824d77c596fe749ee0f831d3832fc4"><meta property="og:image" content="https://lonardonifabio.github.io/tech_documents/previews/41824d77c596fe749ee0f831d3832fc4.jpg?v=1752494668848"><meta property="og:image:secure_url" content="https://lonardonifabio.github.io/tech_documents/previews/41824d77c596fe749ee0f831d3832fc4.jpg?v=1752494668848"><meta property="og:image:type" content="image/svg+xml"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="Disrupting malicious uses of AI: June 2025 - AI &#38; Data Science Document Library"><meta property="og:site_name" content="AI & Data Science Document Library"><meta property="og:locale" content="en_US"><meta property="article:author" content="Fabio Lonardoni"><meta property="article:section" content="AI"><meta property="article:tag" content="AI, artificial intelligence, malicious uses, cover t influence operations, IO, scams, cyber activity, spam, authoritarian regimes, common-sense rules"><meta property="article:published_time" content="2025-06-28T17:59:01"><!-- LinkedIn specific meta tags --><meta property="linkedin:owner" content="Fabio Lonardoni"><!-- Additional meta for mobile sharing --><meta name="author" content=""><meta name="keywords" content="AI, artificial intelligence, malicious uses, cover t influence operations, IO, scams, cyber activity, spam, authoritarian regimes, common-sense rules"><meta name="robots" content="index, follow"><link rel="canonical" href="https://lonardonifabio.github.io/tech_documents/document/41824d77c596fe749ee0f831d3832fc4"><!-- Additional LinkedIn optimization --><meta property="og:rich_attachment" content="true"><!-- Structured Data for better SEO --><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Disrupting malicious uses of AI: June 2025","description":"This document, titled \"Disrupting malicious uses of AI: June 2025\", outlines efforts to mitigate the harmful applications of artificial general intelligence (AI). The core mission is to ensure AI benefits all of humanity, focusing on deploying AI tools to address complex problems while simultaneo...","author":{"@type":"Person","name":""},"publisher":{"@type":"Organization","name":"AI & Data Science Document Library","logo":{"@type":"ImageObject","url":"https://lonardonifabio.github.io/tech_documents/previews/41824d77c596fe749ee0f831d3832fc4.jpg?v=1752494668848"}},"url":"https://lonardonifabio.github.io/tech_documents/document/41824d77c596fe749ee0f831d3832fc4","datePublished":"2025-06-28T17:59:01","image":"https://lonardonifabio.github.io/tech_documents/previews/41824d77c596fe749ee0f831d3832fc4.jpg?v=1752494668848","keywords":"AI, artificial intelligence, malicious uses, cover t influence operations, IO, scams, cyber activity, spam, authoritarian regimes, common-sense rules"}</script><!-- Simple redirect script --><script>(function(){const mainAppUrl = "https://lonardonifabio.github.io/tech_documents/?doc=41824d77c596fe749ee0f831d3832fc4";

      // Manual redirect only - no automatic redirects that interfere with crawlers
      if (typeof window !== 'undefined') {
        // Add click handler for manual redirect button
        document.addEventListener('DOMContentLoaded', () => {
          const redirectButton = document.getElementById('manual-redirect');
          if (redirectButton) {
            redirectButton.addEventListener('click', () => {
              window.location.href = mainAppUrl;
            });
          }
        });
      }
    })();</script><link rel="stylesheet" href="/tech_documents/assets/_id_.B2K7fHu1.css">
<style>html{font-family:system-ui,sans-serif}::-webkit-scrollbar{width:8px}::-webkit-scrollbar-track{background:#f1f1f1}::-webkit-scrollbar-thumb{background:#c1c1c1;border-radius:4px}::-webkit-scrollbar-thumb:hover{background:#a8a8a8}
</style><script type="module">"serviceWorker"in navigator&&window.addEventListener("load",()=>{navigator.serviceWorker.register("/tech_documents/sw.js").then(e=>{console.log("SW registered: ",e)}).catch(e=>{console.log("SW registration failed: ",e)})});window.dataLayer=window.dataLayer||[];function a(){dataLayer.push(arguments)}a("js",new Date);a("config","G-G7VY771Q53");
</script></head> <body class="bg-gray-50 min-h-screen"> <!-- Fallback content for crawlers and users with JS disabled --> <div class="max-w-4xl mx-auto p-8"> <div class="bg-white rounded-lg shadow-lg p-6"> <h1 class="text-3xl font-bold text-gray-900 mb-4">Disrupting malicious uses of AI: June 2025</h1>  <div class="mb-6"> <p class="text-gray-700 leading-relaxed">This document, titled &quot;Disrupting malicious uses of AI: June 2025&quot;, outlines efforts to mitigate the harmful applications of artificial general intelligence (AI). The core mission is to ensure AI benefits all of humanity, focusing on deploying AI tools to address complex problems while simultaneously safeguarding against misuse. The document specifically addresses concerns related to authoritarian regimes leveraging AI for control and coercion, as well as various malicious activities including covert influence operations (IO), child exploitation, scams, spam, and cyberattacks. It emphasizes the importance of establishing common-sense rules to protect individuals from harm and building democratic AI systems. The document references a submission to the Office of Science and Technology Policy‚Äôs U.S. AI Action Plan, indicating a strategic approach to AI governance. It details several operational investigations, including &quot;Operation Sneer Review&quot;, &quot;Operation High Five&quot;, &quot;Operation VAGue Focus&quot;, &quot;Operation Helgoland Bite&quot;, &quot;ScopeCreep&quot;, &quot;Vixen and Keyhole Panda&quot;, and &quot;Operation Uncle Spam&quot;.  The analysis suggests a proactive stance, utilizing AI not only to combat malicious activities but also to defend against them. The document‚Äôs focus on IO and recidivist influence activity, exemplified by STORM-2035, highlights a concern for sophisticated, long-term threats.  The inclusion of scam operations like &quot;Wrong Number&quot; underscores the diverse range of malicious activities being targeted.  Ultimately, the document presents a multi-faceted strategy for responsible AI development and deployment, recognizing the potential for both benefit and harm, and advocating for a robust defense against malicious actors.</p> </div> <div class="flex flex-wrap gap-2 mb-6"> <span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> AI </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> artificial intelligence </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> malicious uses </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> cover t influence operations </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> IO </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> scams </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> cyber activity </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> spam </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> authoritarian regimes </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> common-sense rules </span> </div> <div class="flex items-center justify-between text-sm text-gray-500 mb-6"> <span class="bg-green-100 text-green-800 px-3 py-1 rounded-full"> AI </span> <span class="bg-orange-100 text-orange-800 px-3 py-1 rounded-full"> Intermediate </span> </div> <div class="flex gap-4"> <a href="https://lonardonifabio.github.io/tech_documents/?doc=41824d77c596fe749ee0f831d3832fc4" class="bg-green-600 text-white px-6 py-2 rounded-lg hover:bg-green-700 transition-colors">
üîç View in the library powered by AI
</a> </div> <div class="mt-6 p-4 bg-blue-50 rounded-lg"> <p class="text-blue-800 text-sm"> <strong>Note:</strong> This is a static page optimized for social media sharing.
<a href="https://lonardonifabio.github.io/tech_documents/?doc=41824d77c596fe749ee0f831d3832fc4" class="underline font-semibold">Click here to view this document in the interactive library</a>.
</p> </div> </div> </div> <!-- Service Worker Registration -->  </body> </html> 