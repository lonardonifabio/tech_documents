<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="This policy report investigates the risks associated with the adversarial use of Artificial Intelligence, with a primary focus on its application in cyber offenses and malicious activities. It builds upon the International Scientific Report on the Safety of Advanced AI, which identifies ‚Äòmaliciou..."><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/tech_documents/favicon.svg"><link rel="manifest" href="/tech_documents/manifest.json"><title>Collaboration for AI Governance: Adversarial Use of AI</title><!-- Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-G7VY771Q53"></script><!-- PWA Meta Tags --><!-- <meta name="theme-color" content="#667eea"> --><!-- <meta name="apple-mobile-web-app-capable" content="yes"> --><!-- <meta name="apple-mobile-web-app-status-bar-style" content="default"> --><!-- <meta name="apple-mobile-web-app-title" content="AI Doc Library"> --><!-- Enhanced Open Graph for LinkedIn sharing --><meta property="og:title" content="Collaboration for AI Governance: Adversarial Use of AI"><meta property="og:description" content="This policy report investigates the risks associated with the adversarial use of Artificial Intelligence, with a primary focus on its application in cyber offenses and malicious activities. It builds upon the International Scientific Report on the Safety of Advanced AI, which identifies ‚Äòmaliciou..."><meta property="og:type" content="article"><meta property="og:url" content="https://lonardonifabio.github.io/tech_documents/document/f9d5eefe1479fff0b464582a2b1473e6"><meta property="og:image" content="https://lonardonifabio.github.io/tech_documents/preview/f9d5eefe1479fff0b464582a2b1473e6.jpg"><meta property="og:image:secure_url" content="https://lonardonifabio.github.io/tech_documents/preview/f9d5eefe1479fff0b464582a2b1473e6.jpg"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="Collaboration for AI Governance: Adversarial Use of AI - AI &#38; Data Science Document Library"><meta property="og:site_name" content="AI & Data Science Document Library"><meta property="og:locale" content="en_US"><meta property="article:author" content="Fabio Lonardoni"><meta property="article:section" content="AI"><meta property="article:tag" content="AI risks, Cyber policy, Governance, Cyberspace, Artificial Intelligence, Cybercrime, International Cooperation, AI governance, adversarial use of AI, cyber offence"><meta property="article:published_time" content="2025-07-02T14:16:50.418263"><!-- LinkedIn specific meta tags --><meta property="linkedin:owner" content="Fabio Lonardoni"><!-- Additional meta for mobile sharing --><meta name="author" content="Bengio Y. et al., Michael Z√ºrn"><meta name="keywords" content="AI risks, Cyber policy, Governance, Cyberspace, Artificial Intelligence, Cybercrime, International Cooperation, AI governance, adversarial use of AI, cyber offence"><meta name="robots" content="index, follow"><link rel="canonical" href="https://lonardonifabio.github.io/tech_documents/document/f9d5eefe1479fff0b464582a2b1473e6"><!-- Additional LinkedIn optimization --><meta property="og:rich_attachment" content="true"><!-- Structured Data for better SEO --><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Collaboration for AI Governance: Adversarial Use of AI","description":"This policy report investigates the risks associated with the adversarial use of Artificial Intelligence, with a primary focus on its application in cyber offenses and malicious activities. It builds upon the International Scientific Report on the Safety of Advanced AI, which identifies ‚Äòmaliciou...","author":{"@type":"Person","name":"Bengio Y. et al., Michael Z√ºrn"},"publisher":{"@type":"Organization","name":"AI & Data Science Document Library","logo":{"@type":"ImageObject","url":"https://lonardonifabio.github.io/tech_documents/preview/f9d5eefe1479fff0b464582a2b1473e6.jpg"}},"url":"https://lonardonifabio.github.io/tech_documents/document/f9d5eefe1479fff0b464582a2b1473e6","datePublished":"2025-07-02T14:16:50.418263","image":"https://lonardonifabio.github.io/tech_documents/preview/f9d5eefe1479fff0b464582a2b1473e6.jpg","keywords":"AI risks, Cyber policy, Governance, Cyberspace, Artificial Intelligence, Cybercrime, International Cooperation, AI governance, adversarial use of AI, cyber offence"}</script><!-- Simple redirect script --><script>(function(){const mainAppUrl = "https://lonardonifabio.github.io/tech_documents/?doc=f9d5eefe1479fff0b464582a2b1473e6";

      // Manual redirect only - no automatic redirects that interfere with crawlers
      if (typeof window !== 'undefined') {
        // Add click handler for manual redirect button
        document.addEventListener('DOMContentLoaded', () => {
          const redirectButton = document.getElementById('manual-redirect');
          if (redirectButton) {
            redirectButton.addEventListener('click', () => {
              window.location.href = mainAppUrl;
            });
          }
        });
      }
    })();</script><link rel="stylesheet" href="/tech_documents/assets/_id_.B2K7fHu1.css">
<style>html{font-family:system-ui,sans-serif}::-webkit-scrollbar{width:8px}::-webkit-scrollbar-track{background:#f1f1f1}::-webkit-scrollbar-thumb{background:#c1c1c1;border-radius:4px}::-webkit-scrollbar-thumb:hover{background:#a8a8a8}
</style><script type="module">"serviceWorker"in navigator&&window.addEventListener("load",()=>{navigator.serviceWorker.register("/tech_documents/sw.js").then(e=>{console.log("SW registered: ",e)}).catch(e=>{console.log("SW registration failed: ",e)})});window.dataLayer=window.dataLayer||[];function a(){dataLayer.push(arguments)}a("js",new Date);a("config","G-G7VY771Q53");
</script></head> <body class="bg-gray-50 min-h-screen"> <!-- Fallback content for crawlers and users with JS disabled --> <div class="max-w-4xl mx-auto p-8"> <div class="bg-white rounded-lg shadow-lg p-6"> <h1 class="text-3xl font-bold text-gray-900 mb-4">Collaboration for AI Governance: Adversarial Use of AI</h1> <div class="mb-4"> <p class="text-gray-600"> <strong>Authors:</strong> Bengio Y. et al., Michael Z√ºrn </p> </div> <div class="mb-6"> <p class="text-gray-700 leading-relaxed">This policy report investigates the risks associated with the adversarial use of Artificial Intelligence, with a primary focus on its application in cyber offenses and malicious activities. It builds upon the International Scientific Report on the Safety of Advanced AI, which identifies ‚Äòmalicious use risks‚Äô encompassing a broad range of harmful applications, including large-scale information manipulation through persuasive content generation, targeted harm via fake content for fraud, extortion, and psychological abuse, and the accelerated execution of cyberattacks. The report specifically highlights the weaponization of AI in dual-use scientific fields, particularly in the biological and chemical sectors, enabling the design of novel toxins and facilitating access to related information. A key distinction is made between these deliberate, harmful uses of AI and system malfunctions or systemic risks. The report advocates for global governance structures to address these challenges, utilizing the definition of global governance provided by Michael Z√ºrn, which centers on the exercise of authority and control at an international level.  The use of ‚Äòadversarial use‚Äô is preferred over ‚Äòmalicious use‚Äô to avoid the inherent difficulties in determining intent and to broaden the scope of the analysis. This approach allows for a more comprehensive understanding of the potential threats posed by AI and informs the development of effective governance strategies. The report‚Äôs focus on global governance underscores the need for coordinated international efforts to mitigate the risks associated with the evolving landscape of AI technology.</p> </div> <div class="flex flex-wrap gap-2 mb-6"> <span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> AI risks </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Cyber policy </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Governance </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Cyberspace </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Artificial Intelligence </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Cybercrime </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> International Cooperation </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> AI governance </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> adversarial use of AI </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> cyber offence </span> </div> <div class="flex items-center justify-between text-sm text-gray-500 mb-6"> <span class="bg-green-100 text-green-800 px-3 py-1 rounded-full"> AI </span> <span class="bg-orange-100 text-orange-800 px-3 py-1 rounded-full"> Intermediate </span> </div> <div class="flex gap-4"> <a href="https://lonardonifabio.github.io/tech_documents/?doc=f9d5eefe1479fff0b464582a2b1473e6" class="bg-green-600 text-white px-6 py-2 rounded-lg hover:bg-green-700 transition-colors">
üîç View in the library powered by AI
</a> </div> <div class="mt-6 p-4 bg-blue-50 rounded-lg"> <p class="text-blue-800 text-sm"> <strong>Note:</strong> This is a static page optimized for social media sharing.
<a href="https://lonardonifabio.github.io/tech_documents/?doc=f9d5eefe1479fff0b464582a2b1473e6" class="underline font-semibold">Click here to view this document in the interactive library</a>.
</p> </div> </div> </div> <!-- Service Worker Registration -->  </body> </html> 