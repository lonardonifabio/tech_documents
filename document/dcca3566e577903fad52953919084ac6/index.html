<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="This expert report, prepared for the 48th Plenary meeting of the Convention for the Protection of Individuals with Regard to Automatic Processing of Personal Data (Convention 108) on June 17, 2025, delves into the significant privacy and data protection risks associated with Large Language Models..."><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/tech_documents/favicon.svg"><link rel="manifest" href="/tech_documents/manifest.json"><title>Expert Report on Privacy and Data Protection Risks in Large Language Models (LLMs)</title><!-- Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-G7VY771Q53"></script><!-- PWA Meta Tags --><!-- <meta name="theme-color" content="#667eea"> --><!-- <meta name="apple-mobile-web-app-capable" content="yes"> --><!-- <meta name="apple-mobile-web-app-status-bar-style" content="default"> --><!-- <meta name="apple-mobile-web-app-title" content="AI Doc Library"> --><!-- Enhanced Open Graph for LinkedIn sharing --><meta property="og:title" content="Expert Report on Privacy and Data Protection Risks in Large Language Models (LLMs)"><meta property="og:description" content="This expert report, prepared for the 48th Plenary meeting of the Convention for the Protection of Individuals with Regard to Automatic Processing of Personal Data (Convention 108) on June 17, 2025, delves into the significant privacy and data protection risks associated with Large Language Models..."><meta property="og:type" content="article"><meta property="og:url" content="https://lonardonifabio.github.io/tech_documents/document/dcca3566e577903fad52953919084ac6"><meta property="og:image" content="https://lonardonifabio.github.io/tech_documents/preview/dcca3566e577903fad52953919084ac6.jpg"><meta property="og:image:secure_url" content="https://lonardonifabio.github.io/tech_documents/preview/dcca3566e577903fad52953919084ac6.jpg"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="Expert Report on Privacy and Data Protection Risks in Large Language Models (LLMs) - AI &#38; Data Science Document Library"><meta property="og:site_name" content="AI & Data Science Document Library"><meta property="og:locale" content="en_US"><meta property="article:author" content="Fabio Lonardoni"><meta property="article:section" content="Technology"><meta property="article:tag" content="Large Language Models (LLMs), Privacy, Data Protection, Personal Data, AI lifecycle, Neural Network Architecture, Privacy Risks, Foundation Models, Post-training, Custom Use Cases"><meta property="article:published_time" content="2025-07-02T21:59:26.502413"><!-- LinkedIn specific meta tags --><meta property="linkedin:owner" content="Fabio Lonardoni"><!-- Additional meta for mobile sharing --><meta name="author" content="Isabel Barberá, Murielle Popa -Fabre"><meta name="keywords" content="Large Language Models (LLMs), Privacy, Data Protection, Personal Data, AI lifecycle, Neural Network Architecture, Privacy Risks, Foundation Models, Post-training, Custom Use Cases"><meta name="robots" content="index, follow"><link rel="canonical" href="https://lonardonifabio.github.io/tech_documents/document/dcca3566e577903fad52953919084ac6"><!-- Additional LinkedIn optimization --><meta property="og:rich_attachment" content="true"><!-- Structured Data for better SEO --><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Expert Report on Privacy and Data Protection Risks in Large Language Models (LLMs)","description":"This expert report, prepared for the 48th Plenary meeting of the Convention for the Protection of Individuals with Regard to Automatic Processing of Personal Data (Convention 108) on June 17, 2025, delves into the significant privacy and data protection risks associated with Large Language Models...","author":{"@type":"Person","name":"Isabel Barberá, Murielle Popa -Fabre"},"publisher":{"@type":"Organization","name":"AI & Data Science Document Library","logo":{"@type":"ImageObject","url":"https://lonardonifabio.github.io/tech_documents/preview/dcca3566e577903fad52953919084ac6.jpg"}},"url":"https://lonardonifabio.github.io/tech_documents/document/dcca3566e577903fad52953919084ac6","datePublished":"2025-07-02T21:59:26.502413","image":"https://lonardonifabio.github.io/tech_documents/preview/dcca3566e577903fad52953919084ac6.jpg","keywords":"Large Language Models (LLMs), Privacy, Data Protection, Personal Data, AI lifecycle, Neural Network Architecture, Privacy Risks, Foundation Models, Post-training, Custom Use Cases"}</script><!-- Simple redirect script --><script>(function(){const mainAppUrl = "https://lonardonifabio.github.io/tech_documents/?doc=dcca3566e577903fad52953919084ac6";

      // Manual redirect only - no automatic redirects that interfere with crawlers
      if (typeof window !== 'undefined') {
        // Add click handler for manual redirect button
        document.addEventListener('DOMContentLoaded', () => {
          const redirectButton = document.getElementById('manual-redirect');
          if (redirectButton) {
            redirectButton.addEventListener('click', () => {
              window.location.href = mainAppUrl;
            });
          }
        });
      }
    })();</script><link rel="stylesheet" href="/tech_documents/assets/_id_.B2K7fHu1.css">
<style>html{font-family:system-ui,sans-serif}::-webkit-scrollbar{width:8px}::-webkit-scrollbar-track{background:#f1f1f1}::-webkit-scrollbar-thumb{background:#c1c1c1;border-radius:4px}::-webkit-scrollbar-thumb:hover{background:#a8a8a8}
</style><script type="module">"serviceWorker"in navigator&&window.addEventListener("load",()=>{navigator.serviceWorker.register("/tech_documents/sw.js").then(e=>{console.log("SW registered: ",e)}).catch(e=>{console.log("SW registration failed: ",e)})});window.dataLayer=window.dataLayer||[];function a(){dataLayer.push(arguments)}a("js",new Date);a("config","G-G7VY771Q53");
</script></head> <body class="bg-gray-50 min-h-screen"> <!-- Fallback content for crawlers and users with JS disabled --> <div class="max-w-4xl mx-auto p-8"> <div class="bg-white rounded-lg shadow-lg p-6"> <h1 class="text-3xl font-bold text-gray-900 mb-4">Expert Report on Privacy and Data Protection Risks in Large Language Models (LLMs)</h1> <div class="mb-4"> <p class="text-gray-600"> <strong>Authors:</strong> Isabel Barberá, Murielle Popa -Fabre </p> </div> <div class="mb-6"> <p class="text-gray-700 leading-relaxed">This expert report, prepared for the 48th Plenary meeting of the Convention for the Protection of Individuals with Regard to Automatic Processing of Personal Data (Convention 108) on June 17, 2025, delves into the significant privacy and data protection risks associated with Large Language Models (LLMs). The report’s primary focus is on understanding how LLMs represent and process personal data, a critical concern given their increasing prevalence and capabilities. It begins with a contextual overview, outlining the Convention 108’s role and the initial landscape of LLM-based systems. The core of the report examines the internal workings of LLMs, specifically how words and data are ‘seen’ and represented within the models, including the compression techniques employed within neural network architectures.  A key section maps out the identified privacy risks within the LLM ecosystem, considering both technological evolutions and the potential for new risks. The report meticulously details various personal data extraction methods utilized by LLMs, highlighting the vulnerabilities that arise from this process. It further distinguishes between risks stemming from the models themselves versus those originating from the broader system architecture.  Crucially, the report analyzes privacy risks across the entire AI lifecycle, from development to deployment and ongoing operation.  The document emphasizes the need for technological mitigations to address these identified vulnerabilities. The report’s purpose is to inform the Convention 108 and contribute to the development of appropriate data protection standards for LLMs, acknowledging that the opinions expressed are the responsibility of the authors and do not necessarily reflect the official policy of the Council of Europe. The document is a foundational piece for understanding the complex intersection of AI, data privacy, and legal frameworks.</p> </div> <div class="flex flex-wrap gap-2 mb-6"> <span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Large Language Models (LLMs) </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Privacy </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Data Protection </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Personal Data </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> AI lifecycle </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Neural Network Architecture </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Privacy Risks </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Foundation Models </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Post-training </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Custom Use Cases </span> </div> <div class="flex items-center justify-between text-sm text-gray-500 mb-6"> <span class="bg-green-100 text-green-800 px-3 py-1 rounded-full"> Technology </span> <span class="bg-orange-100 text-orange-800 px-3 py-1 rounded-full"> Intermediate </span> </div> <div class="flex gap-4"> <a href="https://lonardonifabio.github.io/tech_documents/?doc=dcca3566e577903fad52953919084ac6" class="bg-green-600 text-white px-6 py-2 rounded-lg hover:bg-green-700 transition-colors">
🔍 View in the library powered by AI
</a> </div> <div class="mt-6 p-4 bg-blue-50 rounded-lg"> <p class="text-blue-800 text-sm"> <strong>Note:</strong> This is a static page optimized for social media sharing.
<a href="https://lonardonifabio.github.io/tech_documents/?doc=dcca3566e577903fad52953919084ac6" class="underline font-semibold">Click here to view this document in the interactive library</a>.
</p> </div> </div> </div> <!-- Service Worker Registration -->  </body> </html> 