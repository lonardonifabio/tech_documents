<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="This document, titled &#34;Foundations of Large Language Models,&#34; presents an overview of the significant advancements and underlying principles of large language models (LLMs). It highlights the origins of LLMs within the field of natural language processing (NLP) and emphasizes their revolutionary ..."><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/tech_documents/favicon.svg"><link rel="manifest" href="/tech_documents/manifest.json"><title>Foundations of Large Language Models</title><!-- Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-G7VY771Q53"></script><!-- PWA Meta Tags --><!-- <meta name="theme-color" content="#667eea"> --><!-- <meta name="apple-mobile-web-app-capable" content="yes"> --><!-- <meta name="apple-mobile-web-app-status-bar-style" content="default"> --><!-- <meta name="apple-mobile-web-app-title" content="AI Doc Library"> --><!-- Enhanced Open Graph for LinkedIn sharing --><meta property="og:title" content="Foundations of Large Language Models"><meta property="og:description" content="This document, titled &#34;Foundations of Large Language Models,&#34; presents an overview of the significant advancements and underlying principles of large language models (LLMs). It highlights the origins of LLMs within the field of natural language processing (NLP) and emphasizes their revolutionary ..."><meta property="og:type" content="article"><meta property="og:url" content="https://lonardonifabio.github.io/tech_documents/document/885dccd522487991c2f620231d5f84a3"><meta property="og:image" content="https://lonardonifabio.github.io/tech_documents/preview/885dccd522487991c2f620231d5f84a3.jpg?v=1752494956201"><meta property="og:image:secure_url" content="https://lonardonifabio.github.io/tech_documents/preview/885dccd522487991c2f620231d5f84a3.jpg?v=1752494956201"><meta property="og:image:type" content="image/svg+xml"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="Foundations of Large Language Models - AI &#38; Data Science Document Library"><meta property="og:site_name" content="AI & Data Science Document Library"><meta property="og:locale" content="en_US"><meta property="article:author" content="Fabio Lonardoni"><meta property="article:section" content="Technology"><meta property="article:tag" content="Large Language Models, Natural Language Processing, Artificial Intelligence, Knowledge Acquisition, Language Modeling, Universal Model, Prompting, Prompt Design, In-context Learning, Prompt Engineering"><meta property="article:published_time" content="2025-06-12T00:07:23.720128"><!-- LinkedIn specific meta tags --><meta property="linkedin:owner" content="Fabio Lonardoni"><!-- Additional meta for mobile sharing --><meta name="author" content="Tong Xiao, Jingbo Zhu"><meta name="keywords" content="Large Language Models, Natural Language Processing, Artificial Intelligence, Knowledge Acquisition, Language Modeling, Universal Model, Prompting, Prompt Design, In-context Learning, Prompt Engineering"><meta name="robots" content="index, follow"><link rel="canonical" href="https://lonardonifabio.github.io/tech_documents/document/885dccd522487991c2f620231d5f84a3"><!-- Additional LinkedIn optimization --><meta property="og:rich_attachment" content="true"><!-- Structured Data for better SEO --><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Foundations of Large Language Models","description":"This document, titled \"Foundations of Large Language Models,\" presents an overview of the significant advancements and underlying principles of large language models (LLMs). It highlights the origins of LLMs within the field of natural language processing (NLP) and emphasizes their revolutionary ...","author":{"@type":"Person","name":"Tong Xiao, Jingbo Zhu"},"publisher":{"@type":"Organization","name":"AI & Data Science Document Library","logo":{"@type":"ImageObject","url":"https://lonardonifabio.github.io/tech_documents/preview/885dccd522487991c2f620231d5f84a3.jpg?v=1752494956201"}},"url":"https://lonardonifabio.github.io/tech_documents/document/885dccd522487991c2f620231d5f84a3","datePublished":"2025-06-12T00:07:23.720128","image":"https://lonardonifabio.github.io/tech_documents/preview/885dccd522487991c2f620231d5f84a3.jpg?v=1752494956201","keywords":"Large Language Models, Natural Language Processing, Artificial Intelligence, Knowledge Acquisition, Language Modeling, Universal Model, Prompting, Prompt Design, In-context Learning, Prompt Engineering"}</script><!-- Simple redirect script --><script>(function(){const mainAppUrl = "https://lonardonifabio.github.io/tech_documents/?doc=885dccd522487991c2f620231d5f84a3";

      // Manual redirect only - no automatic redirects that interfere with crawlers
      if (typeof window !== 'undefined') {
        // Add click handler for manual redirect button
        document.addEventListener('DOMContentLoaded', () => {
          const redirectButton = document.getElementById('manual-redirect');
          if (redirectButton) {
            redirectButton.addEventListener('click', () => {
              window.location.href = mainAppUrl;
            });
          }
        });
      }
    })();</script><link rel="stylesheet" href="/tech_documents/assets/_id_.B2K7fHu1.css">
<style>html{font-family:system-ui,sans-serif}::-webkit-scrollbar{width:8px}::-webkit-scrollbar-track{background:#f1f1f1}::-webkit-scrollbar-thumb{background:#c1c1c1;border-radius:4px}::-webkit-scrollbar-thumb:hover{background:#a8a8a8}
</style><script type="module">"serviceWorker"in navigator&&window.addEventListener("load",()=>{navigator.serviceWorker.register("/tech_documents/sw.js").then(e=>{console.log("SW registered: ",e)}).catch(e=>{console.log("SW registration failed: ",e)})});window.dataLayer=window.dataLayer||[];function a(){dataLayer.push(arguments)}a("js",new Date);a("config","G-G7VY771Q53");
</script></head> <body class="bg-gray-50 min-h-screen"> <!-- Fallback content for crawlers and users with JS disabled --> <div class="max-w-4xl mx-auto p-8"> <div class="bg-white rounded-lg shadow-lg p-6"> <h1 class="text-3xl font-bold text-gray-900 mb-4">Foundations of Large Language Models</h1> <div class="mb-4"> <p class="text-gray-600"> <strong>Authors:</strong> Tong Xiao, Jingbo Zhu </p> </div> <div class="mb-6"> <p class="text-gray-700 leading-relaxed">This document, titled &quot;Foundations of Large Language Models,&quot; presents an overview of the significant advancements and underlying principles of large language models (LLMs). It highlights the origins of LLMs within the field of natural language processing (NLP) and emphasizes their revolutionary impact on artificial intelligence. A core insight presented is that knowledge acquisition within LLMs stems from large-scale language modeling tasks, enabling the creation of universal models capable of addressing diverse problems. The research has fundamentally shifted NLP methodologies, moving away from traditional training approaches towards leveraging the knowledge gained through these massive language models. The authors underscore the profound influence of this discovery across various related disciplines. The document also includes standard copyright and licensing information, specifying the Creative Commons Attribution-NonCommercial 4.0 Unported License, indicating that the work is distributed without warranties and subject to specific usage restrictions.  The work is produced by the NLP Lab at Northeastern University and NiuTrans Research, and the license allows for non-commercial use with attribution. The document&#39;s focus is on establishing the foundational understanding of LLMs and their transformative role in AI and NLP research.</p> </div> <div class="flex flex-wrap gap-2 mb-6"> <span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Large Language Models </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Natural Language Processing </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Artificial Intelligence </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Knowledge Acquisition </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Language Modeling </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Universal Model </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Prompting </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Prompt Design </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> In-context Learning </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Prompt Engineering </span> </div> <div class="flex items-center justify-between text-sm text-gray-500 mb-6"> <span class="bg-green-100 text-green-800 px-3 py-1 rounded-full"> Technology </span> <span class="bg-orange-100 text-orange-800 px-3 py-1 rounded-full"> Intermediate </span> </div> <div class="flex gap-4"> <a href="https://lonardonifabio.github.io/tech_documents/?doc=885dccd522487991c2f620231d5f84a3" class="bg-green-600 text-white px-6 py-2 rounded-lg hover:bg-green-700 transition-colors">
üîç View in the library powered by AI
</a> </div> <div class="mt-6 p-4 bg-blue-50 rounded-lg"> <p class="text-blue-800 text-sm"> <strong>Note:</strong> This is a static page optimized for social media sharing.
<a href="https://lonardonifabio.github.io/tech_documents/?doc=885dccd522487991c2f620231d5f84a3" class="underline font-semibold">Click here to view this document in the interactive library</a>.
</p> </div> </div> </div> <!-- Service Worker Registration -->  </body> </html> 