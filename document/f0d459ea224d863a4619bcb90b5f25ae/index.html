<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="This document provides a concise overview of several fundamental algorithms used in supervised and unsupervised learning. It focuses on the core aspects of each algorithm, including model objective, training process, regularization techniques, and computational complexity. The document begins wit..."><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/tech_documents/favicon.svg"><link rel="manifest" href="/tech_documents/manifest.json"><title>Algorithms for Supervised- and Unsupervised Learning</title><!-- Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-G7VY771Q53"></script><!-- PWA Meta Tags --><!-- <meta name="theme-color" content="#667eea"> --><!-- <meta name="apple-mobile-web-app-capable" content="yes"> --><!-- <meta name="apple-mobile-web-app-status-bar-style" content="default"> --><!-- <meta name="apple-mobile-web-app-title" content="AI Doc Library"> --><!-- Enhanced Open Graph for LinkedIn sharing --><meta property="og:title" content="Algorithms for Supervised- and Unsupervised Learning"><meta property="og:description" content="This document provides a concise overview of several fundamental algorithms used in supervised and unsupervised learning. It focuses on the core aspects of each algorithm, including model objective, training process, regularization techniques, and computational complexity. The document begins wit..."><meta property="og:type" content="article"><meta property="og:url" content="https://lonardonifabio.github.io/tech_documents/document/f0d459ea224d863a4619bcb90b5f25ae"><meta property="og:image" content="https://lonardonifabio.github.io/tech_documents/preview/f0d459ea224d863a4619bcb90b5f25ae.jpg?v=1751917030334"><meta property="og:image:secure_url" content="https://lonardonifabio.github.io/tech_documents/preview/f0d459ea224d863a4619bcb90b5f25ae.jpg?v=1751917030334"><meta property="og:image:type" content="image/svg+xml"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="Algorithms for Supervised- and Unsupervised Learning - AI &#38; Data Science Document Library"><meta property="og:site_name" content="AI & Data Science Document Library"><meta property="og:locale" content="en_US"><meta property="article:author" content="Fabio Lonardoni"><meta property="article:section" content="Machine Learning"><meta property="article:tag" content="algorithm, supervised learning, unsupervised learning, k-nearest neighbour, Euclidean distance, regularisation, likelihood, Bayes' rule, multinomial likelihood, Gaussian likelihood"><meta property="article:published_time" content="2025-06-29T15:45:00.696859"><!-- Enhanced Twitter Card --><!-- <meta name="twitter:card" content="summary_large_image"> --><!-- <meta name="twitter:title" content={title}> --><!-- <meta name="twitter:description" content={description}> --><!-- <meta name="twitter:image" content={imageUrl}> --><!-- <meta name="twitter:image:alt" content={`${doc.title || doc.filename} - AI & Data Science Document Library`}> --><!-- <meta name="twitter:site" content="@fabiolonardoni"> --><!-- <meta name="twitter:creator" content="@fabiolonardoni"> --><!-- LinkedIn specific meta tags --><meta property="linkedin:owner" content="Fabio Lonardoni"><!-- Additional meta for mobile sharing --><meta name="author" content="Unknown"><meta name="keywords" content="algorithm, supervised learning, unsupervised learning, k-nearest neighbour, Euclidean distance, regularisation, likelihood, Bayes' rule, multinomial likelihood, Gaussian likelihood"><meta name="robots" content="index, follow"><link rel="canonical" href="https://lonardonifabio.github.io/tech_documents/document/f0d459ea224d863a4619bcb90b5f25ae"><!-- Additional LinkedIn optimization --><meta property="og:rich_attachment" content="true"><!-- Structured Data for better SEO --><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Algorithms for Supervised- and Unsupervised Learning","description":"This document provides a concise overview of several fundamental algorithms used in supervised and unsupervised learning. It focuses on the core aspects of each algorithm, including model objective, training process, regularization techniques, and computational complexity. The document begins wit...","author":{"@type":"Person","name":"Unknown"},"publisher":{"@type":"Organization","name":"AI & Data Science Document Library","logo":{"@type":"ImageObject","url":"https://lonardonifabio.github.io/tech_documents/preview/f0d459ea224d863a4619bcb90b5f25ae.jpg?v=1751917030334"}},"url":"https://lonardonifabio.github.io/tech_documents/document/f0d459ea224d863a4619bcb90b5f25ae","datePublished":"2025-06-29T15:45:00.696859","image":"https://lonardonifabio.github.io/tech_documents/preview/f0d459ea224d863a4619bcb90b5f25ae.jpg?v=1751917030334","keywords":"algorithm, supervised learning, unsupervised learning, k-nearest neighbour, Euclidean distance, regularisation, likelihood, Bayes' rule, multinomial likelihood, Gaussian likelihood"}</script><!-- Simple redirect script --><script>(function(){const mainAppUrl = "https://lonardonifabio.github.io/tech_documents/?doc=f0d459ea224d863a4619bcb90b5f25ae";

      // Manual redirect only - no automatic redirects that interfere with crawlers
      if (typeof window !== 'undefined') {
        // Add click handler for manual redirect button
        document.addEventListener('DOMContentLoaded', () => {
          const redirectButton = document.getElementById('manual-redirect');
          if (redirectButton) {
            redirectButton.addEventListener('click', () => {
              window.location.href = mainAppUrl;
            });
          }
        });
      }
    })();</script><link rel="stylesheet" href="/tech_documents/assets/_id_.bQYxGZ17.css">
<style>html{font-family:system-ui,sans-serif}::-webkit-scrollbar{width:8px}::-webkit-scrollbar-track{background:#f1f1f1}::-webkit-scrollbar-thumb{background:#c1c1c1;border-radius:4px}::-webkit-scrollbar-thumb:hover{background:#a8a8a8}
</style><script type="module">"serviceWorker"in navigator&&window.addEventListener("load",()=>{navigator.serviceWorker.register("/tech_documents/sw.js").then(e=>{console.log("SW registered: ",e)}).catch(e=>{console.log("SW registration failed: ",e)})});window.dataLayer=window.dataLayer||[];function a(){dataLayer.push(arguments)}a("js",new Date);a("config","G-G7VY771Q53");
</script></head> <body class="bg-gray-50 min-h-screen"> <!-- Fallback content for crawlers and users with JS disabled --> <div class="max-w-4xl mx-auto p-8"> <div class="bg-white rounded-lg shadow-lg p-6"> <h1 class="text-3xl font-bold text-gray-900 mb-4">Algorithms for Supervised- and Unsupervised Learning</h1> <div class="mb-4"> <p class="text-gray-600"> <strong>Authors:</strong> Unknown </p> </div> <div class="mb-6"> <p class="text-gray-700 leading-relaxed">This document provides a concise overview of several fundamental algorithms used in supervised and unsupervised learning. It focuses on the core aspects of each algorithm, including model objective, training process, regularization techniques, and computational complexity. The document begins with a description of k-Nearest Neighbors (k-NN), a popular supervised learning algorithm. In k-NN, a new data point is classified based on the label of the nearest k training instances, utilizing Euclidean distance to determine proximity. The algorithm acts as a regularizer, smoothing the decision boundary as the value of &#39;k&#39; increases.  A key characteristic of k-NN is its ability to naturally identify non-linear boundaries. The document then moves on to Naive Bayes, a probabilistic classifier that leverages Bayes&#39; rule to estimate conditional probabilities.  Naive Bayes assumes feature independence, hence the name &#39;Naive.&#39; The model learns p(Ck|x) by modeling p(x|Ck) and p(Ck).  The algorithm maximizes the product of p(Ck|x) and p(x|Ck).  It employs multivariate likelihoods (Gaussian and Multinomial) for estimating probabilities. The Gaussian likelihood uses the multivariate likelihood p(x|Ck)=ÔøøD i=1logp(xi|Ck) and the Multinomial likelihood uses word counts. The document highlights the computational complexity of k-NN, noting that it requires storing all training instances and their features in memory, leading to a complexity of O(NM).  The document serves as a quick reference guide for understanding the basics of these algorithms, emphasizing their core principles and key considerations. It&#39;s a simplified explanation suitable for introductory learning or as a starting point for further exploration.</p> </div> <div class="flex flex-wrap gap-2 mb-6"> <span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> algorithm </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> supervised learning </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> unsupervised learning </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> k-nearest neighbour </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Euclidean distance </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> regularisation </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> likelihood </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Bayes&#39; rule </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> multinomial likelihood </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Gaussian likelihood </span> </div> <div class="flex items-center justify-between text-sm text-gray-500 mb-6"> <span class="bg-green-100 text-green-800 px-3 py-1 rounded-full"> Machine Learning </span> <span class="bg-orange-100 text-orange-800 px-3 py-1 rounded-full"> Intermediate </span> </div> <div class="flex gap-4"> <a href="https://lonardonifabio.github.io/tech_documents/?doc=f0d459ea224d863a4619bcb90b5f25ae" class="bg-green-600 text-white px-6 py-2 rounded-lg hover:bg-green-700 transition-colors">
üîç View in the library powered by AI
</a> </div> <div class="mt-6 p-4 bg-blue-50 rounded-lg"> <p class="text-blue-800 text-sm"> <strong>Note:</strong> This is a static page optimized for social media sharing.
<a href="https://lonardonifabio.github.io/tech_documents/?doc=f0d459ea224d863a4619bcb90b5f25ae" class="underline font-semibold">Click here to view this document in the interactive library</a>.
</p> </div> </div> </div> <!-- Service Worker Registration -->  </body> </html> 