<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="This white paper, part of the CLTC White Paper Series, presents a taxonomy of trustworthiness for artificial intelligence, directly linking its properties with risk management and the entire AI lifecycle. The document‚Äôs core focus is on establishing a structured approach to understanding and eval..."><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/tech_documents/favicon.svg"><link rel="manifest" href="/tech_documents/manifest.json"><title>A Taxonomy of Trustworthiness for Artificial Intelligence: Connecting Properties of Trustworthiness with Risk Management and the AI Lifecycle</title><!-- Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-G7VY771Q53"></script><!-- PWA Meta Tags --><!-- <meta name="theme-color" content="#667eea"> --><!-- <meta name="apple-mobile-web-app-capable" content="yes"> --><!-- <meta name="apple-mobile-web-app-status-bar-style" content="default"> --><!-- <meta name="apple-mobile-web-app-title" content="AI Doc Library"> --><!-- Enhanced Open Graph for LinkedIn sharing --><meta property="og:title" content="A Taxonomy of Trustworthiness for Artificial Intelligence: Connecting Properties of Trustworthiness with Risk Management and the AI Lifecycle"><meta property="og:description" content="This white paper, part of the CLTC White Paper Series, presents a taxonomy of trustworthiness for artificial intelligence, directly linking its properties with risk management and the entire AI lifecycle. The document‚Äôs core focus is on establishing a structured approach to understanding and eval..."><meta property="og:type" content="article"><meta property="og:url" content="https://lonardonifabio.github.io/tech_documents/document/6506473c3ed4e11535c1fb08792d3462"><meta property="og:image" content="https://lonardonifabio.github.io/tech_documents/preview/6506473c3ed4e11535c1fb08792d3462.jpg?v=1751970970308"><meta property="og:image:secure_url" content="https://lonardonifabio.github.io/tech_documents/preview/6506473c3ed4e11535c1fb08792d3462.jpg?v=1751970970308"><meta property="og:image:type" content="image/svg+xml"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="A Taxonomy of Trustworthiness for Artificial Intelligence: Connecting Properties of Trustworthiness with Risk Management and the AI Lifecycle - AI &#38; Data Science Document Library"><meta property="og:site_name" content="AI & Data Science Document Library"><meta property="og:locale" content="en_US"><meta property="article:author" content="Fabio Lonardoni"><meta property="article:section" content="AI"><meta property="article:tag" content="Trustworthiness, Artificial Intelligence, AI Risk Management Framework, NIST, AI Lifecycle, Taxonomy, AI system, bias, trustworthiness, solidarity"><meta property="article:published_time" content="2025-07-01T08:47:57.471390"><!-- Enhanced Twitter Card --><!-- <meta name="twitter:card" content="summary_large_image"> --><!-- <meta name="twitter:title" content={title}> --><!-- <meta name="twitter:description" content={description}> --><!-- <meta name="twitter:image" content={imageUrl}> --><!-- <meta name="twitter:image:alt" content={`${doc.title || doc.filename} - AI & Data Science Document Library`}> --><!-- <meta name="twitter:site" content="@fabiolonardoni"> --><!-- <meta name="twitter:creator" content="@fabiolonardoni"> --><!-- LinkedIn specific meta tags --><meta property="linkedin:owner" content="Fabio Lonardoni"><!-- Additional meta for mobile sharing --><meta name="author" content="Jessica Newman, UC Berkeley Center for Long-Term Cybersecurity"><meta name="keywords" content="Trustworthiness, Artificial Intelligence, AI Risk Management Framework, NIST, AI Lifecycle, Taxonomy, AI system, bias, trustworthiness, solidarity"><meta name="robots" content="index, follow"><link rel="canonical" href="https://lonardonifabio.github.io/tech_documents/document/6506473c3ed4e11535c1fb08792d3462"><!-- Additional LinkedIn optimization --><meta property="og:rich_attachment" content="true"><!-- Structured Data for better SEO --><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"A Taxonomy of Trustworthiness for Artificial Intelligence: Connecting Properties of Trustworthiness with Risk Management and the AI Lifecycle","description":"This white paper, part of the CLTC White Paper Series, presents a taxonomy of trustworthiness for artificial intelligence, directly linking its properties with risk management and the entire AI lifecycle. The document‚Äôs core focus is on establishing a structured approach to understanding and eval...","author":{"@type":"Person","name":"Jessica Newman, UC Berkeley Center for Long-Term Cybersecurity"},"publisher":{"@type":"Organization","name":"AI & Data Science Document Library","logo":{"@type":"ImageObject","url":"https://lonardonifabio.github.io/tech_documents/preview/6506473c3ed4e11535c1fb08792d3462.jpg?v=1751970970308"}},"url":"https://lonardonifabio.github.io/tech_documents/document/6506473c3ed4e11535c1fb08792d3462","datePublished":"2025-07-01T08:47:57.471390","image":"https://lonardonifabio.github.io/tech_documents/preview/6506473c3ed4e11535c1fb08792d3462.jpg?v=1751970970308","keywords":"Trustworthiness, Artificial Intelligence, AI Risk Management Framework, NIST, AI Lifecycle, Taxonomy, AI system, bias, trustworthiness, solidarity"}</script><!-- Simple redirect script --><script>(function(){const mainAppUrl = "https://lonardonifabio.github.io/tech_documents/?doc=6506473c3ed4e11535c1fb08792d3462";

      // Manual redirect only - no automatic redirects that interfere with crawlers
      if (typeof window !== 'undefined') {
        // Add click handler for manual redirect button
        document.addEventListener('DOMContentLoaded', () => {
          const redirectButton = document.getElementById('manual-redirect');
          if (redirectButton) {
            redirectButton.addEventListener('click', () => {
              window.location.href = mainAppUrl;
            });
          }
        });
      }
    })();</script><link rel="stylesheet" href="/tech_documents/assets/_id_.B2K7fHu1.css">
<style>html{font-family:system-ui,sans-serif}::-webkit-scrollbar{width:8px}::-webkit-scrollbar-track{background:#f1f1f1}::-webkit-scrollbar-thumb{background:#c1c1c1;border-radius:4px}::-webkit-scrollbar-thumb:hover{background:#a8a8a8}
</style><script type="module">"serviceWorker"in navigator&&window.addEventListener("load",()=>{navigator.serviceWorker.register("/tech_documents/sw.js").then(e=>{console.log("SW registered: ",e)}).catch(e=>{console.log("SW registration failed: ",e)})});window.dataLayer=window.dataLayer||[];function a(){dataLayer.push(arguments)}a("js",new Date);a("config","G-G7VY771Q53");
</script></head> <body class="bg-gray-50 min-h-screen"> <!-- Fallback content for crawlers and users with JS disabled --> <div class="max-w-4xl mx-auto p-8"> <div class="bg-white rounded-lg shadow-lg p-6"> <h1 class="text-3xl font-bold text-gray-900 mb-4">A Taxonomy of Trustworthiness for Artificial Intelligence: Connecting Properties of Trustworthiness with Risk Management and the AI Lifecycle</h1> <div class="mb-4"> <p class="text-gray-600"> <strong>Authors:</strong> Jessica Newman, UC Berkeley Center for Long-Term Cybersecurity </p> </div> <div class="mb-6"> <p class="text-gray-700 leading-relaxed">This white paper, part of the CLTC White Paper Series, presents a taxonomy of trustworthiness for artificial intelligence, directly linking its properties with risk management and the entire AI lifecycle. The document‚Äôs core focus is on establishing a structured approach to understanding and evaluating the trustworthiness of AI systems. It begins with an introduction to the concept of ‚Äòtrustworthy AI,‚Äô referencing the National Institute of Standards and Technology (NIST) AI Risk Management Framework (RMF) as a foundational element. The paper comprehensively analyzes existing frameworks for trustworthy AI, which served as the basis for this work. A key contribution is the introduction of the concept of ‚Äòproperties of trustworthiness‚Äô for AI, offering a detailed categorization of attributes that contribute to a system‚Äôs trustworthiness. The taxonomy is designed to be applicable across the AI lifecycle, from development to deployment and ongoing monitoring.  The paper includes an appendix detailing connections to international AI standards and a comprehensive list of the properties of trustworthiness, deliberately avoiding segmentation by lifecycle stage to facilitate a holistic understanding.  The document‚Äôs purpose is to provide a practical tool for organizations and researchers seeking to build and deploy AI systems that are demonstrably reliable, safe, and aligned with ethical considerations.  It emphasizes the importance of proactively managing risks associated with AI and integrating trustworthiness assessments into every stage of the AI development process. The white paper‚Äôs ultimate goal is to foster a more robust and responsible AI ecosystem.</p> </div> <div class="flex flex-wrap gap-2 mb-6"> <span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Trustworthiness </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Artificial Intelligence </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> AI Risk Management Framework </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> NIST </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> AI Lifecycle </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Taxonomy </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> AI system </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> bias </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> trustworthiness </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> solidarity </span> </div> <div class="flex items-center justify-between text-sm text-gray-500 mb-6"> <span class="bg-green-100 text-green-800 px-3 py-1 rounded-full"> AI </span> <span class="bg-orange-100 text-orange-800 px-3 py-1 rounded-full"> Intermediate </span> </div> <div class="flex gap-4"> <a href="https://lonardonifabio.github.io/tech_documents/?doc=6506473c3ed4e11535c1fb08792d3462" class="bg-green-600 text-white px-6 py-2 rounded-lg hover:bg-green-700 transition-colors">
üîç View in the library powered by AI
</a> </div> <div class="mt-6 p-4 bg-blue-50 rounded-lg"> <p class="text-blue-800 text-sm"> <strong>Note:</strong> This is a static page optimized for social media sharing.
<a href="https://lonardonifabio.github.io/tech_documents/?doc=6506473c3ed4e11535c1fb08792d3462" class="underline font-semibold">Click here to view this document in the interactive library</a>.
</p> </div> </div> </div> <!-- Service Worker Registration -->  </body> </html> 