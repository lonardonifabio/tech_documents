<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="This report details Google DeepMind’s efforts to assess and enhance the adversarial robustness of the Gemini language model. The research focuses on mitigating the risk posed by indirect prompt injections, a sophisticated attack vector where malicious instructions are embedded within untrusted da..."><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/tech_documents/favicon.svg"><link rel="manifest" href="/tech_documents/manifest.json"><title>Lessons from Defending Gemini Against Indirect Prompt Injections</title><!-- Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-G7VY771Q53"></script><!-- PWA Meta Tags --><!-- <meta name="theme-color" content="#667eea"> --><!-- <meta name="apple-mobile-web-app-capable" content="yes"> --><!-- <meta name="apple-mobile-web-app-status-bar-style" content="default"> --><!-- <meta name="apple-mobile-web-app-title" content="AI Doc Library"> --><!-- Enhanced Open Graph for LinkedIn sharing --><meta property="og:title" content="Lessons from Defending Gemini Against Indirect Prompt Injections"><meta property="og:description" content="This report details Google DeepMind’s efforts to assess and enhance the adversarial robustness of the Gemini language model. The research focuses on mitigating the risk posed by indirect prompt injections, a sophisticated attack vector where malicious instructions are embedded within untrusted da..."><meta property="og:type" content="article"><meta property="og:url" content="https://lonardonifabio.github.io/tech_documents/document/01e5924d7872932ae603b5fccc8bbe5a"><meta property="og:image" content="https://lonardonifabio.github.io/tech_documents/previews/01e5924d7872932ae603b5fccc8bbe5a.jpg?v=1752494668660"><meta property="og:image:secure_url" content="https://lonardonifabio.github.io/tech_documents/previews/01e5924d7872932ae603b5fccc8bbe5a.jpg?v=1752494668660"><meta property="og:image:type" content="image/svg+xml"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="Lessons from Defending Gemini Against Indirect Prompt Injections - AI &#38; Data Science Document Library"><meta property="og:site_name" content="AI & Data Science Document Library"><meta property="og:locale" content="en_US"><meta property="article:author" content="Fabio Lonardoni"><meta property="article:section" content="Technology"><meta property="article:tag" content="Gemini, Indirect Prompt Injections, Adversarial Robustness, Function-calling, Tool-use, Attack Techniques, indirect prompt injections, adversarial training, adaptive evaluation, model capabilities"><meta property="article:published_time" content="2025-07-02T21:59:26.726414"><!-- LinkedIn specific meta tags --><meta property="linkedin:owner" content="Fabio Lonardoni"><!-- Additional meta for mobile sharing --><meta name="author" content="Chongyang Shi, Sharon Lin, Shuang Song, Jamie Hayes, Ilia Shumailov, Itay Yona, Juliette Pluto, Aneesh Pappu, Christopher A. Choquette-Choo, Milad Nasr, Chawin Sitawarin, Gena Gibson, Andreas Terzis, John &#34;Four&#34; Flynn"><meta name="keywords" content="Gemini, Indirect Prompt Injections, Adversarial Robustness, Function-calling, Tool-use, Attack Techniques, indirect prompt injections, adversarial training, adaptive evaluation, model capabilities"><meta name="robots" content="index, follow"><link rel="canonical" href="https://lonardonifabio.github.io/tech_documents/document/01e5924d7872932ae603b5fccc8bbe5a"><!-- Additional LinkedIn optimization --><meta property="og:rich_attachment" content="true"><!-- Structured Data for better SEO --><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Lessons from Defending Gemini Against Indirect Prompt Injections","description":"This report details Google DeepMind’s efforts to assess and enhance the adversarial robustness of the Gemini language model. The research focuses on mitigating the risk posed by indirect prompt injections, a sophisticated attack vector where malicious instructions are embedded within untrusted da...","author":{"@type":"Person","name":"Chongyang Shi, Sharon Lin, Shuang Song, Jamie Hayes, Ilia Shumailov, Itay Yona, Juliette Pluto, Aneesh Pappu, Christopher A. Choquette-Choo, Milad Nasr, Chawin Sitawarin, Gena Gibson, Andreas Terzis, John \"Four\" Flynn"},"publisher":{"@type":"Organization","name":"AI & Data Science Document Library","logo":{"@type":"ImageObject","url":"https://lonardonifabio.github.io/tech_documents/previews/01e5924d7872932ae603b5fccc8bbe5a.jpg?v=1752494668660"}},"url":"https://lonardonifabio.github.io/tech_documents/document/01e5924d7872932ae603b5fccc8bbe5a","datePublished":"2025-07-02T21:59:26.726414","image":"https://lonardonifabio.github.io/tech_documents/previews/01e5924d7872932ae603b5fccc8bbe5a.jpg?v=1752494668660","keywords":"Gemini, Indirect Prompt Injections, Adversarial Robustness, Function-calling, Tool-use, Attack Techniques, indirect prompt injections, adversarial training, adaptive evaluation, model capabilities"}</script><!-- Simple redirect script --><script>(function(){const mainAppUrl = "https://lonardonifabio.github.io/tech_documents/?doc=01e5924d7872932ae603b5fccc8bbe5a";

      // Manual redirect only - no automatic redirects that interfere with crawlers
      if (typeof window !== 'undefined') {
        // Add click handler for manual redirect button
        document.addEventListener('DOMContentLoaded', () => {
          const redirectButton = document.getElementById('manual-redirect');
          if (redirectButton) {
            redirectButton.addEventListener('click', () => {
              window.location.href = mainAppUrl;
            });
          }
        });
      }
    })();</script><link rel="stylesheet" href="/tech_documents/assets/_id_.B2K7fHu1.css">
<style>html{font-family:system-ui,sans-serif}::-webkit-scrollbar{width:8px}::-webkit-scrollbar-track{background:#f1f1f1}::-webkit-scrollbar-thumb{background:#c1c1c1;border-radius:4px}::-webkit-scrollbar-thumb:hover{background:#a8a8a8}
</style><script type="module">"serviceWorker"in navigator&&window.addEventListener("load",()=>{navigator.serviceWorker.register("/tech_documents/sw.js").then(e=>{console.log("SW registered: ",e)}).catch(e=>{console.log("SW registration failed: ",e)})});window.dataLayer=window.dataLayer||[];function a(){dataLayer.push(arguments)}a("js",new Date);a("config","G-G7VY771Q53");
</script></head> <body class="bg-gray-50 min-h-screen"> <!-- Fallback content for crawlers and users with JS disabled --> <div class="max-w-4xl mx-auto p-8"> <div class="bg-white rounded-lg shadow-lg p-6"> <h1 class="text-3xl font-bold text-gray-900 mb-4">Lessons from Defending Gemini Against Indirect Prompt Injections</h1> <div class="mb-4"> <p class="text-gray-600"> <strong>Authors:</strong> Chongyang Shi, Sharon Lin, Shuang Song, Jamie Hayes, Ilia Shumailov, Itay Yona, Juliette Pluto, Aneesh Pappu, Christopher A. Choquette-Choo, Milad Nasr, Chawin Sitawarin, Gena Gibson, Andreas Terzis, John &quot;Four&quot; Flynn </p> </div> <div class="mb-6"> <p class="text-gray-700 leading-relaxed">This report details Google DeepMind’s efforts to assess and enhance the adversarial robustness of the Gemini language model. The research focuses on mitigating the risk posed by indirect prompt injections, a sophisticated attack vector where malicious instructions are embedded within untrusted data provided to Gemini. The core of the investigation involves a continuous adversarial evaluation framework that utilizes adaptive attack techniques to probe Gemini’s resilience against manipulation. This framework tests past, current, and future versions of Gemini, allowing for proactive identification and remediation of vulnerabilities. The study highlights the importance of ongoing evaluation and adaptation in securing models that increasingly rely on external data and tool usage. The report outlines the methodology employed, including the deployment of a suite of attack techniques designed to simulate realistic adversarial behavior. The findings directly contribute to making Gemini more resistant to manipulation and safeguard user data and permissions. The research underscores the need for robust defenses against attacks that exploit function-calling and tool-use capabilities, particularly when interacting with untrusted data sources. The continuous evaluation process is presented as a critical component of Gemini’s development, ensuring its reliability and security in a world where models are increasingly entrusted with sensitive tasks and access to user information. The document provides a structured approach to adversarial testing, emphasizing the dynamic nature of threat landscapes and the necessity for adaptive security measures. The report’s insights are relevant to anyone developing or deploying large language models, particularly those operating in environments where data integrity and user privacy are paramount concerns.</p> </div> <div class="flex flex-wrap gap-2 mb-6"> <span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Gemini </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Indirect Prompt Injections </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Adversarial Robustness </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Function-calling </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Tool-use </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Attack Techniques </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> indirect prompt injections </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> adversarial training </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> adaptive evaluation </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> model capabilities </span> </div> <div class="flex items-center justify-between text-sm text-gray-500 mb-6"> <span class="bg-green-100 text-green-800 px-3 py-1 rounded-full"> Technology </span> <span class="bg-orange-100 text-orange-800 px-3 py-1 rounded-full"> Intermediate </span> </div> <div class="flex gap-4"> <a href="https://lonardonifabio.github.io/tech_documents/?doc=01e5924d7872932ae603b5fccc8bbe5a" class="bg-green-600 text-white px-6 py-2 rounded-lg hover:bg-green-700 transition-colors">
🔍 View in the library powered by AI
</a> </div> <div class="mt-6 p-4 bg-blue-50 rounded-lg"> <p class="text-blue-800 text-sm"> <strong>Note:</strong> This is a static page optimized for social media sharing.
<a href="https://lonardonifabio.github.io/tech_documents/?doc=01e5924d7872932ae603b5fccc8bbe5a" class="underline font-semibold">Click here to view this document in the interactive library</a>.
</p> </div> </div> </div> <!-- Service Worker Registration -->  </body> </html> 