<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="This document, published by the National Institute of Standards and Technology (NIST), provides a comprehensive taxonomy and terminology related to adversarial machine learning attacks and their corresponding mitigations.  It’s a crucial resource for researchers, practitioners, and policymakers i..."><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/tech_documents/favicon.svg"><link rel="manifest" href="/tech_documents/manifest.json"><title>NIST Trustworthy and Responsible AI NIST AI 100-2e2025 Adversarial Machine Learning A Taxonomy and Terminology of Attacks and Mitigations</title><!-- Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-G7VY771Q53"></script><!-- PWA Meta Tags --><!-- <meta name="theme-color" content="#667eea"> --><!-- <meta name="apple-mobile-web-app-capable" content="yes"> --><!-- <meta name="apple-mobile-web-app-status-bar-style" content="default"> --><!-- <meta name="apple-mobile-web-app-title" content="AI Doc Library"> --><!-- Enhanced Open Graph for LinkedIn sharing --><meta property="og:title" content="NIST Trustworthy and Responsible AI NIST AI 100-2e2025 Adversarial Machine Learning A Taxonomy and Terminology of Attacks and Mitigations"><meta property="og:description" content="This document, published by the National Institute of Standards and Technology (NIST), provides a comprehensive taxonomy and terminology related to adversarial machine learning attacks and their corresponding mitigations.  It’s a crucial resource for researchers, practitioners, and policymakers i..."><meta property="og:type" content="article"><meta property="og:url" content="https://lonardonifabio.github.io/tech_documents/document/2c5334041419e90fa983e2b098a44614"><meta property="og:image" content="https://lonardonifabio.github.io/tech_documents/previews/2c5334041419e90fa983e2b098a44614.jpg?v=1751998441098"><meta property="og:image:secure_url" content="https://lonardonifabio.github.io/tech_documents/previews/2c5334041419e90fa983e2b098a44614.jpg?v=1751998441098"><meta property="og:image:type" content="image/svg+xml"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="NIST Trustworthy and Responsible AI NIST AI 100-2e2025 Adversarial Machine Learning A Taxonomy and Terminology of Attacks and Mitigations - AI &#38; Data Science Document Library"><meta property="og:site_name" content="AI & Data Science Document Library"><meta property="og:locale" content="en_US"><meta property="article:author" content="Fabio Lonardoni"><meta property="article:section" content="Machine Learning"><meta property="article:tag" content="AI, Adversarial Machine Learning, Taxonomy, Terminology, Attacks, Mitigations, NIST, Trustworthy AI, Responsible AI, attacker capabilities"><meta property="article:published_time" content="2025-06-28T18:57:53.756721"><!-- LinkedIn specific meta tags --><meta property="linkedin:owner" content="Fabio Lonardoni"><!-- Additional meta for mobile sharing --><meta name="author" content="Alina Oprea, Apostol Vassilev, Maia Hamin, Alie Fordyce, Hyrum Anderson, Xander Davies"><meta name="keywords" content="AI, Adversarial Machine Learning, Taxonomy, Terminology, Attacks, Mitigations, NIST, Trustworthy AI, Responsible AI, attacker capabilities"><meta name="robots" content="index, follow"><link rel="canonical" href="https://lonardonifabio.github.io/tech_documents/document/2c5334041419e90fa983e2b098a44614"><!-- Additional LinkedIn optimization --><meta property="og:rich_attachment" content="true"><!-- Structured Data for better SEO --><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"NIST Trustworthy and Responsible AI NIST AI 100-2e2025 Adversarial Machine Learning A Taxonomy and Terminology of Attacks and Mitigations","description":"This document, published by the National Institute of Standards and Technology (NIST), provides a comprehensive taxonomy and terminology related to adversarial machine learning attacks and their corresponding mitigations.  It’s a crucial resource for researchers, practitioners, and policymakers i...","author":{"@type":"Person","name":"Alina Oprea, Apostol Vassilev, Maia Hamin, Alie Fordyce, Hyrum Anderson, Xander Davies"},"publisher":{"@type":"Organization","name":"AI & Data Science Document Library","logo":{"@type":"ImageObject","url":"https://lonardonifabio.github.io/tech_documents/previews/2c5334041419e90fa983e2b098a44614.jpg?v=1751998441098"}},"url":"https://lonardonifabio.github.io/tech_documents/document/2c5334041419e90fa983e2b098a44614","datePublished":"2025-06-28T18:57:53.756721","image":"https://lonardonifabio.github.io/tech_documents/previews/2c5334041419e90fa983e2b098a44614.jpg?v=1751998441098","keywords":"AI, Adversarial Machine Learning, Taxonomy, Terminology, Attacks, Mitigations, NIST, Trustworthy AI, Responsible AI, attacker capabilities"}</script><!-- Simple redirect script --><script>(function(){const mainAppUrl = "https://lonardonifabio.github.io/tech_documents/?doc=2c5334041419e90fa983e2b098a44614";

      // Manual redirect only - no automatic redirects that interfere with crawlers
      if (typeof window !== 'undefined') {
        // Add click handler for manual redirect button
        document.addEventListener('DOMContentLoaded', () => {
          const redirectButton = document.getElementById('manual-redirect');
          if (redirectButton) {
            redirectButton.addEventListener('click', () => {
              window.location.href = mainAppUrl;
            });
          }
        });
      }
    })();</script><link rel="stylesheet" href="/tech_documents/assets/_id_.B2K7fHu1.css">
<style>html{font-family:system-ui,sans-serif}::-webkit-scrollbar{width:8px}::-webkit-scrollbar-track{background:#f1f1f1}::-webkit-scrollbar-thumb{background:#c1c1c1;border-radius:4px}::-webkit-scrollbar-thumb:hover{background:#a8a8a8}
</style><script type="module">"serviceWorker"in navigator&&window.addEventListener("load",()=>{navigator.serviceWorker.register("/tech_documents/sw.js").then(e=>{console.log("SW registered: ",e)}).catch(e=>{console.log("SW registration failed: ",e)})});window.dataLayer=window.dataLayer||[];function a(){dataLayer.push(arguments)}a("js",new Date);a("config","G-G7VY771Q53");
</script></head> <body class="bg-gray-50 min-h-screen"> <!-- Fallback content for crawlers and users with JS disabled --> <div class="max-w-4xl mx-auto p-8"> <div class="bg-white rounded-lg shadow-lg p-6"> <h1 class="text-3xl font-bold text-gray-900 mb-4">NIST Trustworthy and Responsible AI NIST AI 100-2e2025 Adversarial Machine Learning A Taxonomy and Terminology of Attacks and Mitigations</h1> <div class="mb-4"> <p class="text-gray-600"> <strong>Authors:</strong> Alina Oprea, Apostol Vassilev, Maia Hamin, Alie Fordyce, Hyrum Anderson, Xander Davies </p> </div> <div class="mb-6"> <p class="text-gray-700 leading-relaxed">This document, published by the National Institute of Standards and Technology (NIST), provides a comprehensive taxonomy and terminology related to adversarial machine learning attacks and their corresponding mitigations.  It’s a crucial resource for researchers, practitioners, and policymakers involved in ensuring the trustworthiness and responsible development of AI systems. The publication, titled ‘NIST AI 100-2e2025 Adversarial Machine Learning A Taxonomy and Terminology of Attacks and Mitigations,’ focuses on systematically categorizing various attack techniques targeting machine learning models, including those designed to exploit vulnerabilities in training data, model architecture, or inference processes.  The document meticulously defines these attacks, detailing their methodologies and potential impact.  Furthermore, it outlines a range of mitigation strategies, offering practical approaches to defend against these threats.  The work is grounded in a rigorous, technical approach, aiming to provide a standardized framework for understanding and addressing the growing concern of adversarial machine learning.  The authors, representing institutions like the U.S. AI Safety Institute, Cisco, and the U.K. AI Security Institute, demonstrate a multi-faceted perspective on the problem.  The document’s free availability through the NIST website (doi.org/10.6028/NIST.AI.100-2e2025) underscores NIST&#39;s commitment to promoting responsible AI practices.  The inclusion of commercial equipment and software is noted for the purpose of accurately describing experimental procedures, with a clear disclaimer that this does not constitute an endorsement.  The document is a key contribution to the ongoing effort to build robust and reliable AI systems capable of withstanding malicious attacks. It’s a vital resource for anyone seeking to understand the landscape of adversarial machine learning and develop effective defenses.</p> </div> <div class="flex flex-wrap gap-2 mb-6"> <span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> AI </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Adversarial Machine Learning </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Taxonomy </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Terminology </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Attacks </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Mitigations </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> NIST </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Trustworthy AI </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Responsible AI </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> attacker capabilities </span> </div> <div class="flex items-center justify-between text-sm text-gray-500 mb-6"> <span class="bg-green-100 text-green-800 px-3 py-1 rounded-full"> Machine Learning </span> <span class="bg-orange-100 text-orange-800 px-3 py-1 rounded-full"> Intermediate </span> </div> <div class="flex gap-4"> <a href="https://lonardonifabio.github.io/tech_documents/?doc=2c5334041419e90fa983e2b098a44614" class="bg-green-600 text-white px-6 py-2 rounded-lg hover:bg-green-700 transition-colors">
🔍 View in the library powered by AI
</a> </div> <div class="mt-6 p-4 bg-blue-50 rounded-lg"> <p class="text-blue-800 text-sm"> <strong>Note:</strong> This is a static page optimized for social media sharing.
<a href="https://lonardonifabio.github.io/tech_documents/?doc=2c5334041419e90fa983e2b098a44614" class="underline font-semibold">Click here to view this document in the interactive library</a>.
</p> </div> </div> </div> <!-- Service Worker Registration -->  </body> </html> 