<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="This document excerpt details an experiment designed to investigate the effectiveness of Large Language Model (LLM) persuaders compared to human persuaders in influencing participant responses to a 10-question interactive quiz. The core of the study centers around examining how LLMs can persuade ..."><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/tech_documents/favicon.svg"><link rel="manifest" href="/tech_documents/manifest.json"><title>Interactive Experiment Comparing LLM and Human Persuasion</title><!-- Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-G7VY771Q53"></script><!-- PWA Meta Tags --><!-- <meta name="theme-color" content="#667eea"> --><!-- <meta name="apple-mobile-web-app-capable" content="yes"> --><!-- <meta name="apple-mobile-web-app-status-bar-style" content="default"> --><!-- <meta name="apple-mobile-web-app-title" content="AI Doc Library"> --><!-- Enhanced Open Graph for LinkedIn sharing --><meta property="og:title" content="Interactive Experiment Comparing LLM and Human Persuasion"><meta property="og:description" content="This document excerpt details an experiment designed to investigate the effectiveness of Large Language Model (LLM) persuaders compared to human persuaders in influencing participant responses to a 10-question interactive quiz. The core of the study centers around examining how LLMs can persuade ..."><meta property="og:type" content="article"><meta property="og:url" content="https://lonardonifabio.github.io/tech_documents/document/6f23d74ca313dc71eeef463c2b14216a"><meta property="og:image" content="https://lonardonifabio.github.io/tech_documents/preview/6f23d74ca313dc71eeef463c2b14216a.jpg?v=1752494956367"><meta property="og:image:secure_url" content="https://lonardonifabio.github.io/tech_documents/preview/6f23d74ca313dc71eeef463c2b14216a.jpg?v=1752494956367"><meta property="og:image:type" content="image/svg+xml"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="Interactive Experiment Comparing LLM and Human Persuasion - AI &#38; Data Science Document Library"><meta property="og:site_name" content="AI & Data Science Document Library"><meta property="og:locale" content="en_US"><meta property="article:author" content="Fabio Lonardoni"><meta property="article:section" content="Technology"><meta property="article:tag" content="Large Language Models, Persuasion, Human Persuaders, Incentivized, interactive quiz, LLM persuaders, human persuaders, persuasion, empirical experiment, behavioral experiments"><meta property="article:published_time" content="2025-06-08T22:35:05"><!-- LinkedIn specific meta tags --><meta property="linkedin:owner" content="Fabio Lonardoni"><!-- Additional meta for mobile sharing --><meta name="author" content=""><meta name="keywords" content="Large Language Models, Persuasion, Human Persuaders, Incentivized, interactive quiz, LLM persuaders, human persuaders, persuasion, empirical experiment, behavioral experiments"><meta name="robots" content="index, follow"><link rel="canonical" href="https://lonardonifabio.github.io/tech_documents/document/6f23d74ca313dc71eeef463c2b14216a"><!-- Additional LinkedIn optimization --><meta property="og:rich_attachment" content="true"><!-- Structured Data for better SEO --><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Interactive Experiment Comparing LLM and Human Persuasion","description":"This document excerpt details an experiment designed to investigate the effectiveness of Large Language Model (LLM) persuaders compared to human persuaders in influencing participant responses to a 10-question interactive quiz. The core of the study centers around examining how LLMs can persuade ...","author":{"@type":"Person","name":""},"publisher":{"@type":"Organization","name":"AI & Data Science Document Library","logo":{"@type":"ImageObject","url":"https://lonardonifabio.github.io/tech_documents/preview/6f23d74ca313dc71eeef463c2b14216a.jpg?v=1752494956367"}},"url":"https://lonardonifabio.github.io/tech_documents/document/6f23d74ca313dc71eeef463c2b14216a","datePublished":"2025-06-08T22:35:05","image":"https://lonardonifabio.github.io/tech_documents/preview/6f23d74ca313dc71eeef463c2b14216a.jpg?v=1752494956367","keywords":"Large Language Models, Persuasion, Human Persuaders, Incentivized, interactive quiz, LLM persuaders, human persuaders, persuasion, empirical experiment, behavioral experiments"}</script><!-- Simple redirect script --><script>(function(){const mainAppUrl = "https://lonardonifabio.github.io/tech_documents/?doc=6f23d74ca313dc71eeef463c2b14216a";

      // Manual redirect only - no automatic redirects that interfere with crawlers
      if (typeof window !== 'undefined') {
        // Add click handler for manual redirect button
        document.addEventListener('DOMContentLoaded', () => {
          const redirectButton = document.getElementById('manual-redirect');
          if (redirectButton) {
            redirectButton.addEventListener('click', () => {
              window.location.href = mainAppUrl;
            });
          }
        });
      }
    })();</script><link rel="stylesheet" href="/tech_documents/assets/_id_.B2K7fHu1.css">
<style>html{font-family:system-ui,sans-serif}::-webkit-scrollbar{width:8px}::-webkit-scrollbar-track{background:#f1f1f1}::-webkit-scrollbar-thumb{background:#c1c1c1;border-radius:4px}::-webkit-scrollbar-thumb:hover{background:#a8a8a8}
</style><script type="module">"serviceWorker"in navigator&&window.addEventListener("load",()=>{navigator.serviceWorker.register("/tech_documents/sw.js").then(e=>{console.log("SW registered: ",e)}).catch(e=>{console.log("SW registration failed: ",e)})});window.dataLayer=window.dataLayer||[];function a(){dataLayer.push(arguments)}a("js",new Date);a("config","G-G7VY771Q53");
</script></head> <body class="bg-gray-50 min-h-screen"> <!-- Fallback content for crawlers and users with JS disabled --> <div class="max-w-4xl mx-auto p-8"> <div class="bg-white rounded-lg shadow-lg p-6"> <h1 class="text-3xl font-bold text-gray-900 mb-4">Interactive Experiment Comparing LLM and Human Persuasion</h1>  <div class="mb-6"> <p class="text-gray-700 leading-relaxed">This document excerpt details an experiment designed to investigate the effectiveness of Large Language Model (LLM) persuaders compared to human persuaders in influencing participant responses to a 10-question interactive quiz. The core of the study centers around examining how LLMs can persuade individuals to provide correct or incorrect answers. A key element of the design involves ‘verifiable questions,’ encompassing both trivia and forecasting questions about near-future events, enabling researchers to assess both truthful and deceptive persuasion attempts.  The experiment incorporates a dual-reward system, providing incentives for both human persuaders (when quiz takers answered as directed) and quiz takers themselves (for correct answers), creating a competitive environment and allowing for a direct comparison between LLMs and humans.  Five primary research questions are addressed: (1) Do LLMs demonstrate greater persuasive power than humans? (2) Do LLMs effectively steer participants toward correct answers compared to humans? (3) Do LLMs successfully influence participants to provide incorrect answers relative to human persuaders? (4) In scenarios of truthful persuasion, do LLMs or humans improve quiz takers’ accuracy and, consequently, their earnings? And (5) In deceptive persuasion, do LLMs or humans reduce quiz takers’ accuracy and earnings? The study utilizes a web-based platform built on Empirica for conducting large-scale concurrent behavioral experiments. Random assignment of participants to conditions is a central component of the methodology. The research aims to provide empirical evidence regarding the capabilities and limitations of LLMs in persuasive communication, specifically within the context of interactive quizzes and the manipulation of human decision-making. The design incorporates a robust reward system to maximize participant engagement and provide a clear benchmark for evaluating the performance of both LLM and human persuaders. The use of verifiable questions and dual rewards allows for a nuanced analysis of persuasive strategies and their impact on participant behavior. The document highlights the experimental pipeline and the framework used for data collection, setting the stage for a detailed examination of the results.</p> </div> <div class="flex flex-wrap gap-2 mb-6"> <span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Large Language Models </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Persuasion </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Human Persuaders </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Incentivized </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> interactive quiz </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> LLM persuaders </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> human persuaders </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> persuasion </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> empirical experiment </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> behavioral experiments </span> </div> <div class="flex items-center justify-between text-sm text-gray-500 mb-6"> <span class="bg-green-100 text-green-800 px-3 py-1 rounded-full"> Technology </span> <span class="bg-orange-100 text-orange-800 px-3 py-1 rounded-full"> Intermediate </span> </div> <div class="flex gap-4"> <a href="https://lonardonifabio.github.io/tech_documents/?doc=6f23d74ca313dc71eeef463c2b14216a" class="bg-green-600 text-white px-6 py-2 rounded-lg hover:bg-green-700 transition-colors">
🔍 View in the library powered by AI
</a> </div> <div class="mt-6 p-4 bg-blue-50 rounded-lg"> <p class="text-blue-800 text-sm"> <strong>Note:</strong> This is a static page optimized for social media sharing.
<a href="https://lonardonifabio.github.io/tech_documents/?doc=6f23d74ca313dc71eeef463c2b14216a" class="underline font-semibold">Click here to view this document in the interactive library</a>.
</p> </div> </div> </div> <!-- Service Worker Registration -->  </body> </html> 