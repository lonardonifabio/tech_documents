<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="This document excerpt details several publicly released datasets primarily focused on audio and visual data, intended for research and development in areas like human activity recognition, personalized recommendations, and natural language understanding. It highlights four distinct datasets: Audi..."><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/tech_documents/favicon.svg"><link rel="manifest" href="/tech_documents/manifest.json"><title>Audio and Visual Datasets Released by Learn.MachineLearning</title><!-- Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-G7VY771Q53"></script><!-- PWA Meta Tags --><!-- <meta name="theme-color" content="#667eea"> --><!-- <meta name="apple-mobile-web-app-capable" content="yes"> --><!-- <meta name="apple-mobile-web-app-status-bar-style" content="default"> --><!-- <meta name="apple-mobile-web-app-title" content="AI Doc Library"> --><!-- Enhanced Open Graph for LinkedIn sharing --><meta property="og:title" content="Audio and Visual Datasets Released by Learn.MachineLearning"><meta property="og:description" content="This document excerpt details several publicly released datasets primarily focused on audio and visual data, intended for research and development in areas like human activity recognition, personalized recommendations, and natural language understanding. It highlights four distinct datasets: Audi..."><meta property="og:type" content="article"><meta property="og:url" content="https://lonardonifabio.github.io/tech_documents/document/18ea01edf1a3cf79d028d831dc71aeaa"><meta property="og:image" content="https://lonardonifabio.github.io/tech_documents/preview/18ea01edf1a3cf79d028d831dc71aeaa.jpg?v=1751880432942"><meta property="og:image:secure_url" content="https://lonardonifabio.github.io/tech_documents/preview/18ea01edf1a3cf79d028d831dc71aeaa.jpg?v=1751880432942"><meta property="og:image:type" content="image/svg+xml"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="Audio and Visual Datasets Released by Learn.MachineLearning - AI &#38; Data Science Document Library"><meta property="og:site_name" content="AI & Data Science Document Library"><meta property="og:locale" content="en_US"><meta property="article:author" content="Fabio Lonardoni"><meta property="article:section" content="Data Science"><meta property="article:tag" content="AudioSet, AVA Dataset, Cartoon Set, movie preferences, audio events, visual actions, human activity, dialogues, utterances"><meta property="article:published_time" content="2025-07-01T15:28:46.176959"><!-- Enhanced Twitter Card --><!-- <meta name="twitter:card" content="summary_large_image"> --><!-- <meta name="twitter:title" content={title}> --><!-- <meta name="twitter:description" content={description}> --><!-- <meta name="twitter:image" content={imageUrl}> --><!-- <meta name="twitter:image:alt" content={`${doc.title || doc.filename} - AI & Data Science Document Library`}> --><!-- <meta name="twitter:site" content="@fabiolonardoni"> --><!-- <meta name="twitter:creator" content="@fabiolonardoni"> --><!-- LinkedIn specific meta tags --><meta property="linkedin:owner" content="Fabio Lonardoni"><!-- Additional meta for mobile sharing --><meta name="author" content="@learn.machinelearning"><meta name="keywords" content="AudioSet, AVA Dataset, Cartoon Set, movie preferences, audio events, visual actions, human activity, dialogues, utterances"><meta name="robots" content="index, follow"><link rel="canonical" href="https://lonardonifabio.github.io/tech_documents/document/18ea01edf1a3cf79d028d831dc71aeaa"><!-- Additional LinkedIn optimization --><meta property="og:rich_attachment" content="true"><!-- Structured Data for better SEO --><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Audio and Visual Datasets Released by Learn.MachineLearning","description":"This document excerpt details several publicly released datasets primarily focused on audio and visual data, intended for research and development in areas like human activity recognition, personalized recommendations, and natural language understanding. It highlights four distinct datasets: Audi...","author":{"@type":"Person","name":"@learn.machinelearning"},"publisher":{"@type":"Organization","name":"AI & Data Science Document Library","logo":{"@type":"ImageObject","url":"https://lonardonifabio.github.io/tech_documents/preview/18ea01edf1a3cf79d028d831dc71aeaa.jpg?v=1751880432942"}},"url":"https://lonardonifabio.github.io/tech_documents/document/18ea01edf1a3cf79d028d831dc71aeaa","datePublished":"2025-07-01T15:28:46.176959","image":"https://lonardonifabio.github.io/tech_documents/preview/18ea01edf1a3cf79d028d831dc71aeaa.jpg?v=1751880432942","keywords":"AudioSet, AVA Dataset, Cartoon Set, movie preferences, audio events, visual actions, human activity, dialogues, utterances"}</script><!-- Simple redirect script --><script>(function(){const mainAppUrl = "https://lonardonifabio.github.io/tech_documents/?doc=18ea01edf1a3cf79d028d831dc71aeaa";

      // Manual redirect only - no automatic redirects that interfere with crawlers
      if (typeof window !== 'undefined') {
        // Add click handler for manual redirect button
        document.addEventListener('DOMContentLoaded', () => {
          const redirectButton = document.getElementById('manual-redirect');
          if (redirectButton) {
            redirectButton.addEventListener('click', () => {
              window.location.href = mainAppUrl;
            });
          }
        });
      }
    })();</script><link rel="stylesheet" href="/tech_documents/assets/_id_.8gVsPnqW.css">
<style>html{font-family:system-ui,sans-serif}::-webkit-scrollbar{width:8px}::-webkit-scrollbar-track{background:#f1f1f1}::-webkit-scrollbar-thumb{background:#c1c1c1;border-radius:4px}::-webkit-scrollbar-thumb:hover{background:#a8a8a8}
</style><script type="module">"serviceWorker"in navigator&&window.addEventListener("load",()=>{navigator.serviceWorker.register("/tech_documents/sw.js").then(e=>{console.log("SW registered: ",e)}).catch(e=>{console.log("SW registration failed: ",e)})});window.dataLayer=window.dataLayer||[];function a(){dataLayer.push(arguments)}a("js",new Date);a("config","G-G7VY771Q53");
</script></head> <body class="bg-gray-50 min-h-screen"> <!-- Fallback content for crawlers and users with JS disabled --> <div class="max-w-4xl mx-auto p-8"> <div class="bg-white rounded-lg shadow-lg p-6"> <h1 class="text-3xl font-bold text-gray-900 mb-4">Audio and Visual Datasets Released by Learn.MachineLearning</h1> <div class="mb-4"> <p class="text-gray-600"> <strong>Authors:</strong> @learn.machinelearning </p> </div> <div class="mb-6"> <p class="text-gray-700 leading-relaxed">This document excerpt details several publicly released datasets primarily focused on audio and visual data, intended for research and development in areas like human activity recognition, personalized recommendations, and natural language understanding. It highlights four distinct datasets: AudioSet, AVA Dataset, Cartoon Set, and Coached Conversational Preference Elicitation. AudioSet is a large-scale dataset of manually annotated audio events, containing 632 audio event classes and 20,84,320 10-second sound clips sourced from YouTube videos. The AVA Dataset focuses on spatio-temporally localised Atomic Visual Actions (AVA) within 430 15-minute movie clips, annotating 80 atomic visual actions with 1.62 million action labels.  Cartoon Set comprises approximately 1,013 possible combinations of 10 artwork categories, four color categories, and four proportion categories across 2D cartoon avatar images, which was instrumental in developing personalized stickers for Google Allo. Finally, the Coached Conversational Preference Elicitation dataset consists of 502 English dialogues with 12,000 annotated utterances between a user and an assistant discussing movie preferences, collected using a Wizard-of-Oz methodology. The document emphasizes the diverse applications of these datasets, ranging from audio event recognition to understanding human behavior and facilitating natural language interactions. The datasets are released by @learn.machinelearning, suggesting a community-driven effort to promote research and innovation in machine learning and related fields. The inclusion of specific numbers like 632, 20,84,320, 80, 1,62 million, and 12,000 provides a quantitative understanding of the scale and detail of each dataset.</p> </div> <div class="flex flex-wrap gap-2 mb-6"> <span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> AudioSet </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> AVA Dataset </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Cartoon Set </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> movie preferences </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> audio events </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> visual actions </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> human activity </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> dialogues </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> utterances </span> </div> <div class="flex items-center justify-between text-sm text-gray-500 mb-6"> <span class="bg-green-100 text-green-800 px-3 py-1 rounded-full"> Data Science </span> <span class="bg-orange-100 text-orange-800 px-3 py-1 rounded-full"> Intermediate </span> </div> <div class="flex gap-4"> <a href="https://lonardonifabio.github.io/tech_documents/?doc=18ea01edf1a3cf79d028d831dc71aeaa" class="bg-green-600 text-white px-6 py-2 rounded-lg hover:bg-green-700 transition-colors">
🔍 View in the library powered by AI
</a> </div> <div class="mt-6 p-4 bg-blue-50 rounded-lg"> <p class="text-blue-800 text-sm"> <strong>Note:</strong> This is a static page optimized for social media sharing.
<a href="https://lonardonifabio.github.io/tech_documents/?doc=18ea01edf1a3cf79d028d831dc71aeaa" class="underline font-semibold">Click here to view this document in the interactive library</a>.
</p> </div> </div> </div> <!-- Service Worker Registration -->  </body> </html> 