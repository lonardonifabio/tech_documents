<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="This document excerpt is a chapter from Michael Nielsen's online book, &#34;Neural Networks and Deep Learning.&#34; The book provides a foundational introduction to neural networks and deep learning concepts. The excerpt focuses on the initial stages of understanding neural networks, starting with the ba..."><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/tech_documents/favicon.svg"><link rel="manifest" href="/tech_documents/manifest.json"><title>Neural Networks and Deep Learning</title><!-- Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-G7VY771Q53"></script><!-- PWA Meta Tags --><!-- <meta name="theme-color" content="#667eea"> --><!-- <meta name="apple-mobile-web-app-capable" content="yes"> --><!-- <meta name="apple-mobile-web-app-status-bar-style" content="default"> --><!-- <meta name="apple-mobile-web-app-title" content="AI Doc Library"> --><!-- Enhanced Open Graph for LinkedIn sharing --><meta property="og:title" content="Neural Networks and Deep Learning"><meta property="og:description" content="This document excerpt is a chapter from Michael Nielsen's online book, &#34;Neural Networks and Deep Learning.&#34; The book provides a foundational introduction to neural networks and deep learning concepts. The excerpt focuses on the initial stages of understanding neural networks, starting with the ba..."><meta property="og:type" content="article"><meta property="og:url" content="https://lonardonifabio.github.io/tech_documents/document/cd2c8b802eb52fe713219f3be4efc387"><meta property="og:image" content="https://lonardonifabio.github.io/tech_documents/preview/cd2c8b802eb52fe713219f3be4efc387.jpg?v=1752494956534"><meta property="og:image:secure_url" content="https://lonardonifabio.github.io/tech_documents/preview/cd2c8b802eb52fe713219f3be4efc387.jpg?v=1752494956534"><meta property="og:image:type" content="image/svg+xml"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="Neural Networks and Deep Learning - AI &#38; Data Science Document Library"><meta property="og:site_name" content="AI & Data Science Document Library"><meta property="og:locale" content="en_US"><meta property="article:author" content="Fabio Lonardoni"><meta property="article:section" content="AI"><meta property="article:tag" content="neural networks, deep learning, perceptron, sigmoid neurons, gradient descent, backpropagation, matrix, cost function, Hadamard product, principles"><meta property="article:published_time" content="2025-06-12T00:07:41.988916"><!-- LinkedIn specific meta tags --><meta property="linkedin:owner" content="Fabio Lonardoni"><!-- Additional meta for mobile sharing --><meta name="author" content="Michael Nielsen"><meta name="keywords" content="neural networks, deep learning, perceptron, sigmoid neurons, gradient descent, backpropagation, matrix, cost function, Hadamard product, principles"><meta name="robots" content="index, follow"><link rel="canonical" href="https://lonardonifabio.github.io/tech_documents/document/cd2c8b802eb52fe713219f3be4efc387"><!-- Additional LinkedIn optimization --><meta property="og:rich_attachment" content="true"><!-- Structured Data for better SEO --><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Neural Networks and Deep Learning","description":"This document excerpt is a chapter from Michael Nielsen's online book, \"Neural Networks and Deep Learning.\" The book provides a foundational introduction to neural networks and deep learning concepts. The excerpt focuses on the initial stages of understanding neural networks, starting with the ba...","author":{"@type":"Person","name":"Michael Nielsen"},"publisher":{"@type":"Organization","name":"AI & Data Science Document Library","logo":{"@type":"ImageObject","url":"https://lonardonifabio.github.io/tech_documents/preview/cd2c8b802eb52fe713219f3be4efc387.jpg?v=1752494956534"}},"url":"https://lonardonifabio.github.io/tech_documents/document/cd2c8b802eb52fe713219f3be4efc387","datePublished":"2025-06-12T00:07:41.988916","image":"https://lonardonifabio.github.io/tech_documents/preview/cd2c8b802eb52fe713219f3be4efc387.jpg?v=1752494956534","keywords":"neural networks, deep learning, perceptron, sigmoid neurons, gradient descent, backpropagation, matrix, cost function, Hadamard product, principles"}</script><!-- Simple redirect script --><script>(function(){const mainAppUrl = "https://lonardonifabio.github.io/tech_documents/?doc=cd2c8b802eb52fe713219f3be4efc387";

      // Manual redirect only - no automatic redirects that interfere with crawlers
      if (typeof window !== 'undefined') {
        // Add click handler for manual redirect button
        document.addEventListener('DOMContentLoaded', () => {
          const redirectButton = document.getElementById('manual-redirect');
          if (redirectButton) {
            redirectButton.addEventListener('click', () => {
              window.location.href = mainAppUrl;
            });
          }
        });
      }
    })();</script><link rel="stylesheet" href="/tech_documents/assets/_id_.B2K7fHu1.css">
<style>html{font-family:system-ui,sans-serif}::-webkit-scrollbar{width:8px}::-webkit-scrollbar-track{background:#f1f1f1}::-webkit-scrollbar-thumb{background:#c1c1c1;border-radius:4px}::-webkit-scrollbar-thumb:hover{background:#a8a8a8}
</style><script type="module">"serviceWorker"in navigator&&window.addEventListener("load",()=>{navigator.serviceWorker.register("/tech_documents/sw.js").then(e=>{console.log("SW registered: ",e)}).catch(e=>{console.log("SW registration failed: ",e)})});window.dataLayer=window.dataLayer||[];function a(){dataLayer.push(arguments)}a("js",new Date);a("config","G-G7VY771Q53");
</script></head> <body class="bg-gray-50 min-h-screen"> <!-- Fallback content for crawlers and users with JS disabled --> <div class="max-w-4xl mx-auto p-8"> <div class="bg-white rounded-lg shadow-lg p-6"> <h1 class="text-3xl font-bold text-gray-900 mb-4">Neural Networks and Deep Learning</h1> <div class="mb-4"> <p class="text-gray-600"> <strong>Authors:</strong> Michael Nielsen </p> </div> <div class="mb-6"> <p class="text-gray-700 leading-relaxed">This document excerpt is a chapter from Michael Nielsen&#39;s online book, &quot;Neural Networks and Deep Learning.&quot; The book provides a foundational introduction to neural networks and deep learning concepts. The excerpt focuses on the initial stages of understanding neural networks, starting with the basics of perceptrons and sigmoid neurons. It details the architecture of neural networks and illustrates their application to the problem of recognizing handwritten digits. A key component of the chapter is the explanation of the backpropagation algorithm, which is central to training neural networks. The excerpt delves into the mathematical foundations of backpropagation, including matrix operations and the four fundamental equations that govern the process. It also introduces the concept of gradient descent as a learning method. The document serves as a primer for individuals seeking to grasp the core principles behind neural networks and their implementation, particularly in the context of handwritten digit recognition. The book&#39;s online availability at http://neuralnetworksanddeeplearning.com makes it a valuable resource for self-study and exploration within the field of deep learning. The chapter&#39;s structure is designed to build understanding progressively, starting with simpler concepts and gradually introducing more complex ideas like the backpropagation algorithm and its underlying mathematical derivations. The inclusion of optional proofs further enhances the reader&#39;s comprehension of the algorithm&#39;s mechanics.</p> </div> <div class="flex flex-wrap gap-2 mb-6"> <span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> neural networks </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> deep learning </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> perceptron </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> sigmoid neurons </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> gradient descent </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> backpropagation </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> matrix </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> cost function </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> Hadamard product </span><span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium"> principles </span> </div> <div class="flex items-center justify-between text-sm text-gray-500 mb-6"> <span class="bg-green-100 text-green-800 px-3 py-1 rounded-full"> AI </span> <span class="bg-orange-100 text-orange-800 px-3 py-1 rounded-full"> Intermediate </span> </div> <div class="flex gap-4"> <a href="https://lonardonifabio.github.io/tech_documents/?doc=cd2c8b802eb52fe713219f3be4efc387" class="bg-green-600 text-white px-6 py-2 rounded-lg hover:bg-green-700 transition-colors">
üîç View in the library powered by AI
</a> </div> <div class="mt-6 p-4 bg-blue-50 rounded-lg"> <p class="text-blue-800 text-sm"> <strong>Note:</strong> This is a static page optimized for social media sharing.
<a href="https://lonardonifabio.github.io/tech_documents/?doc=cd2c8b802eb52fe713219f3be4efc387" class="underline font-semibold">Click here to view this document in the interactive library</a>.
</p> </div> </div> </div> <!-- Service Worker Registration -->  </body> </html> 