name: Process Documents with Ollama

on:
  workflow_dispatch:
    inputs:
      force_reprocess:
        description: 'Force reprocess all documents'
        required: false
        default: false
        type: boolean
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  push:
    paths:
      - 'documents/**'
      - 'scripts/fixed_ollama_processor.py'
      - 'scripts/incremental_ollama_processor.py'

jobs:
  process-documents:
    runs-on: ubuntu-latest
    timeout-minutes: 350  # Set to 5 hours 50 minutes (under the 6-hour limit)
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r scripts/requirements.txt

    - name: Install and start Ollama
      run: |
        # Install Ollama
        curl -fsSL https://ollama.ai/install.sh | sh
        
        # Generate a random port to avoid conflicts with other workflows
        OLLAMA_PORT=$((11434 + $RANDOM % 1000))
        echo "Using Ollama port: $OLLAMA_PORT"
        
        # Cleanup any existing processes
        sudo pkill -f ollama || true
        sudo pkill -9 ollama || true
        sleep 3
        
        # Check and kill anything using ports
        if sudo lsof -ti:11434 2>/dev/null; then
          sudo kill -9 $(sudo lsof -ti:11434) || true
        fi
        if sudo lsof -ti:$OLLAMA_PORT 2>/dev/null; then
          sudo kill -9 $(sudo lsof -ti:$OLLAMA_PORT) || true
        fi
        
        # Start Ollama service with custom port
        export OLLAMA_HOST=127.0.0.1:$OLLAMA_PORT
        export OLLAMA_ORIGINS="*"
        
        echo "Starting Ollama on port $OLLAMA_PORT..."
        ollama serve &
        
        # Save the port for later steps
        echo "OLLAMA_PORT=$OLLAMA_PORT" >> $GITHUB_ENV
        echo "OLLAMA_HOST=127.0.0.1:$OLLAMA_PORT" >> $GITHUB_ENV
        
        # Wait for Ollama to be ready
        echo "Waiting for Ollama to start..."
        for i in {1..30}; do
          if curl -s http://127.0.0.1:$OLLAMA_PORT/api/tags >/dev/null 2>&1; then
            echo "Ollama is ready on port $OLLAMA_PORT!"
            break
          fi
          echo "Waiting... ($i/30)"
          sleep 3
        done
        
        # Pull the Mistral model
        ollama pull mistral:7b

    - name: Configure Git
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"

    - name: Process documents incrementally
      env:
        OLLAMA_MODEL: mistral:7b
        FORCE_REPROCESS: ${{ github.event.inputs.force_reprocess }}
      run: |
        cd ${{ github.workspace }}
        python3 scripts/incremental_ollama_processor.py

    - name: Final status check
      run: |
        echo "Workflow completed. Checking final state..."
        ls -la data/
        if [ -f "data/documents.json" ]; then
          echo "documents.json exists with $(jq length data/documents.json) documents"
        fi
        if [ -f "data/processed_files.json" ]; then
          echo "processed_files.json exists with $(jq length data/processed_files.json) files tracked"
        fi
