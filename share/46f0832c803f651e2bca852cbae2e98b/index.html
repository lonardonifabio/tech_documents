<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="This expert report, prepared for the 48th Plenary meeting of the Convention for the Protection of Individuals with Regard to Automatic Processing of Personal Data (Convenio 108), delves into the significant privacy and data protection risks associated with Large Language Models (LLMs). The docume..."><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/tech_documents/favicon.svg"><title>Expert Report on Privacy and Data Protection Risks in Large Language Models (LLMs)</title><!-- Enhanced Open Graph for LinkedIn sharing --><meta property="og:title" content="Expert Report on Privacy and Data Protection Risks in Large Language Models (LLMs)"><meta property="og:description" content="This expert report, prepared for the 48th Plenary meeting of the Convention for the Protection of Individuals with Regard to Automatic Processing of Personal Data (Convenio 108), delves into the significant privacy and data protection risks associated with Large Language Models (LLMs). The docume..."><meta property="og:type" content="article"><meta property="og:url" content="https://lonardonifabio.github.io/tech_documents/share/46f0832c803f651e2bca852cbae2e98b"><meta property="og:image" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:secure_url" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="Expert Report on Privacy and Data Protection Risks in Large Language Models (LLMs) - AI &#38; Data Science Document Library"><meta property="og:site_name" content="AI & Data Science Document Library"><meta property="og:locale" content="en_US"><meta property="article:author" content="Fabio Lonardoni"><meta property="article:section" content="Data Science"><meta property="article:tag" content="Large Language Models (LLMs), Privacy, Data Protection, Personal Data, AI lifecycle, Neural Network Architecture, LLMs, Data, Privacy Risk Analysis, Fine-tuning"><meta property="article:published_time" content="2025-07-01T22:00:11.045793"><!-- LinkedIn specific meta tags --><meta property="linkedin:owner" content="Fabio Lonardoni"><meta property="og:rich_attachment" content="true"><!-- Additional meta for mobile sharing --><meta name="author" content="Isabel Barber, Murielle Popa -Fabre"><meta name="keywords" content="Large Language Models (LLMs), Privacy, Data Protection, Personal Data, AI lifecycle, Neural Network Architecture, LLMs, Data, Privacy Risk Analysis, Fine-tuning"><meta name="robots" content="index, follow"><link rel="canonical" href="https://lonardonifabio.github.io/tech_documents/share/46f0832c803f651e2bca852cbae2e98b"><!-- Immediate redirect to main app --><script>(function(){const mainAppUrl = "https://lonardonifabio.github.io/tech_documents/?doc=46f0832c803f651e2bca852cbae2e98b";

      // Immediate redirect for users (crawlers will read meta tags first)
      if (typeof window !== 'undefined') {
        window.location.replace(mainAppUrl);
      }
    })();</script><!-- Fallback meta refresh for non-JS environments --><meta http-equiv="refresh" content="0; url={mainAppUrl}"><link rel="stylesheet" href="/tech_documents/assets/_id_.DNY9BzS4.css"></head> <body class="bg-gray-50 min-h-screen"> <!-- Fallback content for crawlers and users with JS disabled --> <div style="max-width: 800px; margin: 0 auto; padding: 20px; font-family: system-ui, sans-serif;"> <div style="background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);"> <h1 style="color: #1f2937; margin-bottom: 20px;">Expert Report on Privacy and Data Protection Risks in Large Language Models (LLMs)</h1> <div style="margin-bottom: 15px;"> <p style="color: #6b7280;"> <strong>Authors:</strong> Isabel Barber, Murielle Popa -Fabre </p> </div> <div style="margin-bottom: 20px;"> <p style="color: #374151; line-height: 1.6;">This expert report, prepared for the 48th Plenary meeting of the Convention for the Protection of Individuals with Regard to Automatic Processing of Personal Data (Convenio 108), delves into the significant privacy and data protection risks associated with Large Language Models (LLMs). The document outlines a comprehensive analysis of the landscape surrounding LLMs, focusing on how these models represent and utilize personal data.  It begins with a contextual background, defining the scope of the investigation and the relevant ecosystem of LLM-based systems.  A core section unpacks the internal workings of LLMs, specifically examining how words and data are ‚Äòseen‚Äô and represented within the models, including the compression techniques employed within neural network architectures.  The report then transitions to a critical mapping of privacy risks inherent in LLM-based systems. This involves exploring the latest technological evolutions in LLMs and the resultant new privacy risks.  Crucially, it details the methods used to extract personal data from LLMs, highlighting the vulnerabilities within the system. The report distinguishes between risks associated with the models themselves and those stemming from the broader LLM ecosystem.  Furthermore, it analyzes privacy risks throughout the entire AI lifecycle, from development to deployment.  The document emphasizes the need for technological mitigations to address these identified risks, acknowledging the complex interplay between model architecture, data representation, and potential privacy breaches. The report is intended to inform the Convention‚Äôs ongoing work on protecting individuals‚Äô rights in the context of increasingly sophisticated automated processing systems.  It‚Äôs a foundational piece for understanding the challenges posed by LLMs and guiding future policy development.</p> </div> <div style="margin-bottom: 20px;"> <h3 style="color: #1f2937; margin-bottom: 10px;">Key Concepts:</h3> <ul style="color: #374151;"> <li style="margin-bottom: 5px;">Representation of words within Large Language Models</li><li style="margin-bottom: 5px;">Data compression techniques used in LLMs</li><li style="margin-bottom: 5px;">Privacy risks associated with LLM-based systems and their lifecycle</li><li style="margin-bottom: 5px;">LLM-based systems lifecycle</li><li style="margin-bottom: 5px;">Three phases of LLM development (training, adaptation, optimization)</li><li style="margin-bottom: 5px;">Data curation across phases</li><li style="margin-bottom: 5px;">Privacy risk analysis in LLM development</li><li style="margin-bottom: 5px;">Erosion of authorship and authenticity</li><li style="margin-bottom: 5px;">Mimicking human communication</li><li style="margin-bottom: 5px;">Impact on individual identity and autonomy</li> </ul> </div> <div style="margin-bottom: 20px;"> <span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Large Language Models (LLMs) </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Privacy </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Data Protection </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Personal Data </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> AI lifecycle </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Neural Network Architecture </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> LLMs </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Data </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Privacy Risk Analysis </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Fine-tuning </span> </div> <div style="margin-bottom: 20px;"> <span style="background: #dcfce7; color: #166534; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 10px;"> Data Science </span> <span style="background: #fed7aa; color: #9a3412; padding: 4px 12px; border-radius: 20px; font-size: 14px;"> Intermediate </span> </div> <div style="margin-bottom: 20px;"> <a href="https://raw.githubusercontent.com/lonardonifabio/tech_documents/main/documents/Privacy_Data_Protection_Risk_in_Large_Language_Models_1749157942.pdf" target="_blank" rel="noopener noreferrer" style="background: #2563eb; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; margin-right: 10px; display: inline-block;">
üì• Download PDF
</a> <a href="https://lonardonifabio.github.io/tech_documents/?doc=46f0832c803f651e2bca852cbae2e98b" style="background: #16a34a; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; display: inline-block;">
üîç View in Library
</a> </div> <div style="background: #eff6ff; padding: 15px; border-radius: 8px; border-left: 4px solid #3b82f6;"> <p style="color: #1e40af; font-size: 14px; margin: 0;"> <strong>Note:</strong> You will be automatically redirected to the interactive document library. 
            If the redirect doesn't work, <a href="https://lonardonifabio.github.io/tech_documents/?doc=46f0832c803f651e2bca852cbae2e98b" style="color: #1e40af; text-decoration: underline;">click here</a>.
</p> </div> </div> </div> </body></html>