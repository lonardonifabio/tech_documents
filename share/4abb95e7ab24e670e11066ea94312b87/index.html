<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="This document presents a concise cheatsheet for machine learning algorithms, drawing inspiration from resources like MachineLearningMastery, ML Pros &#38; Cons of HackingNote, and The Probability Cheatsheet of W. Chen. It provides a foundational overview of key concepts and algorithms, categorized pr..."><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/tech_documents/favicon.svg"><title>Machine Learning Cheatsheet</title><!-- Enhanced Open Graph for LinkedIn sharing --><meta property="og:title" content="Machine Learning Cheatsheet"><meta property="og:description" content="This document presents a concise cheatsheet for machine learning algorithms, drawing inspiration from resources like MachineLearningMastery, ML Pros &#38; Cons of HackingNote, and The Probability Cheatsheet of W. Chen. It provides a foundational overview of key concepts and algorithms, categorized pr..."><meta property="og:type" content="article"><meta property="og:url" content="https://lonardonifabio.github.io/tech_documents/share/4abb95e7ab24e670e11066ea94312b87"><meta property="og:image" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:secure_url" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="Machine Learning Cheatsheet - AI &#38; Data Science Document Library"><meta property="og:site_name" content="AI & Data Science Document Library"><meta property="og:locale" content="en_US"><meta property="article:author" content="Fabio Lonardoni"><meta property="article:section" content="Machine Learning"><meta property="article:tag" content="Machine Learning, Algorithms, Supervised Learning, Unsupervised Learning, Bias-Variance, Linear, Nonlinear, Parametric, Nonparametric, linear kernel"><meta property="article:published_time" content="2025-06-28T18:58:00.386766"><!-- LinkedIn specific meta tags --><meta property="linkedin:owner" content="Fabio Lonardoni"><meta property="og:rich_attachment" content="true"><!-- Additional meta for mobile sharing --><meta name="author" content="R√©mi Canard"><meta name="keywords" content="Machine Learning, Algorithms, Supervised Learning, Unsupervised Learning, Bias-Variance, Linear, Nonlinear, Parametric, Nonparametric, linear kernel"><meta name="robots" content="index, follow"><link rel="canonical" href="https://lonardonifabio.github.io/tech_documents/share/4abb95e7ab24e670e11066ea94312b87"><!-- Immediate redirect to main app --><script>(function(){const mainAppUrl = "https://lonardonifabio.github.io/tech_documents/?doc=4abb95e7ab24e670e11066ea94312b87";

      // Immediate redirect for users (crawlers will read meta tags first)
      if (typeof window !== 'undefined') {
        window.location.replace(mainAppUrl);
      }
    })();</script><!-- Fallback meta refresh for non-JS environments --><meta http-equiv="refresh" content="0; url={mainAppUrl}"><link rel="stylesheet" href="/tech_documents/assets/_id_.B2K7fHu1.css"></head> <body class="bg-gray-50 min-h-screen"> <!-- Fallback content for crawlers and users with JS disabled --> <div style="max-width: 800px; margin: 0 auto; padding: 20px; font-family: system-ui, sans-serif;"> <div style="background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);"> <h1 style="color: #1f2937; margin-bottom: 20px;">Machine Learning Cheatsheet</h1> <div style="margin-bottom: 15px;"> <p style="color: #6b7280;"> <strong>Authors:</strong> R√©mi Canard </p> </div> <div style="margin-bottom: 20px;"> <p style="color: #374151; line-height: 1.6;">This document presents a concise cheatsheet for machine learning algorithms, drawing inspiration from resources like MachineLearningMastery, ML Pros &amp; Cons of HackingNote, and The Probability Cheatsheet of W. Chen. It provides a foundational overview of key concepts and algorithms, categorized primarily by their approach ‚Äì parametric (linear) versus non-parametric (nonlinear). The core distinction lies in the assumptions made about the target function &#39;f&#39; mapping input variables &#39;X&#39; to output variable &#39;Y&#39; with an associated error &#39;e&#39;. Linear algorithms simplify this mapping to a known linear combination, focusing on learning coefficients, while non-parametric algorithms offer greater flexibility and power by learning any functional form directly from the training data. The cheatsheet highlights the importance of the bias-variance trade-off, a central concept in supervised learning. Bias represents the simplifying assumptions made to facilitate learning, while variance reflects the model&#39;s sensitivity to changes in the training data. The document emphasizes that supervised learning methods predict &#39;Y&#39; from &#39;X&#39; using labeled data, whereas unsupervised learning aims to uncover the inherent structure of unlabeled data.  The cheatsheet serves as a quick reference for understanding the fundamental differences between these approaches and the core concepts driving model selection and performance evaluation. It&#39;s a valuable tool for anyone seeking a rapid introduction to the landscape of machine learning algorithms and their associated trade-offs. The document&#39;s design is inspired by established cheatsheets, aiming for clarity and conciseness.</p> </div> <div style="margin-bottom: 20px;"> <h3 style="color: #1f2937; margin-bottom: 10px;">Key Concepts:</h3> <ul style="color: #374151;"> <li style="margin-bottom: 5px;">Target Function: f that maps input variables X to output variable Y</li><li style="margin-bottom: 5px;">Bias-Variance Trade-off: Relationship between bias and variance in model performance</li><li style="margin-bottom: 5px;">Linear Algorithms: Simplify mapping to a linear combination</li><li style="margin-bottom: 5px;">Nonlinear Algorithms: Learn any functional form from training data</li><li style="margin-bottom: 5px;">Support Vector Machines (SVM) utilize kernels to map data into a higher-dimensional space to enable nonlinear separation.</li><li style="margin-bottom: 5px;">Hyperplane learning involves finding the optimal hyperplane that maximizes the margin between classes.</li><li style="margin-bottom: 5px;">Ensemble methods combine multiple models to improve predictive performance, with bagging reducing variance by creating multiple subsamples.</li><li style="margin-bottom: 5px;">Bagging uses Bootstrap Aggregation, creating random subsamples with replacement and averaging predictions.</li> </ul> </div> <div style="margin-bottom: 20px;"> <span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Machine Learning </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Algorithms </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Supervised Learning </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Unsupervised Learning </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Bias-Variance </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Linear </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Nonlinear </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Parametric </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Nonparametric </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> linear kernel </span> </div> <div style="margin-bottom: 20px;"> <span style="background: #dcfce7; color: #166534; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 10px;"> Machine Learning </span> <span style="background: #fed7aa; color: #9a3412; padding: 4px 12px; border-radius: 20px; font-size: 14px;"> Basic </span> </div> <div style="margin-bottom: 20px;"> <a href="https://raw.githubusercontent.com/lonardonifabio/tech_documents/main/documents/ML_CheatSheet_1637007275.pdf" target="_blank" rel="noopener noreferrer" style="background: #2563eb; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; margin-right: 10px; display: inline-block;">
üì• Download PDF
</a> <a href="https://lonardonifabio.github.io/tech_documents/?doc=4abb95e7ab24e670e11066ea94312b87" style="background: #16a34a; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; display: inline-block;">
üîç View in Library
</a> </div> <div style="background: #eff6ff; padding: 15px; border-radius: 8px; border-left: 4px solid #3b82f6;"> <p style="color: #1e40af; font-size: 14px; margin: 0;"> <strong>Note:</strong> You will be automatically redirected to the interactive document library. 
            If the redirect doesn't work, <a href="https://lonardonifabio.github.io/tech_documents/?doc=4abb95e7ab24e670e11066ea94312b87" style="color: #1e40af; text-decoration: underline;">click here</a>.
</p> </div> </div> </div> </body></html>