<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="This document excerpt details several publicly released datasets primarily focused on audio and visual data, intended for research and development in areas like human activity recognition, personalized recommendations, and natural language understanding. It highlights four distinct datasets: Audi..."><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/tech_documents/favicon.svg"><title>Audio and Visual Datasets Released by Learn.MachineLearning</title><!-- Enhanced Open Graph for LinkedIn sharing --><meta property="og:title" content="Audio and Visual Datasets Released by Learn.MachineLearning"><meta property="og:description" content="This document excerpt details several publicly released datasets primarily focused on audio and visual data, intended for research and development in areas like human activity recognition, personalized recommendations, and natural language understanding. It highlights four distinct datasets: Audi..."><meta property="og:type" content="article"><meta property="og:url" content="https://lonardonifabio.github.io/tech_documents/share/18ea01edf1a3cf79d028d831dc71aeaa"><meta property="og:image" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:secure_url" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="Audio and Visual Datasets Released by Learn.MachineLearning - AI &#38; Data Science Document Library"><meta property="og:site_name" content="AI & Data Science Document Library"><meta property="og:locale" content="en_US"><meta property="article:author" content="Fabio Lonardoni"><meta property="article:section" content="Data Science"><meta property="article:tag" content="AudioSet, AVA Dataset, Cartoon Set, movie preferences, audio events, visual actions, human activity, dialogues, utterances"><meta property="article:published_time" content="2025-07-01T15:28:46.176959"><!-- LinkedIn specific meta tags --><meta property="linkedin:owner" content="Fabio Lonardoni"><meta property="og:rich_attachment" content="true"><!-- Additional meta for mobile sharing --><meta name="author" content="@learn.machinelearning"><meta name="keywords" content="AudioSet, AVA Dataset, Cartoon Set, movie preferences, audio events, visual actions, human activity, dialogues, utterances"><meta name="robots" content="index, follow"><link rel="canonical" href="https://lonardonifabio.github.io/tech_documents/share/18ea01edf1a3cf79d028d831dc71aeaa"><!-- Immediate redirect to main app --><script>(function(){const mainAppUrl = "https://lonardonifabio.github.io/tech_documents/?doc=18ea01edf1a3cf79d028d831dc71aeaa";

      // Immediate redirect for users (crawlers will read meta tags first)
      if (typeof window !== 'undefined') {
        window.location.replace(mainAppUrl);
      }
    })();</script><!-- Fallback meta refresh for non-JS environments --><meta http-equiv="refresh" content="0; url={mainAppUrl}"><link rel="stylesheet" href="/tech_documents/assets/_id_.DNY9BzS4.css"></head> <body class="bg-gray-50 min-h-screen"> <!-- Fallback content for crawlers and users with JS disabled --> <div style="max-width: 800px; margin: 0 auto; padding: 20px; font-family: system-ui, sans-serif;"> <div style="background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);"> <h1 style="color: #1f2937; margin-bottom: 20px;">Audio and Visual Datasets Released by Learn.MachineLearning</h1> <div style="margin-bottom: 15px;"> <p style="color: #6b7280;"> <strong>Authors:</strong> @learn.machinelearning </p> </div> <div style="margin-bottom: 20px;"> <p style="color: #374151; line-height: 1.6;">This document excerpt details several publicly released datasets primarily focused on audio and visual data, intended for research and development in areas like human activity recognition, personalized recommendations, and natural language understanding. It highlights four distinct datasets: AudioSet, AVA Dataset, Cartoon Set, and Coached Conversational Preference Elicitation. AudioSet is a large-scale dataset of manually annotated audio events, containing 632 audio event classes and 20,84,320 10-second sound clips sourced from YouTube videos. The AVA Dataset focuses on spatio-temporally localised Atomic Visual Actions (AVA) within 430 15-minute movie clips, annotating 80 atomic visual actions with 1.62 million action labels.  Cartoon Set comprises approximately 1,013 possible combinations of 10 artwork categories, four color categories, and four proportion categories across 2D cartoon avatar images, which was instrumental in developing personalized stickers for Google Allo. Finally, the Coached Conversational Preference Elicitation dataset consists of 502 English dialogues with 12,000 annotated utterances between a user and an assistant discussing movie preferences, collected using a Wizard-of-Oz methodology. The document emphasizes the diverse applications of these datasets, ranging from audio event recognition to understanding human behavior and facilitating natural language interactions. The datasets are released by @learn.machinelearning, suggesting a community-driven effort to promote research and innovation in machine learning and related fields. The inclusion of specific numbers like 632, 20,84,320, 80, 1,62 million, and 12,000 provides a quantitative understanding of the scale and detail of each dataset.</p> </div> <div style="margin-bottom: 20px;"> <h3 style="color: #1f2937; margin-bottom: 10px;">Key Concepts:</h3> <ul style="color: #374151;"> <li style="margin-bottom: 5px;">Large-scale audio datasets with annotated audio events.</li><li style="margin-bottom: 5px;">Spatio-temporally localised atomic visual actions.</li><li style="margin-bottom: 5px;">Collection of cartoon avatar images with varying categories.</li> </ul> </div> <div style="margin-bottom: 20px;"> <span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> AudioSet </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> AVA Dataset </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Cartoon Set </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> movie preferences </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> audio events </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> visual actions </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> human activity </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> dialogues </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> utterances </span> </div> <div style="margin-bottom: 20px;"> <span style="background: #dcfce7; color: #166534; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 10px;"> Data Science </span> <span style="background: #fed7aa; color: #9a3412; padding: 4px 12px; border-radius: 20px; font-size: 14px;"> Intermediate </span> </div> <div style="margin-bottom: 20px;"> <a href="https://raw.githubusercontent.com/lonardonifabio/tech_documents/main/documents/datasets_released_by_google_1623394859.pdf" target="_blank" rel="noopener noreferrer" style="background: #2563eb; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; margin-right: 10px; display: inline-block;">
üì• Download PDF
</a> <a href="https://lonardonifabio.github.io/tech_documents/?doc=18ea01edf1a3cf79d028d831dc71aeaa" style="background: #16a34a; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; display: inline-block;">
üîç View in Library
</a> </div> <div style="background: #eff6ff; padding: 15px; border-radius: 8px; border-left: 4px solid #3b82f6;"> <p style="color: #1e40af; font-size: 14px; margin: 0;"> <strong>Note:</strong> You will be automatically redirected to the interactive document library. 
            If the redirect doesn't work, <a href="https://lonardonifabio.github.io/tech_documents/?doc=18ea01edf1a3cf79d028d831dc71aeaa" style="color: #1e40af; text-decoration: underline;">click here</a>.
</p> </div> </div> </div> </body></html>