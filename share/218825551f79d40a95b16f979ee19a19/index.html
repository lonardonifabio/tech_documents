<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="This 2025 Responsible AI Transparency Report, released in May 2024, details the company's approach to building, supporting, and evolving its generative AI systems and models responsibly. The report focuses on key areas including governance, risk identification and assessment, risk mitigation stra..."><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/tech_documents/favicon.svg"><title>2025 Responsible AI Transparency Report</title><!-- Enhanced Open Graph for LinkedIn sharing --><meta property="og:title" content="2025 Responsible AI Transparency Report"><meta property="og:description" content="This 2025 Responsible AI Transparency Report, released in May 2024, details the company's approach to building, supporting, and evolving its generative AI systems and models responsibly. The report focuses on key areas including governance, risk identification and assessment, risk mitigation stra..."><meta property="og:type" content="article"><meta property="og:url" content="https://lonardonifabio.github.io/tech_documents/share/218825551f79d40a95b16f979ee19a19"><meta property="og:image" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:secure_url" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="2025 Responsible AI Transparency Report - AI &#38; Data Science Document Library"><meta property="og:site_name" content="AI & Data Science Document Library"><meta property="og:locale" content="en_US"><meta property="article:author" content="Fabio Lonardoni"><meta property="article:section" content="AI"><meta property="article:tag" content="Responsible AI, Generative AI, AI Systems, AI Risks, AI Adoption, Transparency Report, AI Governance, generative AI, regulatory requirements, AI Act"><meta property="article:published_time" content="2025-06-29T10:14:46.743382"><!-- LinkedIn specific meta tags --><meta property="linkedin:owner" content="Fabio Lonardoni"><meta property="og:rich_attachment" content="true"><!-- Additional meta for mobile sharing --><meta name="author" content="Unknown"><meta name="keywords" content="Responsible AI, Generative AI, AI Systems, AI Risks, AI Adoption, Transparency Report, AI Governance, generative AI, regulatory requirements, AI Act"><meta name="robots" content="index, follow"><link rel="canonical" href="https://lonardonifabio.github.io/tech_documents/share/218825551f79d40a95b16f979ee19a19"><!-- Immediate redirect to main app --><script>(function(){const mainAppUrl = "https://lonardonifabio.github.io/tech_documents/?doc=218825551f79d40a95b16f979ee19a19";

      // Immediate redirect for users (crawlers will read meta tags first)
      if (typeof window !== 'undefined') {
        window.location.replace(mainAppUrl);
      }
    })();</script><!-- Fallback meta refresh for non-JS environments --><meta http-equiv="refresh" content="0; url={mainAppUrl}"><link rel="stylesheet" href="/tech_documents/assets/_id_.B2K7fHu1.css"></head> <body class="bg-gray-50 min-h-screen"> <!-- Fallback content for crawlers and users with JS disabled --> <div style="max-width: 800px; margin: 0 auto; padding: 20px; font-family: system-ui, sans-serif;"> <div style="background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);"> <h1 style="color: #1f2937; margin-bottom: 20px;">2025 Responsible AI Transparency Report</h1> <div style="margin-bottom: 15px;"> <p style="color: #6b7280;"> <strong>Authors:</strong> Unknown </p> </div> <div style="margin-bottom: 20px;"> <p style="color: #374151; line-height: 1.6;">This 2025 Responsible AI Transparency Report, released in May 2024, details the company&#39;s approach to building, supporting, and evolving its generative AI systems and models responsibly. The report focuses on key areas including governance, risk identification and assessment, risk mitigation strategies, and the deployment safety of these systems. A core element of the report is the ‚ÄòSensitive Uses and Emerging Technologies program,‚Äô designed to proactively address potential risks associated with new AI applications.  Furthermore, it outlines the company‚Äôs commitment to supporting customers in their own responsible AI development and deployment efforts, providing tools and resources to facilitate transparency and accountability. The report emphasizes a multi-faceted approach, incorporating customer feedback and ongoing investments in research and innovation.  It highlights the importance of multistakeholder input in shaping the future of AI governance. The document showcases a dedication to continuous improvement and adaptation, reflecting the rapidly evolving landscape of AI technology and its implications. The company‚Äôs commitment extends beyond simply building AI systems; it‚Äôs about fostering trust and ensuring responsible adoption across the entire ecosystem. The report‚Äôs release followed the initial 2024 report, indicating an ongoing commitment to transparency and accountability in the development and deployment of generative AI. The document‚Äôs scope encompasses not only internal processes but also external support for customers, acknowledging the broader impact of AI technology.</p> </div> <div style="margin-bottom: 20px;"> <h3 style="color: #1f2937; margin-bottom: 10px;">Key Concepts:</h3> <ul style="color: #374151;"> <li style="margin-bottom: 5px;">Building AI responsibly</li><li style="margin-bottom: 5px;">Risk assessment and mitigation in AI</li><li style="margin-bottom: 5px;">Deployment safety of generative AI</li><li style="margin-bottom: 5px;">Supporting customers in responsible AI development</li><li style="margin-bottom: 5px;">Stakeholder feedback and continuous improvement</li><li style="margin-bottom: 5px;">Formalized internal requirements for generative AI systems to mitigate novel risks.</li><li style="margin-bottom: 5px;">Layered approach to compliance with evolving regulatory requirements.</li><li style="margin-bottom: 5px;">Microsoft‚Äôs role in supporting customer compliance with the EU AI Act and GPAI model provider obligations.</li><li style="margin-bottom: 5px;">AIRT&#39;s operations involve case studies across modalities and analysis of AI threats.</li><li style="margin-bottom: 5px;">The development and utilization of an AI threat model ontology for identifying attack components.</li> </ul> </div> <div style="margin-bottom: 20px;"> <span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Responsible AI </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Generative AI </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> AI Systems </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> AI Risks </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> AI Adoption </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Transparency Report </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> AI Governance </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> generative AI </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> regulatory requirements </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> AI Act </span> </div> <div style="margin-bottom: 20px;"> <span style="background: #dcfce7; color: #166534; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 10px;"> AI </span> <span style="background: #fed7aa; color: #9a3412; padding: 4px 12px; border-radius: 20px; font-size: 14px;"> Intermediate </span> </div> <div style="margin-bottom: 20px;"> <a href="https://raw.githubusercontent.com/lonardonifabio/tech_documents/main/documents/Responsible_AI_Transparency_Report_2025_1750661701.pdf" target="_blank" rel="noopener noreferrer" style="background: #2563eb; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; margin-right: 10px; display: inline-block;">
üì• Download PDF
</a> <a href="https://lonardonifabio.github.io/tech_documents/?doc=218825551f79d40a95b16f979ee19a19" style="background: #16a34a; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; display: inline-block;">
üîç View in Library
</a> </div> <div style="background: #eff6ff; padding: 15px; border-radius: 8px; border-left: 4px solid #3b82f6;"> <p style="color: #1e40af; font-size: 14px; margin: 0;"> <strong>Note:</strong> You will be automatically redirected to the interactive document library. 
            If the redirect doesn't work, <a href="https://lonardonifabio.github.io/tech_documents/?doc=218825551f79d40a95b16f979ee19a19" style="color: #1e40af; text-decoration: underline;">click here</a>.
</p> </div> </div> </div> </body></html>