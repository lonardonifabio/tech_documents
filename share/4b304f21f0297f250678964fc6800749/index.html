<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="This document excerpt presents introductory lecture notes for a course on Deep Learning, authored by Hadar Sharvit and based on lectures by Raanan Fattal and recitations by Matan Halfon. The course is designed to be informal, with the author intending to elaborate on key topics, indicated by the ..."><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/tech_documents/favicon.svg"><title>Intro to Deep Learning</title><!-- Enhanced Open Graph for LinkedIn sharing --><meta property="og:title" content="Intro to Deep Learning"><meta property="og:description" content="This document excerpt presents introductory lecture notes for a course on Deep Learning, authored by Hadar Sharvit and based on lectures by Raanan Fattal and recitations by Matan Halfon. The course is designed to be informal, with the author intending to elaborate on key topics, indicated by the ..."><meta property="og:type" content="article"><meta property="og:url" content="https://lonardonifabio.github.io/tech_documents/share/4b304f21f0297f250678964fc6800749"><meta property="og:image" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:secure_url" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="Intro to Deep Learning - AI &#38; Data Science Document Library"><meta property="og:site_name" content="AI & Data Science Document Library"><meta property="og:locale" content="en_US"><meta property="article:author" content="Fabio Lonardoni"><meta property="article:section" content="AI"><meta property="article:tag" content="Deep Learning, Neural Network, Gradient Descent, Mini Batching, SGD, Likelihood, Entropy, Cross-Entropy, MLP, Perceptron"><meta property="article:published_time" content="2025-07-03T22:49:27.429291"><!-- LinkedIn specific meta tags --><meta property="linkedin:owner" content="Fabio Lonardoni"><meta property="og:rich_attachment" content="true"><!-- Additional meta for mobile sharing --><meta name="author" content="Hadar Sharvit, Raanan Fattal, Matan Halfon"><meta name="keywords" content="Deep Learning, Neural Network, Gradient Descent, Mini Batching, SGD, Likelihood, Entropy, Cross-Entropy, MLP, Perceptron"><meta name="robots" content="index, follow"><link rel="canonical" href="https://lonardonifabio.github.io/tech_documents/share/4b304f21f0297f250678964fc6800749"><!-- Immediate redirect to main app --><script>(function(){const mainAppUrl = "https://lonardonifabio.github.io/tech_documents/?doc=4b304f21f0297f250678964fc6800749";

      // Immediate redirect for users (crawlers will read meta tags first)
      if (typeof window !== 'undefined') {
        window.location.replace(mainAppUrl);
      }
    })();</script><!-- Fallback meta refresh for non-JS environments --><meta http-equiv="refresh" content="0; url={mainAppUrl}"><link rel="stylesheet" href="/tech_documents/assets/_id_.DNY9BzS4.css"></head> <body class="bg-gray-50 min-h-screen"> <!-- Fallback content for crawlers and users with JS disabled --> <div style="max-width: 800px; margin: 0 auto; padding: 20px; font-family: system-ui, sans-serif;"> <div style="background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);"> <h1 style="color: #1f2937; margin-bottom: 20px;">Intro to Deep Learning</h1> <div style="margin-bottom: 15px;"> <p style="color: #6b7280;"> <strong>Authors:</strong> Hadar Sharvit, Raanan Fattal, Matan Halfon </p> </div> <div style="margin-bottom: 20px;"> <p style="color: #374151; line-height: 1.6;">This document excerpt presents introductory lecture notes for a course on Deep Learning, authored by Hadar Sharvit and based on lectures by Raanan Fattal and recitations by Matan Halfon. The course is designed to be informal, with the author intending to elaborate on key topics, indicated by the (‚Ä†) symbol. The notes cover fundamental concepts within deep learning, starting with an introduction to Information Theory, specifically focusing on Entropy and Cross-Entropy, and their relationship to maximizing likelihood.  A significant portion is dedicated to Neural Network Models, beginning with the Perceptron and progressing to Multi-Layer Perceptrons (MLPs), detailing activation functions (including various types), and loss functions (both regression and classification). Finally, the document outlines the process of Network Training, including Gradient Descent Optimization and techniques like Mini Batching and Stochastic Gradient Descent (SGD). The material provides a foundational understanding of the core elements required for building and training deep learning models. The document serves as a concise overview of essential concepts, likely intended for students or individuals seeking a quick introduction to the field of deep learning. The inclusion of different loss functions highlights the importance of choosing the appropriate loss function based on the type of problem being addressed. The emphasis on optimization techniques like gradient descent and mini-batching underscores the critical role of efficient training algorithms in deep learning.</p> </div> <div style="margin-bottom: 20px;"> <h3 style="color: #1f2937; margin-bottom: 10px;">Key Concepts:</h3> <ul style="color: #374151;"> <li style="margin-bottom: 5px;">The course introduces concepts related to Deep Learning and Neural Networks.</li><li style="margin-bottom: 5px;">Minimizing Cross-Entropy maximizes the Likelihood.</li><li style="margin-bottom: 5px;">Gradient Descent is used for Network Training.</li><li style="margin-bottom: 5px;">The maximum likelihood principle seeks to find parameters that maximize the probability of observed data given a model.</li><li style="margin-bottom: 5px;">The Perceptron is a supervised learning algorithm that learns a linear classifier (hyperplane) to separate data into clusters.</li><li style="margin-bottom: 5px;">The definition of a half-plane is defined as the set of points satisfying a linear equation.</li><li style="margin-bottom: 5px;">Mini-batch sampling</li><li style="margin-bottom: 5px;">Gradient descent optimization</li><li style="margin-bottom: 5px;">Backpropagation algorithm</li><li style="margin-bottom: 5px;">L2 loss</li> </ul> </div> <div style="margin-bottom: 20px;"> <span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Deep Learning </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Neural Network </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Gradient Descent </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Mini Batching </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> SGD </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Likelihood </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Entropy </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Cross-Entropy </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> MLP </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Perceptron </span> </div> <div style="margin-bottom: 20px;"> <span style="background: #dcfce7; color: #166534; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 10px;"> AI </span> <span style="background: #fed7aa; color: #9a3412; padding: 4px 12px; border-radius: 20px; font-size: 14px;"> Intermediate </span> </div> <div style="margin-bottom: 20px;"> <a href="https://raw.githubusercontent.com/lonardonifabio/tech_documents/main/documents/Intro_to_Deep_Learning_HUJI_1638274642.pdf" target="_blank" rel="noopener noreferrer" style="background: #2563eb; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; margin-right: 10px; display: inline-block;">
üì• Download PDF
</a> <a href="https://lonardonifabio.github.io/tech_documents/?doc=4b304f21f0297f250678964fc6800749" style="background: #16a34a; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; display: inline-block;">
üîç View in Library
</a> </div> <div style="background: #eff6ff; padding: 15px; border-radius: 8px; border-left: 4px solid #3b82f6;"> <p style="color: #1e40af; font-size: 14px; margin: 0;"> <strong>Note:</strong> You will be automatically redirected to the interactive document library. 
            If the redirect doesn't work, <a href="https://lonardonifabio.github.io/tech_documents/?doc=4b304f21f0297f250678964fc6800749" style="color: #1e40af; text-decoration: underline;">click here</a>.
</p> </div> </div> </div> </body></html>