<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="This document, published by the National Institute of Standards and Technology (NIST), provides a comprehensive taxonomy and terminology related to adversarial machine learning attacks and their corresponding mitigations.  It‚Äôs a crucial resource for researchers, practitioners, and policymakers i..."><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/tech_documents/favicon.svg"><title>NIST Trustworthy and Responsible AI NIST AI 100-2e2025 Adversarial Machine Learning A Taxonomy and Terminology of Attacks and Mitigations</title><!-- Enhanced Open Graph for LinkedIn sharing --><meta property="og:title" content="NIST Trustworthy and Responsible AI NIST AI 100-2e2025 Adversarial Machine Learning A Taxonomy and Terminology of Attacks and Mitigations"><meta property="og:description" content="This document, published by the National Institute of Standards and Technology (NIST), provides a comprehensive taxonomy and terminology related to adversarial machine learning attacks and their corresponding mitigations.  It‚Äôs a crucial resource for researchers, practitioners, and policymakers i..."><meta property="og:type" content="article"><meta property="og:url" content="https://lonardonifabio.github.io/tech_documents/share/2c5334041419e90fa983e2b098a44614"><meta property="og:image" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:secure_url" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="NIST Trustworthy and Responsible AI NIST AI 100-2e2025 Adversarial Machine Learning A Taxonomy and Terminology of Attacks and Mitigations - AI &#38; Data Science Document Library"><meta property="og:site_name" content="AI & Data Science Document Library"><meta property="og:locale" content="en_US"><meta property="article:author" content="Fabio Lonardoni"><meta property="article:section" content="Machine Learning"><meta property="article:tag" content="AI, Adversarial Machine Learning, Taxonomy, Terminology, Attacks, Mitigations, NIST, Trustworthy AI, Responsible AI, attacker capabilities"><meta property="article:published_time" content="2025-06-28T18:57:53.756721"><!-- LinkedIn specific meta tags --><meta property="linkedin:owner" content="Fabio Lonardoni"><meta property="og:rich_attachment" content="true"><!-- Additional meta for mobile sharing --><meta name="author" content="Alina Oprea, Apostol Vassilev, Maia Hamin, Alie Fordyce, Hyrum Anderson, Xander Davies"><meta name="keywords" content="AI, Adversarial Machine Learning, Taxonomy, Terminology, Attacks, Mitigations, NIST, Trustworthy AI, Responsible AI, attacker capabilities"><meta name="robots" content="index, follow"><link rel="canonical" href="https://lonardonifabio.github.io/tech_documents/share/2c5334041419e90fa983e2b098a44614"><!-- Immediate redirect to main app --><script>(function(){const mainAppUrl = "https://lonardonifabio.github.io/tech_documents/?doc=2c5334041419e90fa983e2b098a44614";

      // Immediate redirect for users (crawlers will read meta tags first)
      if (typeof window !== 'undefined') {
        window.location.replace(mainAppUrl);
      }
    })();</script><!-- Fallback meta refresh for non-JS environments --><meta http-equiv="refresh" content="0; url={mainAppUrl}"><link rel="stylesheet" href="/tech_documents/assets/_id_.8gVsPnqW.css"></head> <body class="bg-gray-50 min-h-screen"> <!-- Fallback content for crawlers and users with JS disabled --> <div style="max-width: 800px; margin: 0 auto; padding: 20px; font-family: system-ui, sans-serif;"> <div style="background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);"> <h1 style="color: #1f2937; margin-bottom: 20px;">NIST Trustworthy and Responsible AI NIST AI 100-2e2025 Adversarial Machine Learning A Taxonomy and Terminology of Attacks and Mitigations</h1> <div style="margin-bottom: 15px;"> <p style="color: #6b7280;"> <strong>Authors:</strong> Alina Oprea, Apostol Vassilev, Maia Hamin, Alie Fordyce, Hyrum Anderson, Xander Davies </p> </div> <div style="margin-bottom: 20px;"> <p style="color: #374151; line-height: 1.6;">This document, published by the National Institute of Standards and Technology (NIST), provides a comprehensive taxonomy and terminology related to adversarial machine learning attacks and their corresponding mitigations.  It‚Äôs a crucial resource for researchers, practitioners, and policymakers involved in ensuring the trustworthiness and responsible development of AI systems. The publication, titled ‚ÄòNIST AI 100-2e2025 Adversarial Machine Learning A Taxonomy and Terminology of Attacks and Mitigations,‚Äô focuses on systematically categorizing various attack techniques targeting machine learning models, including those designed to exploit vulnerabilities in training data, model architecture, or inference processes.  The document meticulously defines these attacks, detailing their methodologies and potential impact.  Furthermore, it outlines a range of mitigation strategies, offering practical approaches to defend against these threats.  The work is grounded in a rigorous, technical approach, aiming to provide a standardized framework for understanding and addressing the growing concern of adversarial machine learning.  The authors, representing institutions like the U.S. AI Safety Institute, Cisco, and the U.K. AI Security Institute, demonstrate a multi-faceted perspective on the problem.  The document‚Äôs free availability through the NIST website (doi.org/10.6028/NIST.AI.100-2e2025) underscores NIST&#39;s commitment to promoting responsible AI practices.  The inclusion of commercial equipment and software is noted for the purpose of accurately describing experimental procedures, with a clear disclaimer that this does not constitute an endorsement.  The document is a key contribution to the ongoing effort to build robust and reliable AI systems capable of withstanding malicious attacks. It‚Äôs a vital resource for anyone seeking to understand the landscape of adversarial machine learning and develop effective defenses.</p> </div> <div style="margin-bottom: 20px;"> <h3 style="color: #1f2937; margin-bottom: 10px;">Key Concepts:</h3> <ul style="color: #374151;"> <li style="margin-bottom: 5px;">A taxonomy and terminology of attacks and mitigations related to AI.</li><li style="margin-bottom: 5px;">The development of standards for trustworthy and responsible AI.</li><li style="margin-bottom: 5px;">Identifying and classifying different types of adversarial attacks on machine learning systems.</li><li style="margin-bottom: 5px;">Attacker capabilities refer to the abilities of an attacker.</li><li style="margin-bottom: 5px;">Supply chain attacks involve compromising systems through the supply chain.</li><li style="margin-bottom: 5px;">Data poisoning attacks manipulate training data.</li><li style="margin-bottom: 5px;">Model poisoning attacks manipulate machine learning models.</li><li style="margin-bottom: 5px;">Prompt injection attacks exploit vulnerabilities in prompt-based systems.</li><li style="margin-bottom: 5px;">Indirect prompt injection attacks involve manipulating systems through indirect means.</li><li style="margin-bottom: 5px;">Availability attacks target system availability.</li> </ul> </div> <div style="margin-bottom: 20px;"> <span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> AI </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Adversarial Machine Learning </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Taxonomy </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Terminology </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Attacks </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Mitigations </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> NIST </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Trustworthy AI </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Responsible AI </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> attacker capabilities </span> </div> <div style="margin-bottom: 20px;"> <span style="background: #dcfce7; color: #166534; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 10px;"> Machine Learning </span> <span style="background: #fed7aa; color: #9a3412; padding: 4px 12px; border-radius: 20px; font-size: 14px;"> Intermediate </span> </div> <div style="margin-bottom: 20px;"> <a href="https://raw.githubusercontent.com/lonardonifabio/tech_documents/main/documents/Adversarial_Machine_Learning_1743431306.pdf" target="_blank" rel="noopener noreferrer" style="background: #2563eb; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; margin-right: 10px; display: inline-block;">
üì• Download PDF
</a> <a href="https://lonardonifabio.github.io/tech_documents/?doc=2c5334041419e90fa983e2b098a44614" style="background: #16a34a; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; display: inline-block;">
üîç View in Library
</a> </div> <div style="background: #eff6ff; padding: 15px; border-radius: 8px; border-left: 4px solid #3b82f6;"> <p style="color: #1e40af; font-size: 14px; margin: 0;"> <strong>Note:</strong> You will be automatically redirected to the interactive document library. 
            If the redirect doesn't work, <a href="https://lonardonifabio.github.io/tech_documents/?doc=2c5334041419e90fa983e2b098a44614" style="color: #1e40af; text-decoration: underline;">click here</a>.
</p> </div> </div> </div> </body></html>