<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="This research paper investigates the extent to which language models memorize information from their training datasets. The authors introduce a novel method for quantifying memorization, distinguishing between 'unintended memorization' – the model's knowledge derived directly from the dataset – a..."><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/tech_documents/favicon.svg"><title>How much do language models memorize?</title><!-- Enhanced Open Graph for LinkedIn sharing --><meta property="og:title" content="How much do language models memorize?"><meta property="og:description" content="This research paper investigates the extent to which language models memorize information from their training datasets. The authors introduce a novel method for quantifying memorization, distinguishing between 'unintended memorization' – the model's knowledge derived directly from the dataset – a..."><meta property="og:type" content="article"><meta property="og:url" content="https://lonardonifabio.github.io/tech_documents/share/870c5bde64d95c3de9ff5c8474ee4c58"><meta property="og:image" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:secure_url" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="How much do language models memorize? - AI &#38; Data Science Document Library"><meta property="og:site_name" content="AI & Data Science Document Library"><meta property="og:locale" content="en_US"><meta property="article:author" content="Fabio Lonardoni"><meta property="article:section" content="Technology"><meta property="article:tag" content="language models, memorization, capacity, scaling laws, transformer language models, data size, membership inference, GPT family, unintended memorization, entropy"><meta property="article:published_time" content="2025-06-23T22:00:43.412286"><!-- LinkedIn specific meta tags --><meta property="linkedin:owner" content="Fabio Lonardoni"><meta property="og:rich_attachment" content="true"><!-- Additional meta for mobile sharing --><meta name="author" content="John X. Morris, Chawin Sitawarin, Chuan Guo, Narine Kokhlikyan, G. Edward Suh, Alexander M. Rush, Kamalika Chaudhuri, Saeed Mahloujifar"><meta name="keywords" content="language models, memorization, capacity, scaling laws, transformer language models, data size, membership inference, GPT family, unintended memorization, entropy"><meta name="robots" content="index, follow"><link rel="canonical" href="https://lonardonifabio.github.io/tech_documents/share/870c5bde64d95c3de9ff5c8474ee4c58"><!-- Immediate redirect to main app --><script>(function(){const mainAppUrl = "https://lonardonifabio.github.io/tech_documents/?doc=870c5bde64d95c3de9ff5c8474ee4c58";

      // Immediate redirect for users (crawlers will read meta tags first)
      if (typeof window !== 'undefined') {
        window.location.replace(mainAppUrl);
      }
    })();</script><!-- Fallback meta refresh for non-JS environments --><meta http-equiv="refresh" content="0; url={mainAppUrl}"><link rel="stylesheet" href="/tech_documents/assets/_id_.B2K7fHu1.css"></head> <body class="bg-gray-50 min-h-screen"> <!-- Fallback content for crawlers and users with JS disabled --> <div style="max-width: 800px; margin: 0 auto; padding: 20px; font-family: system-ui, sans-serif;"> <div style="background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);"> <h1 style="color: #1f2937; margin-bottom: 20px;">How much do language models memorize?</h1> <div style="margin-bottom: 15px;"> <p style="color: #6b7280;"> <strong>Authors:</strong> John X. Morris, Chawin Sitawarin, Chuan Guo, Narine Kokhlikyan, G. Edward Suh, Alexander M. Rush, Kamalika Chaudhuri, Saeed Mahloujifar </p> </div> <div style="margin-bottom: 20px;"> <p style="color: #374151; line-height: 1.6;">This research paper investigates the extent to which language models memorize information from their training datasets. The authors introduce a novel method for quantifying memorization, distinguishing between &#39;unintended memorization&#39; – the model&#39;s knowledge derived directly from the dataset – and &#39;generalization,&#39; which represents the model&#39;s understanding of the underlying data generation process.  By isolating and measuring unintended memorization, the researchers aim to determine the true capacity of modern language models, such as those within the GPT family.  Their experiments involved training hundreds of transformer language models, ranging in size from 500,000 to 1.5 billion parameters, across various dataset sizes (170K, 500K, 2.5M, 7M).  The study reveals a clear relationship between model size, data size, and memorization capacity. Initially, models exhibit increasing memorization as their capacity fills. However, beyond a certain point, &#39;grokking&#39; occurs, where unintended memorization plateaus, and the model begins to generalize, effectively reducing the amount of direct memorization.  The research culminates in an estimated capacity of approximately 3.6 bits-per-parameter for models in the GPT family.  The authors also explore scaling laws relating model capacity and data size to membership inference, providing valuable insights into the behavior of large language models. The paper&#39;s findings contribute to a better understanding of model capacity and the mechanisms underlying memorization in neural networks.  The research is significant for assessing the risks associated with model deployment and for guiding the development of more robust and generalizable language models.  The methodology and results presented offer a framework for future research in this critical area.</p> </div> <div style="margin-bottom: 20px;"> <h3 style="color: #1f2937; margin-bottom: 10px;">Key Concepts:</h3> <ul style="color: #374151;"> <li style="margin-bottom: 5px;">The study of how much information language models memorize.</li><li style="margin-bottom: 5px;">Separation of memorization into unintended memorization and generalization.</li><li style="margin-bottom: 5px;">Capacity of language models is determined by the amount of memorized data.</li><li style="margin-bottom: 5px;">Models exhibit ‘grokking’ when their capacity is filled, leading to decreased unintended memorization.</li><li style="margin-bottom: 5px;">Super-additivity of Unintended Memorization</li><li style="margin-bottom: 5px;">Entropy-based notion of information</li><li style="margin-bottom: 5px;">Single underlying model</li><li style="margin-bottom: 5px;">Dataset level measurement</li><li style="margin-bottom: 5px;">Unintended memorization of models during pre-training.</li><li style="margin-bottom: 5px;">Measuring extraction rates accurately through deduplication.</li> </ul> </div> <div style="margin-bottom: 20px;"> <span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> language models </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> memorization </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> capacity </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> scaling laws </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> transformer language models </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> data size </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> membership inference </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> GPT family </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> unintended memorization </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> entropy </span> </div> <div style="margin-bottom: 20px;"> <span style="background: #dcfce7; color: #166534; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 10px;"> Technology </span> <span style="background: #fed7aa; color: #9a3412; padding: 4px 12px; border-radius: 20px; font-size: 14px;"> Intermediate </span> </div> <div style="margin-bottom: 20px;"> <a href="https://raw.githubusercontent.com/lonardonifabio/tech_documents/main/documents/LLM_memory_Google_Meta_Cornell_1750055868.pdf" target="_blank" rel="noopener noreferrer" style="background: #2563eb; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; margin-right: 10px; display: inline-block;">
📥 Download PDF
</a> <a href="https://lonardonifabio.github.io/tech_documents/?doc=870c5bde64d95c3de9ff5c8474ee4c58" style="background: #16a34a; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; display: inline-block;">
🔍 View in Library
</a> </div> <div style="background: #eff6ff; padding: 15px; border-radius: 8px; border-left: 4px solid #3b82f6;"> <p style="color: #1e40af; font-size: 14px; margin: 0;"> <strong>Note:</strong> You will be automatically redirected to the interactive document library. 
            If the redirect doesn't work, <a href="https://lonardonifabio.github.io/tech_documents/?doc=870c5bde64d95c3de9ff5c8474ee4c58" style="color: #1e40af; text-decoration: underline;">click here</a>.
</p> </div> </div> </div> </body></html>