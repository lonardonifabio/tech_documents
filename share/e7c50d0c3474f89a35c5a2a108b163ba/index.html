<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="This document provides a foundational overview of probability theory, focusing on key definitions and axioms. It begins by defining a sample space as the set of all possible outcomes, emphasizing that its elements must be mutually exclusive, collectively exhaustive, and at the appropriate granula..."><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/tech_documents/favicon.svg"><title>Probability Fundamentals: Definitions and Axioms</title><!-- Enhanced Open Graph for LinkedIn sharing --><meta property="og:title" content="Probability Fundamentals: Definitions and Axioms"><meta property="og:description" content="This document provides a foundational overview of probability theory, focusing on key definitions and axioms. It begins by defining a sample space as the set of all possible outcomes, emphasizing that its elements must be mutually exclusive, collectively exhaustive, and at the appropriate granula..."><meta property="og:type" content="article"><meta property="og:url" content="https://lonardonifabio.github.io/tech_documents/share/e7c50d0c3474f89a35c5a2a108b163ba"><meta property="og:image" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:secure_url" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="Probability Fundamentals: Definitions and Axioms - AI &#38; Data Science Document Library"><meta property="og:site_name" content="AI & Data Science Document Library"><meta property="og:locale" content="en_US"><meta property="article:author" content="Fabio Lonardoni"><meta property="article:section" content="AI"><meta property="article:tag" content="Probability, Sample Space, Event, Probability Axioms, Bayes' rule, Conditional Probability, Discrete Uniform Law, continuous random variables, joint distribution, conditional expectation"><meta property="article:published_time" content="2025-07-01T15:28:43.366944"><!-- LinkedIn specific meta tags --><meta property="linkedin:owner" content="Fabio Lonardoni"><meta property="og:rich_attachment" content="true"><!-- Additional meta for mobile sharing --><meta name="author" content="Stanford University, Massachusetts Institute of Technology"><meta name="keywords" content="Probability, Sample Space, Event, Probability Axioms, Bayes' rule, Conditional Probability, Discrete Uniform Law, continuous random variables, joint distribution, conditional expectation"><meta name="robots" content="index, follow"><link rel="canonical" href="https://lonardonifabio.github.io/tech_documents/share/e7c50d0c3474f89a35c5a2a108b163ba"><!-- Immediate redirect to main app --><script>(function(){const mainAppUrl = "https://lonardonifabio.github.io/tech_documents/?doc=e7c50d0c3474f89a35c5a2a108b163ba";

      // Immediate redirect for users (crawlers will read meta tags first)
      if (typeof window !== 'undefined') {
        window.location.replace(mainAppUrl);
      }
    })();</script><!-- Fallback meta refresh for non-JS environments --><meta http-equiv="refresh" content="0; url={mainAppUrl}"><link rel="stylesheet" href="/tech_documents/assets/_id_.bQYxGZ17.css"></head> <body class="bg-gray-50 min-h-screen"> <!-- Fallback content for crawlers and users with JS disabled --> <div style="max-width: 800px; margin: 0 auto; padding: 20px; font-family: system-ui, sans-serif;"> <div style="background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);"> <h1 style="color: #1f2937; margin-bottom: 20px;">Probability Fundamentals: Definitions and Axioms</h1> <div style="margin-bottom: 15px;"> <p style="color: #6b7280;"> <strong>Authors:</strong> Stanford University, Massachusetts Institute of Technology </p> </div> <div style="margin-bottom: 20px;"> <p style="color: #374151; line-height: 1.6;">This document provides a foundational overview of probability theory, focusing on key definitions and axioms. It begins by defining a sample space as the set of all possible outcomes, emphasizing that its elements must be mutually exclusive, collectively exhaustive, and at the appropriate granularity.  The concept of an event is then introduced as a subset of the sample space, with probability assigned to each event.  The core axioms of probability are detailed: non-negativity (P(A) ‚â• 0 for all events A), normalization (P( ) = 1), and additivity (for any sequence of events, the probability of the union is the sum of their individual probabilities).  Several corollaries stemming from these axioms are also presented, including P(A) + P(Ac) = 1, P(A) ‚â§ 1, and the relationship between the probability of a subset and its superset.  The document further explores the concept of conditional probability, defining it as P(A|B) = P(A‚à©B) / P(B), which represents the probability of event A occurring given that event B has already occurred.  The excerpt highlights the importance of understanding these fundamental principles for analyzing uncertainty and data. The document&#39;s focus is on establishing a rigorous mathematical framework for probability, laying the groundwork for more advanced topics within the field. It provides a concise yet comprehensive introduction to the core concepts and rules governing probability calculations.</p> </div> <div style="margin-bottom: 20px;"> <h3 style="color: #1f2937; margin-bottom: 10px;">Key Concepts:</h3> <ul style="color: #374151;"> <li style="margin-bottom: 5px;">Probability as the science of uncertainty and data</li><li style="margin-bottom: 5px;">Sample space definition (set of all possible outcomes)</li><li style="margin-bottom: 5px;">Event definition (subset of the sample space)</li><li style="margin-bottom: 5px;">Probability axioms (Nonnegativity, Normalization, Additivity)</li><li style="margin-bottom: 5px;">Bayes&#39; rule (Conditional probability)</li><li style="margin-bottom: 5px;">Discrete uniform law (probability of a subset)</li><li style="margin-bottom: 5px;">The conditional expected value of X given Y is calculated using integration.</li><li style="margin-bottom: 5px;">Jointly continuous random variables are independent if their joint distribution equals the product of their individual distributions.</li><li style="margin-bottom: 5px;">The total probability theorem relates the joint distribution to the individual distributions.</li><li style="margin-bottom: 5px;">Bayes&#39; rule provides a formula for updating probabilities based on evidence.</li> </ul> </div> <div style="margin-bottom: 20px;"> <span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Probability </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Sample Space </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Event </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Probability Axioms </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Bayes&#39; rule </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Conditional Probability </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Discrete Uniform Law </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> continuous random variables </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> joint distribution </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> conditional expectation </span> </div> <div style="margin-bottom: 20px;"> <span style="background: #dcfce7; color: #166534; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 10px;"> AI </span> <span style="background: #fed7aa; color: #9a3412; padding: 4px 12px; border-radius: 20px; font-size: 14px;"> Intermediate </span> </div> <div style="margin-bottom: 20px;"> <a href="https://raw.githubusercontent.com/lonardonifabio/tech_documents/main/documents/Stanford_MIT_on_AI_1737374742.pdf" target="_blank" rel="noopener noreferrer" style="background: #2563eb; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; margin-right: 10px; display: inline-block;">
üì• Download PDF
</a> <a href="https://lonardonifabio.github.io/tech_documents/?doc=e7c50d0c3474f89a35c5a2a108b163ba" style="background: #16a34a; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; display: inline-block;">
üîç View in Library
</a> </div> <div style="background: #eff6ff; padding: 15px; border-radius: 8px; border-left: 4px solid #3b82f6;"> <p style="color: #1e40af; font-size: 14px; margin: 0;"> <strong>Note:</strong> You will be automatically redirected to the interactive document library. 
            If the redirect doesn't work, <a href="https://lonardonifabio.github.io/tech_documents/?doc=e7c50d0c3474f89a35c5a2a108b163ba" style="color: #1e40af; text-decoration: underline;">click here</a>.
</p> </div> </div> </div> </body></html>