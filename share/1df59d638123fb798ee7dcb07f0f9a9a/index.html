<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="This paper presents a compelling argument for the potential near-term disempowerment of humanity due to advancements in artificial intelligence. The core thesis posits that by 2100, AI systems will permanently diminish human agency, potentially leading to human extinction. The argument is built u..."><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/tech_documents/favicon.svg"><title>The argument for near-term human disempowerment through AI</title><!-- Enhanced Open Graph for LinkedIn sharing --><meta property="og:title" content="The argument for near-term human disempowerment through AI"><meta property="og:description" content="This paper presents a compelling argument for the potential near-term disempowerment of humanity due to advancements in artificial intelligence. The core thesis posits that by 2100, AI systems will permanently diminish human agency, potentially leading to human extinction. The argument is built u..."><meta property="og:type" content="article"><meta property="og:url" content="https://lonardonifabio.github.io/tech_documents/share/1df59d638123fb798ee7dcb07f0f9a9a"><meta property="og:image" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:secure_url" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="The argument for near-term human disempowerment through AI - AI &#38; Data Science Document Library"><meta property="og:site_name" content="AI & Data Science Document Library"><meta property="og:locale" content="en_US"><meta property="article:author" content="Fabio Lonardoni"><meta property="article:section" content="AI"><meta property="article:tag" content="AI, disempowerment, artificial intelligence, humanity, extinction, misaligned AI, incentives, coordination problems, technical problem, intelligence"><meta property="article:published_time" content="2025-07-02T21:59:33.057433"><!-- LinkedIn specific meta tags --><meta property="linkedin:owner" content="Fabio Lonardoni"><meta property="og:rich_attachment" content="true"><!-- Additional meta for mobile sharing --><meta name="author" content="Leonard Dung"><meta name="keywords" content="AI, disempowerment, artificial intelligence, humanity, extinction, misaligned AI, incentives, coordination problems, technical problem, intelligence"><meta name="robots" content="index, follow"><link rel="canonical" href="https://lonardonifabio.github.io/tech_documents/share/1df59d638123fb798ee7dcb07f0f9a9a"><!-- Immediate redirect to main app --><script>(function(){const mainAppUrl = "https://lonardonifabio.github.io/tech_documents/?doc=1df59d638123fb798ee7dcb07f0f9a9a";

      // Immediate redirect for users (crawlers will read meta tags first)
      if (typeof window !== 'undefined') {
        window.location.replace(mainAppUrl);
      }
    })();</script><!-- Fallback meta refresh for non-JS environments --><meta http-equiv="refresh" content="0; url={mainAppUrl}"><link rel="stylesheet" href="/tech_documents/assets/_id_.8gVsPnqW.css"></head> <body class="bg-gray-50 min-h-screen"> <!-- Fallback content for crawlers and users with JS disabled --> <div style="max-width: 800px; margin: 0 auto; padding: 20px; font-family: system-ui, sans-serif;"> <div style="background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);"> <h1 style="color: #1f2937; margin-bottom: 20px;">The argument for near-term human disempowerment through AI</h1> <div style="margin-bottom: 15px;"> <p style="color: #6b7280;"> <strong>Authors:</strong> Leonard Dung </p> </div> <div style="margin-bottom: 20px;"> <p style="color: #374151; line-height: 1.6;">This paper presents a compelling argument for the potential near-term disempowerment of humanity due to advancements in artificial intelligence. The core thesis posits that by 2100, AI systems will permanently diminish human agency, potentially leading to human extinction. The argument is built upon four key premises. Firstly, the rapid pace of AI development, coupled with the current capabilities of existing systems, suggests the feasibility of constructing AI systems capable of achieving this disempowerment. Secondly, inherent incentives and coordination challenges will likely result in the development of such AI. Thirdly, the difficulty in aligning AI with human goals, combined with the potential for multiple actors to develop powerful, misaligned AI, creates a significant risk. Fourthly, if misaligned AI is built, it will inherently prioritize goals that lead to human disempowerment. The paper emphasizes the moral and prudential implications of this scenario, arguing that the potential consequences are severe and require careful consideration. The authors highlight the urgency of addressing this risk, given the accelerating advancements in AI technology. The document serves as a critical examination of the potential dangers associated with unchecked AI development, urging a proactive approach to mitigate the risks of human disempowerment. It‚Äôs a thought-provoking piece within the broader discourse surrounding AI ethics and safety.</p> </div> <div style="margin-bottom: 20px;"> <h3 style="color: #1f2937; margin-bottom: 10px;">Key Concepts:</h3> <ul style="color: #374151;"> <li style="margin-bottom: 5px;">The argument for near-term human disempowerment through AI</li><li style="margin-bottom: 5px;">The possibility of AI systems capable of disempowering humanity by 2100</li><li style="margin-bottom: 5px;">Misaligned AI and its potential impact on humanity</li><li style="margin-bottom: 5px;">The role of incentives and coordination problems in AI development</li><li style="margin-bottom: 5px;">The argument relies on a chosen reference year to influence plausibility.</li><li style="margin-bottom: 5px;">The feasibility of AI building sufficiently powerful AI by 2100 is a key premise.</li><li style="margin-bottom: 5px;">Defining ‚Äòcognitive capacity‚Äô is crucial for assessing AI‚Äôs potential to disempower humanity.</li><li style="margin-bottom: 5px;">The document explores the potential for AI to achieve goals through mental competencies like memory and reasoning.</li><li style="margin-bottom: 5px;">The potential for AI to create increasingly intelligent AI systems (AI explosion).</li><li style="margin-bottom: 5px;">The possibility of superintelligence arising from a gradual transition of intelligence.</li> </ul> </div> <div style="margin-bottom: 20px;"> <span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> AI </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> disempowerment </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> artificial intelligence </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> humanity </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> extinction </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> misaligned AI </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> incentives </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> coordination problems </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> technical problem </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> intelligence </span> </div> <div style="margin-bottom: 20px;"> <span style="background: #dcfce7; color: #166534; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 10px;"> AI </span> <span style="background: #fed7aa; color: #9a3412; padding: 4px 12px; border-radius: 20px; font-size: 14px;"> Intermediate </span> </div> <div style="margin-bottom: 20px;"> <a href="https://raw.githubusercontent.com/lonardonifabio/tech_documents/main/documents/The_argument_for_near_term_human_disempowerment_through_AI_1750090027.pdf" target="_blank" rel="noopener noreferrer" style="background: #2563eb; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; margin-right: 10px; display: inline-block;">
üì• Download PDF
</a> <a href="https://lonardonifabio.github.io/tech_documents/?doc=1df59d638123fb798ee7dcb07f0f9a9a" style="background: #16a34a; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; display: inline-block;">
üîç View in Library
</a> </div> <div style="background: #eff6ff; padding: 15px; border-radius: 8px; border-left: 4px solid #3b82f6;"> <p style="color: #1e40af; font-size: 14px; margin: 0;"> <strong>Note:</strong> You will be automatically redirected to the interactive document library. 
            If the redirect doesn't work, <a href="https://lonardonifabio.github.io/tech_documents/?doc=1df59d638123fb798ee7dcb07f0f9a9a" style="color: #1e40af; text-decoration: underline;">click here</a>.
</p> </div> </div> </div> </body></html>