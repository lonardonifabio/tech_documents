<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="This report details Google DeepMind’s efforts to assess and enhance the adversarial robustness of the Gemini language model. The research focuses on mitigating the risk posed by indirect prompt injections, a sophisticated attack vector where malicious instructions are embedded within untrusted da..."><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/tech_documents/favicon.svg"><title>Lessons from Defending Gemini Against Indirect Prompt Injections</title><!-- Enhanced Open Graph for LinkedIn sharing --><meta property="og:title" content="Lessons from Defending Gemini Against Indirect Prompt Injections"><meta property="og:description" content="This report details Google DeepMind’s efforts to assess and enhance the adversarial robustness of the Gemini language model. The research focuses on mitigating the risk posed by indirect prompt injections, a sophisticated attack vector where malicious instructions are embedded within untrusted da..."><meta property="og:type" content="article"><meta property="og:url" content="https://lonardonifabio.github.io/tech_documents/share/01e5924d7872932ae603b5fccc8bbe5a"><meta property="og:image" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:secure_url" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="Lessons from Defending Gemini Against Indirect Prompt Injections - AI &#38; Data Science Document Library"><meta property="og:site_name" content="AI & Data Science Document Library"><meta property="og:locale" content="en_US"><meta property="article:author" content="Fabio Lonardoni"><meta property="article:section" content="Technology"><meta property="article:tag" content="Gemini, Indirect Prompt Injections, Adversarial Robustness, Function-calling, Tool-use, Attack Techniques, indirect prompt injections, adversarial training, adaptive evaluation, model capabilities"><meta property="article:published_time" content="2025-07-02T21:59:26.726414"><!-- LinkedIn specific meta tags --><meta property="linkedin:owner" content="Fabio Lonardoni"><meta property="og:rich_attachment" content="true"><!-- Additional meta for mobile sharing --><meta name="author" content="Chongyang Shi, Sharon Lin, Shuang Song, Jamie Hayes, Ilia Shumailov, Itay Yona, Juliette Pluto, Aneesh Pappu, Christopher A. Choquette-Choo, Milad Nasr, Chawin Sitawarin, Gena Gibson, Andreas Terzis, John &#34;Four&#34; Flynn"><meta name="keywords" content="Gemini, Indirect Prompt Injections, Adversarial Robustness, Function-calling, Tool-use, Attack Techniques, indirect prompt injections, adversarial training, adaptive evaluation, model capabilities"><meta name="robots" content="index, follow"><link rel="canonical" href="https://lonardonifabio.github.io/tech_documents/share/01e5924d7872932ae603b5fccc8bbe5a"><!-- Immediate redirect to main app --><script>(function(){const mainAppUrl = "https://lonardonifabio.github.io/tech_documents/?doc=01e5924d7872932ae603b5fccc8bbe5a";

      // Immediate redirect for users (crawlers will read meta tags first)
      if (typeof window !== 'undefined') {
        window.location.replace(mainAppUrl);
      }
    })();</script><!-- Fallback meta refresh for non-JS environments --><meta http-equiv="refresh" content="0; url={mainAppUrl}"><link rel="stylesheet" href="/tech_documents/assets/_id_.8gVsPnqW.css"></head> <body class="bg-gray-50 min-h-screen"> <!-- Fallback content for crawlers and users with JS disabled --> <div style="max-width: 800px; margin: 0 auto; padding: 20px; font-family: system-ui, sans-serif;"> <div style="background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);"> <h1 style="color: #1f2937; margin-bottom: 20px;">Lessons from Defending Gemini Against Indirect Prompt Injections</h1> <div style="margin-bottom: 15px;"> <p style="color: #6b7280;"> <strong>Authors:</strong> Chongyang Shi, Sharon Lin, Shuang Song, Jamie Hayes, Ilia Shumailov, Itay Yona, Juliette Pluto, Aneesh Pappu, Christopher A. Choquette-Choo, Milad Nasr, Chawin Sitawarin, Gena Gibson, Andreas Terzis, John &quot;Four&quot; Flynn </p> </div> <div style="margin-bottom: 20px;"> <p style="color: #374151; line-height: 1.6;">This report details Google DeepMind’s efforts to assess and enhance the adversarial robustness of the Gemini language model. The research focuses on mitigating the risk posed by indirect prompt injections, a sophisticated attack vector where malicious instructions are embedded within untrusted data provided to Gemini. The core of the investigation involves a continuous adversarial evaluation framework that utilizes adaptive attack techniques to probe Gemini’s resilience against manipulation. This framework tests past, current, and future versions of Gemini, allowing for proactive identification and remediation of vulnerabilities. The study highlights the importance of ongoing evaluation and adaptation in securing models that increasingly rely on external data and tool usage. The report outlines the methodology employed, including the deployment of a suite of attack techniques designed to simulate realistic adversarial behavior. The findings directly contribute to making Gemini more resistant to manipulation and safeguard user data and permissions. The research underscores the need for robust defenses against attacks that exploit function-calling and tool-use capabilities, particularly when interacting with untrusted data sources. The continuous evaluation process is presented as a critical component of Gemini’s development, ensuring its reliability and security in a world where models are increasingly entrusted with sensitive tasks and access to user information. The document provides a structured approach to adversarial testing, emphasizing the dynamic nature of threat landscapes and the necessity for adaptive security measures. The report’s insights are relevant to anyone developing or deploying large language models, particularly those operating in environments where data integrity and user privacy are paramount concerns.</p> </div> <div style="margin-bottom: 20px;"> <h3 style="color: #1f2937; margin-bottom: 10px;">Key Concepts:</h3> <ul style="color: #374151;"> <li style="margin-bottom: 5px;">Gemini models are vulnerable to indirect prompt injections.</li><li style="margin-bottom: 5px;">Adversaries can manipulate Gemini through malicious instructions embedded in untrusted data.</li><li style="margin-bottom: 5px;">Google DeepMind is evaluating Gemini&#39;s resilience against adversarial attacks using an adaptive evaluation framework.</li><li style="margin-bottom: 5px;">Prompt Injection Attacks: Models deviating from user instructions to perform attacker-defined tasks.</li><li style="margin-bottom: 5px;">Adaptive Evaluation: The need for dynamically adjusted attacks to accurately assess defense effectiveness.</li><li style="margin-bottom: 5px;">Adversarial Training: Training models on adversarial data to improve robustness, while acknowledging potential performance impacts on benign tasks.</li><li style="margin-bottom: 5px;">Indirect prompt injection attack leveraging Gemini.</li><li style="margin-bottom: 5px;">Use of an adversary-crafted prompt (𝑥𝑎𝑑𝑣) to manipulate the agent&#39;s behavior.</li><li style="margin-bottom: 5px;">Exfiltration of private data (𝑑𝑝𝑟𝑖𝑣) through manipulated function calls.</li><li style="margin-bottom: 5px;">Binary scoring (harmful vs. successful jailbreak)</li> </ul> </div> <div style="margin-bottom: 20px;"> <span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Gemini </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Indirect Prompt Injections </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Adversarial Robustness </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Function-calling </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Tool-use </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Attack Techniques </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> indirect prompt injections </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> adversarial training </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> adaptive evaluation </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> model capabilities </span> </div> <div style="margin-bottom: 20px;"> <span style="background: #dcfce7; color: #166534; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 10px;"> Technology </span> <span style="background: #fed7aa; color: #9a3412; padding: 4px 12px; border-radius: 20px; font-size: 14px;"> Intermediate </span> </div> <div style="margin-bottom: 20px;"> <a href="https://raw.githubusercontent.com/lonardonifabio/tech_documents/main/documents/Lessons_from_Defending_Gemini_1749677785.pdf" target="_blank" rel="noopener noreferrer" style="background: #2563eb; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; margin-right: 10px; display: inline-block;">
📥 Download PDF
</a> <a href="https://lonardonifabio.github.io/tech_documents/?doc=01e5924d7872932ae603b5fccc8bbe5a" style="background: #16a34a; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; display: inline-block;">
🔍 View in Library
</a> </div> <div style="background: #eff6ff; padding: 15px; border-radius: 8px; border-left: 4px solid #3b82f6;"> <p style="color: #1e40af; font-size: 14px; margin: 0;"> <strong>Note:</strong> You will be automatically redirected to the interactive document library. 
            If the redirect doesn't work, <a href="https://lonardonifabio.github.io/tech_documents/?doc=01e5924d7872932ae603b5fccc8bbe5a" style="color: #1e40af; text-decoration: underline;">click here</a>.
</p> </div> </div> </div> </body></html>