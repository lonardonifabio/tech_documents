<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="This document outlines a Code of Practice designed to enhance the safety and security of general-purpose AI models within the European Union. The primary goal is to foster the adoption of human-centric and trustworthy AI, aligning with the principles of the AI Act. Specifically, the Code aims to ..."><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/tech_documents/favicon.svg"><title>Code of Practice for General-Purpose AI Models Safety and Security</title><!-- Enhanced Open Graph for LinkedIn sharing --><meta property="og:title" content="Code of Practice for General-Purpose AI Models Safety and Security"><meta property="og:description" content="This document outlines a Code of Practice designed to enhance the safety and security of general-purpose AI models within the European Union. The primary goal is to foster the adoption of human-centric and trustworthy AI, aligning with the principles of the AI Act. Specifically, the Code aims to ..."><meta property="og:type" content="article"><meta property="og:url" content="https://lonardonifabio.github.io/tech_documents/share/2f83c783166e3c354b5fcdbb440dc85d"><meta property="og:image" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:secure_url" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="Code of Practice for General-Purpose AI Models Safety and Security - AI &#38; Data Science Document Library"><meta property="og:site_name" content="AI & Data Science Document Library"><meta property="og:locale" content="en_US"><meta property="article:author" content="Fabio Lonardoni"><meta property="article:section" content="AI"><meta property="article:tag" content="AI Act, General-purpose AI models, Compliance, Trustworthy AI, Human-centric AI, AI Office, systemic risk, systemic risk tiers, model, framework"><meta property="article:published_time" content="2025-07-10T15:08:11"><!-- LinkedIn specific meta tags --><meta property="linkedin:owner" content="Fabio Lonardoni"><meta property="og:rich_attachment" content="true"><!-- Additional meta for mobile sharing --><meta name="author" content="Matthias Samwald, Yoshua Bengio, Marietje Schaake, Marta Ziosi, Daniel Privitera, Anka Reuel, Alexander Zacherl, Nitarshan Rajkumar, Markus Anderljung"><meta name="keywords" content="AI Act, General-purpose AI models, Compliance, Trustworthy AI, Human-centric AI, AI Office, systemic risk, systemic risk tiers, model, framework"><meta name="robots" content="index, follow"><link rel="canonical" href="https://lonardonifabio.github.io/tech_documents/share/2f83c783166e3c354b5fcdbb440dc85d"><!-- Immediate redirect to main app --><script>(function(){const mainAppUrl = "https://lonardonifabio.github.io/tech_documents/?doc=2f83c783166e3c354b5fcdbb440dc85d";

      // Immediate redirect for users (crawlers will read meta tags first)
      if (typeof window !== 'undefined') {
        window.location.replace(mainAppUrl);
      }
    })();</script><!-- Fallback meta refresh for non-JS environments --><meta http-equiv="refresh" content="0; url={mainAppUrl}"><link rel="stylesheet" href="/tech_documents/assets/_id_.B2K7fHu1.css"></head> <body class="bg-gray-50 min-h-screen"> <!-- Fallback content for crawlers and users with JS disabled --> <div style="max-width: 800px; margin: 0 auto; padding: 20px; font-family: system-ui, sans-serif;"> <div style="background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);"> <h1 style="color: #1f2937; margin-bottom: 20px;">Code of Practice for General-Purpose AI Models Safety and Security</h1> <div style="margin-bottom: 15px;"> <p style="color: #6b7280;"> <strong>Authors:</strong> Matthias Samwald, Yoshua Bengio, Marietje Schaake, Marta Ziosi, Daniel Privitera, Anka Reuel, Alexander Zacherl, Nitarshan Rajkumar, Markus Anderljung </p> </div> <div style="margin-bottom: 20px;"> <p style="color: #374151; line-height: 1.6;">This document outlines a Code of Practice designed to enhance the safety and security of general-purpose AI models within the European Union. The primary goal is to foster the adoption of human-centric and trustworthy AI, aligning with the principles of the AI Act. Specifically, the Code aims to improve the functioning of the internal market and safeguard fundamental rights, including democracy, the rule of law, and environmental protection, against potential harms arising from AI. It serves as a guiding document for demonstrating compliance with Articles 53 and 55 of the AI Act, acknowledging that adherence to the Code doesn&#39;t guarantee full compliance with the AI Act&#39;s obligations. The Code targets AI model providers, enabling the AI Office to evaluate their adherence to the Act.  The document emphasizes a proactive approach to mitigating risks associated with AI, promoting responsible innovation while upholding ethical and legal standards. It&#39;s a key component in the broader regulatory framework surrounding AI development and deployment within the EU, focusing on accountability and transparency. The Code&#39;s implementation is crucial for ensuring that general-purpose AI models are developed and used in a manner that respects human rights and societal values.  The document&#39;s creation reflects the growing need for robust governance mechanisms in the rapidly evolving field of artificial intelligence, particularly as AI systems become increasingly integrated into various aspects of life.  The Code&#39;s objectives are directly linked to the broader ambitions of the AI Act, which seeks to establish a harmonized regulatory landscape for AI across the European Union.</p> </div> <div style="margin-bottom: 20px;"> <h3 style="color: #1f2937; margin-bottom: 10px;">Key Concepts:</h3> <ul style="color: #374151;"> <li style="margin-bottom: 5px;">Code of Practice for AI Models</li><li style="margin-bottom: 5px;">Improving the functioning of the internal market</li><li style="margin-bottom: 5px;">Protection of health, safety, and fundamental rights</li><li style="margin-bottom: 5px;">Innovation support</li><li style="margin-bottom: 5px;">Systemic risk acceptance criteria definition and justification</li><li style="margin-bottom: 5px;">High-level description of safety and security mitigations for different risk tiers</li><li style="margin-bottom: 5px;">Estimates of timelines for model development exceeding risk tiers</li><li style="margin-bottom: 5px;">Allocation of systemic risk responsibility</li><li style="margin-bottom: 5px;">Determining acceptable systemic risk based on Measure 4.1.</li><li style="margin-bottom: 5px;">Updating Model Reports based on Measure 7.6.</li> </ul> </div> <div style="margin-bottom: 20px;"> <span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> AI Act </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> General-purpose AI models </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Compliance </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Trustworthy AI </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Human-centric AI </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> AI Office </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> systemic risk </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> systemic risk tiers </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> model </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> framework </span> </div> <div style="margin-bottom: 20px;"> <span style="background: #dcfce7; color: #166534; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 10px;"> AI </span> <span style="background: #fed7aa; color: #9a3412; padding: 4px 12px; border-radius: 20px; font-size: 14px;"> Intermediate </span> </div> <div style="margin-bottom: 20px;"> <a href="https://raw.githubusercontent.com/lonardonifabio/tech_documents/main/documents/Code_of_Practice_for_GeneralPurpose_AI_Models_Safety_and_Security_Chapter_ssUDv1Co3EZxRH3L9TArvZCLQo_118119.pdf" target="_blank" rel="noopener noreferrer" style="background: #2563eb; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; margin-right: 10px; display: inline-block;">
üì• Download PDF
</a> <a href="https://lonardonifabio.github.io/tech_documents/?doc=2f83c783166e3c354b5fcdbb440dc85d" style="background: #16a34a; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; display: inline-block;">
üîç View in Library
</a> </div> <div style="background: #eff6ff; padding: 15px; border-radius: 8px; border-left: 4px solid #3b82f6;"> <p style="color: #1e40af; font-size: 14px; margin: 0;"> <strong>Note:</strong> You will be automatically redirected to the interactive document library. 
            If the redirect doesn't work, <a href="https://lonardonifabio.github.io/tech_documents/?doc=2f83c783166e3c354b5fcdbb440dc85d" style="color: #1e40af; text-decoration: underline;">click here</a>.
</p> </div> </div> </div> </body></html>