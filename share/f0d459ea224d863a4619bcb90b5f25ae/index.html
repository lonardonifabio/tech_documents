<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="This document provides a concise overview of several fundamental algorithms used in supervised and unsupervised learning. It focuses on the core aspects of each algorithm, including model objective, training process, regularization techniques, and computational complexity. The document begins wit..."><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/tech_documents/favicon.svg"><title>Algorithms for Supervised- and Unsupervised Learning</title><!-- Enhanced Open Graph for LinkedIn sharing --><meta property="og:title" content="Algorithms for Supervised- and Unsupervised Learning"><meta property="og:description" content="This document provides a concise overview of several fundamental algorithms used in supervised and unsupervised learning. It focuses on the core aspects of each algorithm, including model objective, training process, regularization techniques, and computational complexity. The document begins wit..."><meta property="og:type" content="article"><meta property="og:url" content="https://lonardonifabio.github.io/tech_documents/share/f0d459ea224d863a4619bcb90b5f25ae"><meta property="og:image" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:secure_url" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="Algorithms for Supervised- and Unsupervised Learning - AI &#38; Data Science Document Library"><meta property="og:site_name" content="AI & Data Science Document Library"><meta property="og:locale" content="en_US"><meta property="article:author" content="Fabio Lonardoni"><meta property="article:section" content="Machine Learning"><meta property="article:tag" content="algorithm, supervised learning, unsupervised learning, k-nearest neighbour, Euclidean distance, regularisation, likelihood, Bayes' rule, multinomial likelihood, Gaussian likelihood"><meta property="article:published_time" content="2025-06-29T15:45:00.696859"><!-- LinkedIn specific meta tags --><meta property="linkedin:owner" content="Fabio Lonardoni"><meta property="og:rich_attachment" content="true"><!-- Additional meta for mobile sharing --><meta name="author" content="Unknown"><meta name="keywords" content="algorithm, supervised learning, unsupervised learning, k-nearest neighbour, Euclidean distance, regularisation, likelihood, Bayes' rule, multinomial likelihood, Gaussian likelihood"><meta name="robots" content="index, follow"><link rel="canonical" href="https://lonardonifabio.github.io/tech_documents/share/f0d459ea224d863a4619bcb90b5f25ae"><!-- Immediate redirect to main app --><script>(function(){const mainAppUrl = "https://lonardonifabio.github.io/tech_documents/?doc=f0d459ea224d863a4619bcb90b5f25ae";

      // Immediate redirect for users (crawlers will read meta tags first)
      if (typeof window !== 'undefined') {
        window.location.replace(mainAppUrl);
      }
    })();</script><!-- Fallback meta refresh for non-JS environments --><meta http-equiv="refresh" content="0; url={mainAppUrl}"><link rel="stylesheet" href="/tech_documents/assets/_id_.DNY9BzS4.css"></head> <body class="bg-gray-50 min-h-screen"> <!-- Fallback content for crawlers and users with JS disabled --> <div style="max-width: 800px; margin: 0 auto; padding: 20px; font-family: system-ui, sans-serif;"> <div style="background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);"> <h1 style="color: #1f2937; margin-bottom: 20px;">Algorithms for Supervised- and Unsupervised Learning</h1> <div style="margin-bottom: 15px;"> <p style="color: #6b7280;"> <strong>Authors:</strong> Unknown </p> </div> <div style="margin-bottom: 20px;"> <p style="color: #374151; line-height: 1.6;">This document provides a concise overview of several fundamental algorithms used in supervised and unsupervised learning. It focuses on the core aspects of each algorithm, including model objective, training process, regularization techniques, and computational complexity. The document begins with a description of k-Nearest Neighbors (k-NN), a popular supervised learning algorithm. In k-NN, a new data point is classified based on the label of the nearest k training instances, utilizing Euclidean distance to determine proximity. The algorithm acts as a regularizer, smoothing the decision boundary as the value of &#39;k&#39; increases.  A key characteristic of k-NN is its ability to naturally identify non-linear boundaries. The document then moves on to Naive Bayes, a probabilistic classifier that leverages Bayes&#39; rule to estimate conditional probabilities.  Naive Bayes assumes feature independence, hence the name &#39;Naive.&#39; The model learns p(Ck|x) by modeling p(x|Ck) and p(Ck).  The algorithm maximizes the product of p(Ck|x) and p(x|Ck).  It employs multivariate likelihoods (Gaussian and Multinomial) for estimating probabilities. The Gaussian likelihood uses the multivariate likelihood p(x|Ck)=ÔøøD i=1logp(xi|Ck) and the Multinomial likelihood uses word counts. The document highlights the computational complexity of k-NN, noting that it requires storing all training instances and their features in memory, leading to a complexity of O(NM).  The document serves as a quick reference guide for understanding the basics of these algorithms, emphasizing their core principles and key considerations. It&#39;s a simplified explanation suitable for introductory learning or as a starting point for further exploration.</p> </div> <div style="margin-bottom: 20px;"> <h3 style="color: #1f2937; margin-bottom: 10px;">Key Concepts:</h3> <ul style="color: #374151;"> <li style="margin-bottom: 5px;">Classification based on nearest neighbors</li><li style="margin-bottom: 5px;">Model learning conditional probabilities (p(Ck|x) and p(Ck))</li><li style="margin-bottom: 5px;">Independent feature assumption (Naive Bayes)</li><li style="margin-bottom: 5px;">Optimization of model parameters using likelihood functions</li><li style="margin-bottom: 5px;">Cross-validation for parameter tuning (k)</li> </ul> </div> <div style="margin-bottom: 20px;"> <span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> algorithm </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> supervised learning </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> unsupervised learning </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> k-nearest neighbour </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Euclidean distance </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> regularisation </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> likelihood </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Bayes&#39; rule </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> multinomial likelihood </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Gaussian likelihood </span> </div> <div style="margin-bottom: 20px;"> <span style="background: #dcfce7; color: #166534; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 10px;"> Machine Learning </span> <span style="background: #fed7aa; color: #9a3412; padding: 4px 12px; border-radius: 20px; font-size: 14px;"> Intermediate </span> </div> <div style="margin-bottom: 20px;"> <a href="https://raw.githubusercontent.com/lonardonifabio/tech_documents/main/documents/Mathematics_of_Algorithms_Cheatsheet_1567887099.pdf" target="_blank" rel="noopener noreferrer" style="background: #2563eb; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; margin-right: 10px; display: inline-block;">
üì• Download PDF
</a> <a href="https://lonardonifabio.github.io/tech_documents/?doc=f0d459ea224d863a4619bcb90b5f25ae" style="background: #16a34a; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; display: inline-block;">
üîç View in Library
</a> </div> <div style="background: #eff6ff; padding: 15px; border-radius: 8px; border-left: 4px solid #3b82f6;"> <p style="color: #1e40af; font-size: 14px; margin: 0;"> <strong>Note:</strong> You will be automatically redirected to the interactive document library. 
            If the redirect doesn't work, <a href="https://lonardonifabio.github.io/tech_documents/?doc=f0d459ea224d863a4619bcb90b5f25ae" style="color: #1e40af; text-decoration: underline;">click here</a>.
</p> </div> </div> </div> </body></html>