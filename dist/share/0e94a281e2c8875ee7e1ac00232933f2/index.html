<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="This research paper, published on arXiv in June 2025 (arXiv:2505.24832v2 [cs.CL]), investigates the extent to which modern language models ‚Äòmemorize‚Äô information from their training datasets. The authors propose a novel method to quantify this memorization, separating it into two distinct compone..."><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/tech_documents/favicon.svg"><title>How much do language models memorize?</title><!-- Enhanced Open Graph for LinkedIn sharing --><meta property="og:title" content="How much do language models memorize?"><meta property="og:description" content="This research paper, published on arXiv in June 2025 (arXiv:2505.24832v2 [cs.CL]), investigates the extent to which modern language models ‚Äòmemorize‚Äô information from their training datasets. The authors propose a novel method to quantify this memorization, separating it into two distinct compone..."><meta property="og:type" content="article"><meta property="og:url" content="https://lonardonifabio.github.io/tech_documents/share/0e94a281e2c8875ee7e1ac00232933f2"><meta property="og:image" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:secure_url" content="https://www.fabiolonardoni.it/AIdatasciencelibrary_cover.JPG"><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="How much do language models memorize? - AI &#38; Data Science Document Library"><meta property="og:site_name" content="AI & Data Science Document Library"><meta property="og:locale" content="en_US"><meta property="article:author" content="Fabio Lonardoni"><meta property="article:section" content="Technology"><meta property="article:tag" content="language models, memorization, capacity, scaling laws, transformer language models, membership inference, data size, entropy, Kolmogorov Complexity, dataset"><meta property="article:published_time" content="2025-06-23T13:44:23.767407"><!-- LinkedIn specific meta tags --><meta property="linkedin:owner" content="Fabio Lonardoni"><meta property="og:rich_attachment" content="true"><!-- Additional meta for mobile sharing --><meta name="author" content=""><meta name="keywords" content="language models, memorization, capacity, scaling laws, transformer language models, membership inference, data size, entropy, Kolmogorov Complexity, dataset"><meta name="robots" content="index, follow"><link rel="canonical" href="https://lonardonifabio.github.io/tech_documents/share/0e94a281e2c8875ee7e1ac00232933f2"><!-- Immediate redirect to main app --><script>(function(){const mainAppUrl = "https://lonardonifabio.github.io/tech_documents/?doc=0e94a281e2c8875ee7e1ac00232933f2";

      // Immediate redirect for users (crawlers will read meta tags first)
      if (typeof window !== 'undefined') {
        window.location.replace(mainAppUrl);
      }
    })();</script><!-- Fallback meta refresh for non-JS environments --><meta http-equiv="refresh" content="0; url={mainAppUrl}"><link rel="stylesheet" href="/tech_documents/assets/_id_.BVtkUjOa.css"></head> <body class="bg-gray-50 min-h-screen"> <!-- Fallback content for crawlers and users with JS disabled --> <div style="max-width: 800px; margin: 0 auto; padding: 20px; font-family: system-ui, sans-serif;"> <div style="background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);"> <h1 style="color: #1f2937; margin-bottom: 20px;">How much do language models memorize?</h1>  <div style="margin-bottom: 20px;"> <p style="color: #374151; line-height: 1.6;">This research paper, published on arXiv in June 2025 (arXiv:2505.24832v2 [cs.CL]), investigates the extent to which modern language models ‚Äòmemorize‚Äô information from their training datasets. The authors propose a novel method to quantify this memorization, separating it into two distinct components: unintended memorization, representing the model&#39;s direct knowledge of the specific dataset, and generalization, which reflects the model&#39;s understanding of the underlying data generation process.  The core contribution is a framework for calculating total memorization, providing an estimate of model capacity.  The study utilizes a large-scale experiment training hundreds of transformer language models, ranging in size from 500K to 1.5B parameters, across datasets of increasing size.  The researchers observed a clear relationship between model size, data size, and memorization. Initially, models exhibited increasing memorization as their capacity filled. However, beyond a certain point, ‚Äògrokking‚Äô ‚Äì a process where models begin to generalize ‚Äì occurred, leading to a decrease in unintended memorization.  The findings suggest that models in the GPT family have an approximate capacity of 3.6 bits-per-parameter.  The research also explores scaling laws relating model capacity and data size to membership inference, a critical area for understanding and mitigating potential privacy risks associated with language models. The study&#39;s methodology and results offer valuable insights into the limitations and capabilities of current language models, particularly concerning their reliance on memorization rather than genuine understanding. The authors&#39; approach provides a more nuanced way to assess model capacity and highlights the importance of controlling for generalization to prevent unintended data leakage.  The research is significant for advancing the field of AI safety and responsible model development.</p> </div> <div style="margin-bottom: 20px;"> <h3 style="color: #1f2937; margin-bottom: 10px;">Key Concepts:</h3> <ul style="color: #374151;"> <li style="margin-bottom: 5px;">Models memorize information from datasets (unintended memorization).</li><li style="margin-bottom: 5px;">Generalization refers to a model&#39;s understanding of the data generation process.</li><li style="margin-bottom: 5px;">Model capacity is estimated by isolating memorization and measuring its relationship to data size.</li><li style="margin-bottom: 5px;">Grokking is a phenomenon where memorization plateaus and generalization begins.</li><li style="margin-bottom: 5px;">Super-additivity of Unintended Memorization</li><li style="margin-bottom: 5px;">Entropy-based notion of information</li><li style="margin-bottom: 5px;">Single underlying model</li><li style="margin-bottom: 5px;">Dataset level measurement</li><li style="margin-bottom: 5px;">Unintended memorization of models</li><li style="margin-bottom: 5px;">Deduplication practices</li> </ul> </div> <div style="margin-bottom: 20px;"> <span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> language models </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> memorization </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> capacity </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> scaling laws </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> transformer language models </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> membership inference </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> data size </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> entropy </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> Kolmogorov Complexity </span><span style="background: #dbeafe; color: #1e40af; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 8px; margin-bottom: 8px; display: inline-block;"> dataset </span> </div> <div style="margin-bottom: 20px;"> <span style="background: #dcfce7; color: #166534; padding: 4px 12px; border-radius: 20px; font-size: 14px; margin-right: 10px;"> Technology </span> <span style="background: #fed7aa; color: #9a3412; padding: 4px 12px; border-radius: 20px; font-size: 14px;"> Intermediate </span> </div> <div style="margin-bottom: 20px;"> <a href="https://raw.githubusercontent.com/lonardonifabio/tech_documents/main/documents/LLM_memory_Google_Meta_Cornell_1750055868.pdf" target="_blank" rel="noopener noreferrer" style="background: #2563eb; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; margin-right: 10px; display: inline-block;">
üì• Download PDF
</a> <a href="https://lonardonifabio.github.io/tech_documents/?doc=0e94a281e2c8875ee7e1ac00232933f2" style="background: #16a34a; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; display: inline-block;">
üîç View in Library
</a> </div> <div style="background: #eff6ff; padding: 15px; border-radius: 8px; border-left: 4px solid #3b82f6;"> <p style="color: #1e40af; font-size: 14px; margin: 0;"> <strong>Note:</strong> You will be automatically redirected to the interactive document library. 
            If the redirect doesn't work, <a href="https://lonardonifabio.github.io/tech_documents/?doc=0e94a281e2c8875ee7e1ac00232933f2" style="color: #1e40af; text-decoration: underline;">click here</a>.
</p> </div> </div> </div> </body></html>